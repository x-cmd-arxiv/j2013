{"id":"1303.6868","submitter":"Bradley James Kavanagh","authors":"Bradley J. Kavanagh, Anne M. Green","title":"Model independent determination of the dark matter mass from direct\n  detection experiments","comments":"5 pages, 3 figures. Minor changes. Matches version published in PRL","journal-ref":"Phys. Rev. Lett. 111, 031302 (2013)","doi":"10.1103/PhysRevLett.111.031302","report-no":null,"categories":"astro-ph.CO hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Determining the dark matter (DM) mass is of paramount importance for\nunderstanding dark matter. We present a novel parametrization of the DM speed\ndistribution which will allow the DM mass to be accurately measured using data\nfrom Weakly Interacting Massive Particle (WIMP) direct detection experiments.\nSpecifically, we parametrize the natural logarithm of the speed distribution as\na polynomial in the speed v. We demonstrate, using mock data from upcoming\nexperiments, that by fitting the WIMP mass and interaction cross-section, along\nwith the polynomial coefficients, we can accurately reconstruct both the WIMP\nmass and speed distribution. This new method is the first demonstration that an\naccurate, unbiased reconstruction of the WIMP mass is possible without prior\nassumptions about the distribution function. We anticipate that this technique\nwill be invaluable in the analysis of future experimental data.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:02:33 GMT"},{"version":"v2","created":"Thu, 18 Jul 2013 09:48:22 GMT"}],"update_date":"2013-07-19"}
{"id":"1303.6869","submitter":"Nicolae Radu Zabet","authors":"Nicolae Radu Zabet, Robert Foy and Boris Adryan","title":"The influence of transcription factor competition on the relationship\n  between occupancy and affinity","comments":"28 pages, 14 figures, 6 tables","journal-ref":"PLoS ONE 8:9 (2013) e73714","doi":"10.1371/journal.pone.0073714","report-no":null,"categories":"q-bio.MN q-bio.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transcription factors (TFs) are proteins that bind to specific sites on the\nDNA and regulate gene activity. Identifying where TF molecules bind and how\nmuch time they spend on their target sites is key for understanding\ntranscriptional regulation. It is usually assumed that the free energy of\nbinding of a TF to the DNA (the affinity of the site) is highly correlated to\nthe amount of time the TF remains bound (the occupancy of the site). However,\nknowing the binding energy is not sufficient to infer actual binding site\noccupancy. This mismatch between the occupancy predicted by the affinity and\nthe observed occupancy may be caused by various factors, such as TF abundance,\ncompetition between TFs or the arrangement of the sites on the DNA. We\ninvestigated the relationship between the affinity of a TF for a set of binding\nsites and their occupancy. In particular, we considered the case of lac\nrepressor (lacI) in E.coli and performed stochastic simulations of the TF\ndynamics on the DNA for various combinations of lacI abundance in competition\nwith TFs that contribute to macromolecular crowding. Our results showed that\nfor medium and high affinity sites, TF competition does not play a significant\nrole in genomic occupancy, except in cases when the abundance of lacI is\nsignificantly increased or when a low-information content PWM was used.\nNevertheless, for medium and low affinity sites, an increase in TF abundance\n(for both lacI or other molecules) leads to an increase in occupancy at several\nsites. Keywords: facilitated diffusion, Position Weight Matrix, thermodynamic\nequilibrium, motif information content, molecular crowding\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:03:09 GMT"}],"update_date":"2013-10-01"}
{"id":"1303.6870","submitter":"Brian Kloppenborg","authors":"Brian K. Kloppenborg, Roger Pieri, Heinz-Bernd Eggenstein, Grigoris\n  Maravelias, Tom Pearson","title":"A Demonstration of Accurate Wide-field V-band Photometry Using a\n  Consumer-grade DSLR Camera","comments":"Published in JAAVSO v40 n2: http://www.aavso.org/ejaavso402815. See\n  also: http://adsabs.harvard.edu/abs/2012JAVSO..40..815K","journal-ref":"2012JAVSO..40..815K","doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The authors examined the suitability of using a Digital Single Lens Reflex\n(DSLR) camera for stellar photometry and, in particular, investigated wide\nfield exposures made with minimal equipment for analysis of bright variable\nstars. A magnitude-limited sample of stars was evaluated exhibiting a wide\nrange of (B-V) colors taken from four fields between Cygnus and Draco.\nExperiments comparing green channel DSLR photometry with VT photometry of the\nTycho 2 catalogue showed very good agreement. Encouraged by the results of\nthese comparisons, a method for performing color-based transformations to the\nmore widely used Johnson V filter band was developed and tested. This method is\nsimilar to that recommended for Tycho 2 VT data. The experimental evaluation of\nthe proposed method led to recommendations concerning the feasibility of high\nprecision DSLR photometry for certain types of variable star projects. Most\nimportantly, we have demonstrated that DSLR cameras can be used as accurate,\nwide field photometers with only a minimal investment of funds and time.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:03:19 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6871","submitter":"Brian Kloppenborg","authors":"Brian Kloppenborg, Jeffery Hopkins, Robert Stencel","title":"An Analysis of the Long-term Photometric Behavior of epsilon Aurigae","comments":"Published in JAAVSO v40n2 http://www.aavso.org/jaavso-v40n2 Also see\n  http://adsabs.harvard.edu/abs/2012JAVSO..40..647K","journal-ref":"2012JAVSO..40..647K","doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The lure of a 50 percent reduction in light has brought a multitude of\nobservers and researchers to epsilon Aur every twenty-seven years, but few have\npaid attention to the system outside of eclipse. As early as the late 1800s, it\nwas clear that the system undergoes some form of quasi-periodic variation\noutside of totality, but few considered this effect in their research until the\nmid-1950s. In this work we focus exclusively on the out-of-eclipse (OOE)\nvariations seen in this system. We have digitized twenty-seven sources of\nhistoric photometry from eighty-one different observers. Two of these sources\nprovide twenty-seven years of inter-eclipse UBV photometry which we have\nanalyzed using modern period finding techniques. We have discovered the F-star\nvariations are multiperiodic with at least two periods that evolve in time at\ndelta(Period) approximately -1.5 day/year. These periods are detected when they\nmanifest as near-sinusoidal variations at 3,200-day intervals. We discuss our\nwork in an evolutionary context by comparing the behavior found in e Aur with\nbona-fide supergiant and post-AGB stars of similar spectral type. Based upon\nour qualitative comparison, we find the photometric behavior of the F-star in\nthe e Aur system is more indicative of supergiant behavior. Therefore the star\nis more likely to be a \"traditional supergiant\" than a post-AGB object. We\nencourage continued photometric monitoring of this system to test our\npredictions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:08:55 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6872","submitter":"Jakub Radoszewski","authors":"Maxime Crochemore, Costas S. Iliopoulos, Tomasz Kociumaka, Marcin\n  Kubica, Alessio Langiu, Solon P. Pissis, Jakub Radoszewski, Wojciech Rytter,\n  Tomasz Walen","title":"Order-Preserving Suffix Trees and Their Algorithmic Applications","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently Kubica et al. (Inf. Process. Let., 2013) and Kim et al. (submitted\nto Theor. Comp. Sci.) introduced order-preserving pattern matching. In this\nproblem we are looking for consecutive substrings of the text that have the\nsame \"shape\" as a given pattern. These results include a linear-time\norder-preserving pattern matching algorithm for polynomially-bounded alphabet\nand an extension of this result to pattern matching with multiple patterns. We\nmake one step forward in the analysis and give an\n$O(\\frac{n\\log{n}}{\\log\\log{n}})$ time randomized algorithm constructing suffix\ntrees in the order-preserving setting. We show a number of applications of\norder-preserving suffix trees to identify patterns and repetitions in time\nseries.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:13:03 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6873","submitter":"Robin Stephenson","authors":"Robin Stephenson (CEREMADE)","title":"General Fragmentation Trees","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the genealogy of any self-similar fragmentation process can be\nencoded in a compact measured real tree. Under some Malthusian hypotheses, we\ncompute the fractal Hausdorff dimension of this tree through the use of a\nnatural measure on the set of its leaves. This generalizes previous work of\nHaas and Miermont which was restricted to conservative fragmentation processes.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:13:06 GMT"},{"version":"v2","created":"Sun, 31 Mar 2013 08:51:42 GMT"}],"update_date":"2013-04-02"}
{"id":"1303.6874","submitter":"Elisa Gorla","authors":"Emanuela De Negri and Elisa Gorla","title":"Invariants of ideals generated by pfaffians","comments":null,"journal-ref":"Commutative Algebra and Its Connections to Geometry, A. Corso and\n  C. Polini Editors, Contemporary Mathematics 555 (2011), 47-62","doi":null,"report-no":null,"categories":"math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Ideals generated by pfaffians are of interest in commutative algebra and\nalgebraic geometry, as well as in combinatorics. In this article we compute\nmultiplicity and Castelnuovo-Mumford regularity of pfaffian ideals of ladders.\nWe give explicit formulas for some families of ideals, and indicate a procedure\nthat allows to recursively compute the invariants of any pfaffian ideal of\nladder. Our approach makes an essential use of liaison theory.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:15:43 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6875","submitter":"Serge Bouc","authors":"Serge Bouc (LAMFA)","title":"Fused Mackey functors","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR math.CT math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $G$ be a finite group. In [HTW], Hambleton, Taylor and Williams have\nconsidered the question of comparing Mackey functors for $G$ and biset functors\ndefined on subgroups of $G$ and bifree bisets as morphisms. This paper proposes\na different approach to this problem, from the point of view of various\ncategories of $G$-sets. In particular, the category of fused $G$-sets is\nintroduced, as well its category of spans. The fused Mackey functors for $G$\nover a commutative ring $R$ are defined as $R$-linear functors from this\n($R$-linearized) category of spans to $R$-modules. They form an abelian\nsubcategory of the category of Mackey functors for $G$ over $R$, equivalent\n(for $R=Z$) to the category to the category of conjugation Mackey functors of\n[HTW]. The category of fused Mackey functors is also equivalent to the category\nof modules over the fused Mackey algebra, which is a quotient of the usual\nMackey algebra of $G$ over $R$. Reference: [HTW] I. Hambleton, L. R. Taylor,\nand E. B. Williams. Mackey functors and bisets. Geom. Dedicata, 148:157--174,\n2010.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:17:01 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6876","submitter":"Ben Van Duppen","authors":"B. Van Duppen, F. M. Peeters","title":"Four band tunneling in bilayer graphene","comments":null,"journal-ref":"Phys. Rev. B 87, 205427 (2013)","doi":"10.1103/PhysRevB.87.205427","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The conductance, the transmission and the reflection probabilities through\nrectangular potential barriers and pn-junctions are obtained for bilayer\ngraphene taking into account the four bands of the energy spectrum. We have\nevaluated the importance of the skew hopping parameters {\\gamma}3 and {\\gamma}4\nto these properties and show that for energies E>{\\gamma}1/100 their effect is\nnegligible. For high energies two modes of propagation exist and we investigate\nscattering between these modes. For perpendicular incidence both propagation\nmodes are decoupled and scattering between them is forbidden. This extends the\nconcept of pseudospin as defined within the two band approximation to a four\nband model and corresponds to the (anti)symmetry of the wavefunctions under\nin-plane mirroring. New transmission resonances are found that appear as sharp\npeaks in the conductance which are absent in the two band approximation. The\napplication of an interlayer bias to the system: 1) breaks the pseudospin\nstructure, 2) opens a bandgap that results in a distinct feature of suppressed\ntransmission in the conductance, and 3) breaks the angular symmetry with\nrespect to normal incidence in the transmission and reflection.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:19:28 GMT"}],"update_date":"2013-05-28"}
{"id":"1303.6877","submitter":"Alexander Enzenh\\\"ofer","authors":"Alexander Enzenh\\\"ofer (for the KM3NeT Collaboration)","title":"Acoustic Calibration for the KM3NeT Pre-Production Module","comments":"4 pages, 4 figures. To be published in: Nuclear Inst. and Methods in\n  Physics Research, A. Conference proceedings of the \"VLVnT11 - Very Large\n  Volume Neutrino Telescope Workshop (2011)\"","journal-ref":"Nuclear Inst. and Methods in Physics Research, A (2013), pp.\n  211-214","doi":"10.1016/j.nima.2012.12.074","report-no":null,"categories":"astro-ph.IM physics.ins-det","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The proposed large scale Cherenkov neutrino telescope KM3NeT will carry\nphoto-sensors on flexible structures, the detection units. The Mediterranean\nSea, where KM3NeT will be installed, constitutes a highly dynamic environment\nin which the detection units are constantly in motion. Thus it is necessary to\nmonitor the exact sensor positions continuously to achieve the desired\nresolution for the neutrino telescope. A common way to perform this monitoring\nis the use of acoustic positioning systems with emitters and receivers based on\nthe piezoelectric effect. The acoustic receivers are attached to detection\nunits whereas the emitters are located at known positions on the sea floor.\nThere are complete commercial systems for this application with sufficient\nprecision. But these systems are limited in the use of their data and\ninefficient as they were designed to perform only this single task. Several\nworking groups in the KM3NeT consortium are cooperating to custom-design a\npositioning system for the specific requirements of KM3NeT. Most of the studied\nsolutions hold the possibility to extend the application area from positioning\nto additional tasks like acoustic particle detection or monitoring of the\ndeep-sea acoustic environment. The KM3NeT Pre-Production Module (PPM) is a test\nsystem to verify the correct operation and interoperability of the major\ninvolved hardware and software components developed for KM3NeT. In the context\nof the PPM, alternative designs of acoustic sensors including small\npiezoelectric elements equipped with preamplifiers inside the same housing as\nthe optical sensors will be tested. These will be described in this article.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:22:01 GMT"}],"update_date":"2019-08-14"}
{"id":"1303.6878","submitter":"Christof Wetterich","authors":"C. Wetterich","title":"A Universe without expansion","comments":"new references, extended discussion of absence of big bang\n  singularity, 5 pages. arXiv admin note: text overlap with arXiv:1308.1019","journal-ref":null,"doi":"10.1016/j.dark.2013.10.002","report-no":null,"categories":"astro-ph.CO gr-qc hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss a cosmological model where the universe shrinks rather than\nexpands during the radiation and matter dominated periods. Instead, the Planck\nmass and all particle masses grow exponentially, with the size of atoms\nshrinking correspondingly. Only dimensionless ratios as the distance between\ngalaxies divided by the atom radius are observable. Then the cosmological\nincrease of this ratio can also be attributed to shrinking atoms. We present a\nsimple model where the masses of particles arise from a scalar \"cosmon\" field,\nsimilar to the Higgs scalar. The potential of the cosmon is responsible for\ninflation and the present dark energy. Our model is compatible with all present\nobservations. While the value of the cosmon field increases, the curvature\nscalar is almost constant during all cosmological epochs. Cosmology has no big\nbang singularity. There exist other, equivalent choices of field variables for\nwhich the universe shows the usual expansion or is static during the radiation\nor matter dominated epochs. For those \"field coordinates\" the big bang is\nsingular. Thus the big bang singularity turns out to be related to a singular\nchoice of field coordinates.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:22:39 GMT"},{"version":"v2","created":"Fri, 5 Jul 2013 12:14:14 GMT"},{"version":"v3","created":"Tue, 30 Jul 2013 12:34:29 GMT"},{"version":"v4","created":"Tue, 12 Nov 2013 09:20:52 GMT"}],"update_date":"2013-11-13"}
{"id":"1303.6880","submitter":"Hassan Ghozlan","authors":"Hassan Ghozlan and Gerhard Kramer","title":"Multi-sample Receivers Increase Information Rates for Wiener Phase Noise\n  Channels","comments":"Submitted to Globecom 2013","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A waveform channel is considered where the transmitted signal is corrupted by\nWiener phase noise and additive white Gaussian noise (AWGN). A discrete-time\nchannel model is introduced that is based on a multi-sample receiver. Tight\nlower bounds on the information rates achieved by the multi-sample receiver are\ncomputed by means of numerical simulations. The results show that oversampling\nat the receiver is beneficial for both strong and weak phase noise at high\nsignal-to-noise ratios. The results are compared with results obtained when\nusing other discrete-time models.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:24:08 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6881","submitter":"Richard Clegg","authors":"Eleni Mykoniati, Laurence Latif, Raul Landa, Ben Yang, Richard G.\n  Clegg, David Griffin, Miguel Rio","title":"Distributed Overlay Anycast Table using Space filling curves","comments":"7 pages, 4 figures","journal-ref":"Proceedings of IEEE INFOCOM Workshop, Global Internet Symposium GI\n  2009","doi":"10.1109/INFCOMW.2009.5072131","report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we present the \\emph{Distributed Overlay Anycast Table}, a\nstructured overlay that implements application-layer anycast, allowing the\ndiscovery of the closest host that is a member of a given group. One\napplication is in locality-aware peer-to-peer networks, where peers need to\ndiscover low-latency peers participating in the distribution of a particular\nfile or stream. The DOAT makes use of network delay coordinates and a space\nfilling curve to achieve locality-aware routing across the overlay, and Bloom\nfilters to aggregate group identifiers. The solution is designed to optimise\nboth accuracy and query time, which are essential for real-time applications.\nWe simulated DOAT using both random and realistic node distributions. The\nresults show that accuracy is high and query time is low.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:24:21 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6882","submitter":"Romain Abraham","authors":"Romain Abraham (MAPMO), Jean-Francois Delmas (CERMICS)","title":"$\\beta$-coalescents and stable Galton-Watson trees","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Representation of coalescent process using pruning of trees has been used by\nGoldschmidt and Martin for the Bolthausen-Sznitman coalescent and by Abraham\nand Delmas for the $\\beta(3/2,1/2)$-coalescent. By considering a pruning\nprocedure on stable Galton-Watson tree with $n$ labeled leaves, we give a\nrepresentation of the discrete $\\beta(1+\\alpha,1-\\alpha)$-coalescent, with\n$\\alpha\\in [1/2,1)$ starting from the trivial partition of the $n$ first\nintegers. The construction can also be made directly on the stable continuum\nL{\\'e}vy tree, with parameter $1/\\alpha$, simultaneously for all $n$. This\nrepresentation allows to use results on the asymptotic number of coalescence\nevents to get the asymptotic number of cuts in stable Galton-Watson tree (with\ninfinite variance for the reproduction law) needed to isolate the root. Using\nconvergence of the stable Galton-Watson tree conditioned to have infinitely\nmany leaves, one can get the asymptotic distribution of blocks in the last\ncoalescence event in the $\\beta(1+\\alpha,1-\\alpha)$-coalescent.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:25:15 GMT"},{"version":"v2","created":"Wed, 7 Jan 2015 17:43:10 GMT"}],"update_date":"2015-01-08"}
{"id":"1303.6883","submitter":"Thomas Dufaud","authors":"Thomas Dufaud (IRISA / INRIA Rennes), Tromeur-Dervout Damien (ICJ)","title":"ARAS: Fully algebraic Two-level domain decomposition precondition\n  technique with approximation on course interfaces Fully","comments":"33 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper focuses on the development of a two-level preconditioner based on\na fully algebraical enhancement of a Schwarz domain decomposition method. We\nconsider the purely divergence of a Restricted Additive Scwharz iterative\nprocess leading to the preconditioner developped by X.-C. Cai and M. Sarkis in\nSIAM Journal of Scientific Computing, Vol. 21 no. 2, 1999. The convergence of\nvectorial sequence of traces of this process on the artificial interface can be\naccelerated by an Aitken acceleration technique as proposed in the work of M.\nGarbey and D. Tromeur-Dervout, in International Journal for Numerical Methods\nin Fluids, Vol. 40, no. 12,2002. We propose a formulation of the Aitken-Schwarz\ntechnique as a preconditioning technique called Aitken-RAS 1 . The Aitken\nacceleration is performed in a reduced space to save computing or permit fully\nalgebraic computation of the accelerated solution without knowledge of the\nunderlying equations. A convergence study of the Aitken-RAS preconditioner is\nproposed also application on industrial problem.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:26:22 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6884","submitter":"Arnaud Guillin","authors":"Patrick Cattiaux (IMT), Arnaud Guillin","title":"Semi Log-Concave Markov Diffusions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we intend to give a comprehensive approach of functional\ninequalities for diffusion processes under some \"curvature\" assumptions. Our\nnotion of curvature coincides with the usual $\\Gamma_2$ curvature of Bakry and\nEmery in the case of a (reversible) drifted Brownian motion, but differs for\nmore general diffusion processes. Our approach using simple coupling arguments\ntogether with classical stochastic tools, allows us to obtain new results, to\nrecover and to extend already known results, giving in many situations explicit\n(though non optimal) bounds. In particular, we show new results for\ngradient/semigroup commutation in the log concave case. Some new convergence to\nequilibrium in the granular media equation is also exhibited.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:27:59 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6885","submitter":"Hui Kong","authors":"Hui Kong, Fei He, Xiaoyu Song, William N. N. Hung and Ming Gu","title":"Exponential-Condition-Based Barrier Certificate Generation for Safety\n  Verification of Hybrid Systems","comments":"18 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A barrier certificate is an inductive invariant function which can be used\nfor the safety verification of a hybrid system. Safety verification based on\nbarrier certificate has the benefit of avoiding explicit computation of the\nexact reachable set which is usually intractable for nonlinear hybrid systems.\nIn this paper, we propose a new barrier certificate condition, called\nExponential Condition, for the safety verification of semi-algebraic hybrid\nsystems. The most important benefit of Exponential Condition is that it has a\nlower conservativeness than the existing convex condition and meanwhile it\npossesses the property of convexity. On the one hand, a less conservative\nbarrier certificate forms a tighter over-approximation for the reachable set\nand hence is able to verify critical safety properties. On the other hand, the\nproperty of convexity guarantees its solvability by semidefinite programming\nmethod. Some examples are presented to illustrate the effectiveness and\npracticality of our method.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:28:35 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6886","submitter":"Jordan Raddick","authors":"M. Jordan Raddick, Georgia Bracey, Pamela L. Gay, Chris J. Lintott,\n  Carie Cardamone, Phil Murray, Kevin Schawinski, Alexander S. Szalay, Jan\n  Vandenberg","title":"Galaxy Zoo: Motivations of Citizen Scientists","comments":"41 pages, including 6 figures and one appendix. In press at Astronomy\n  Education Review","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ed-ph astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Citizen science, in which volunteers work with professional scientists to\nconduct research, is expanding due to large online datasets. To plan projects,\nit is important to understand volunteers' motivations for participating. This\npaper analyzes results from an online survey of nearly 11,000 volunteers in\nGalaxy Zoo, an astronomy citizen science project. Results show that volunteers'\nprimary motivation is a desire to contribute to scientific research. We\nencourage other citizen science projects to study the motivations of their\nvolunteers, to see whether and how these results may be generalized to inform\nthe field of citizen science.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:28:51 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6887","submitter":"Richard Clegg","authors":"Eleni Mykoniati, Raul Landa, Spiros Spirou, Richard G. Clegg, Lawrence\n  Latif, David Griffin, Miguel Rio","title":"Scalable peer-to-peer streaming for live entertainment content","comments":"11 pages, 6 figures","journal-ref":"IEEE Communications 46(12) pp40-46 2008","doi":"10.1109/MCOM.2008.4689206","report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a system for streaming live entertainment content over the\nInternet originating from a single source to a scalable number of consumers\nwithout resorting to centralised or provider- provisioned resources. The system\ncreates a peer-to-peer overlay network, which attempts to optimise use of\nexisting capacity to ensure quality of service, delivering low start-up delay\nand lag in playout of the live content. There are three main aspects of our\nsolution. Firstly, a swarming mechanism that constructs an overlay topology for\nminimising propagation delays from the source to end consumers. Secondly, a\ndistributed overlay anycast system that uses a location-based search algorithm\nfor peers to quickly find the closest peers in a given stream. Finally, a novel\nincentives mechanism that encourages peers to donate capacity even when the\nuser is not actively consuming content.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:34:25 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6888","submitter":"Oktay Mukhtarov","authors":"O. Sh. Mukhtarov and K.Aydemir","title":"Asymptotic formulas for eigenvalues and eigenfunctions of a new\n  boundary-value-transmission problem","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we are concerned with a new class of BVP' s consisting of\neigendependent boundary conditions and two supplementary transmission\nconditions at one interior point. By modifying some techniques of classical\nSturm-Liouville theory and suggesting own approaches we find asymptotic\nformulas for the eigenvalues and eigenfunction.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:42:21 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6889","submitter":"Samuel Taylor","authors":"Samuel J. Taylor","title":"Right-angled Artin groups and Out(F_n) I: quasi-isometric embeddings","comments":"37 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct quasi-isometric embeddings from right-angled Artin groups into\nthe outer automorphism group of a free group. These homomorphisms are in\nanalogy with those constructed in \\cite{CLM}, where the target group is the\nmapping class group of a surface. Toward this goal, we develop tools in the\nfree group setting that mirror those for surface groups as well as discuss\nvarious analogs of subsurface projection; these may be of independent interest.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:44:17 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6890","submitter":"Oktay Mukhtarov","authors":"K. Aydemir and O.Sh.Mukhtarov","title":"Selfadjoint realization of boundary-value problems with interior\n  singularities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The purpose of this paper is to investigate some spectral properties of\nSturm-Liouville type problems with interior singularities. Some of the\nmathematical aspects necessary for developing own technique presented. By\napplying this technique we construct some special solutions of the homogeneous\nequation and present a formula and the existence conditions of Green's\nfunction. Further based on this results and introducing operator treatment in\nadequate Hilbert space we derive the resolvent operator and prove\nselfadjointness of the considered problem.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:45:15 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6891","submitter":"Aaron Manalaysay","authors":"Laura Baudis, Hrvoje Dujmovic, Christopher Geis, Andreas James,\n  Alexander Kish, Aaron Manalaysay, Teresa Marrodan Undagoitia, Marc Schumann","title":"Response of liquid xenon to Compton electrons down to 1.5 keV","comments":"14 pages, 10 figures. v2: Figure 8 updated, now including the NEST\n  prediction for field quenching. v3: modified values of derived energy\n  thresholds in the four DM experiments considered","journal-ref":"Phys.Rev.D87:115015,2013","doi":"10.1103/PhysRevD.87.115015","report-no":null,"categories":"astro-ph.IM physics.ins-det","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The response of liquid xenon to low-energy electronic recoils is relevant in\nthe search for dark-matter candidates which interact predominantly with atomic\nelectrons in the medium, such as axions or axion-like particles, as opposed to\nweakly interacting massive particles which are predicted to scatter with atomic\nnuclei. Recently, liquid-xenon scintillation light has been observed from\nelectronic recoils down to 2.1 keV, but without applied electric fields that\nare used in most xenon dark matter searches. Applied electric fields can reduce\nthe scintillation yield by hindering the electron-ion recombination process\nthat produces most of the scintillation photons. We present new results of\nliquid xenon's scintillation emission in response to electronic recoils as low\nas 1.5 keV, with and without an applied electric field. At zero field, a\nreduced scintillation output per unit deposited energy is observed below 10\nkeV, dropping to nearly 40% of its value at higher energies. With an applied\nelectric field of 450 V/cm, we observe a reduction of the scintillation output\nto about 75% relative to the value at zero field. We see no significant energy\ndependence of this value between 1.5 keV and 7.8 keV. With these results, we\nestimate the electronic-recoil energy thresholds of ZEPLIN-III, XENON10,\nXENON100, and XMASS to be 2.8 keV, 2.5 keV, 2.3 keV, and 1.1 keV, respectively,\nvalidating their excellent sensitivity to low-energy electronic recoils.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:46:45 GMT"},{"version":"v2","created":"Thu, 4 Apr 2013 09:29:05 GMT"},{"version":"v3","created":"Wed, 12 Jun 2013 09:50:06 GMT"}],"update_date":"2013-06-21"}
{"id":"1303.6892","submitter":"Oktay Mukhtarov","authors":"O. Sh. Mukhtarov and K. Aydemir","title":"Green's function for Sturm-Liouville problem","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The purpose of this study is to investigate a new class of boundary value\ntransmission problems (BVTP's) for Sturm-Liouville equation on two separate\nintervals. We introduce modified inner product in direct sum space\n$L_{2}[a,c)\\oplus L_{2}(c,b]\\oplus\\mathbb{C}^{2}$ and define symmetric linear\noperator in it such a way that the considered problem can be interpreted as an\neigenvalue problem of this operator. Then by suggesting an own approaches we\nconstruct Green's function for problem under consideration and find the\nresolvent function for corresponding inhomogeneous problem.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:49:06 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6893","submitter":"Oktay Mukhtarov","authors":"O. Sh. Mukhtarov and K. Aydemir","title":"Expansion Theorem for Sturm-Liouville problems transmission conditions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The purpose of this paper is to extend some spectral properties of regular\nSturm-Liouville problems to the special type discontinuous boundary-value\nproblem, which consists of a Sturm-Liouville equation together with\neigenparameter-dependent boundary conditions and two supplementary transmission\nconditions. We construct the resolvent operator and Green's function and prove\ntheorems about expansions in terms of eigenfunctions in modified Hilbert space\n$L_{2}[a, b]$. \\vskip0.3cm\\noindent Keywords: Boundary-value problems,\ntransmission conditions, Resolvent operator, expansion theorem.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:51:47 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6894","submitter":"Sean Ledger","authors":"Sean Ledger","title":"Sharp regularity near an absorbing boundary for solutions to second\n  order SPDEs in a half-line with constant coefficients","comments":null,"journal-ref":"Stochastic Partial Differential Equations: Analysis and\n  Computations, 2014, Volume 2, Issue 1, pp 1-26","doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that the weak version of the SPDE problem \\begin{align*} dV_{t}(x) &\n= [-\\mu V_{t}'(x) + \\frac{1}{2} (\\sigma_{M}^{2} + \\sigma_{I}^{2})V_{t}\"(x)]dt -\n\\sigma_{M} V_{t}'(x)dW^{M}_{t}, \\quad x > 0, \\\\ V_{t}(0) &= 0 \\end{align*} with\na specified bounded initial density, $V_{0}$, and $W$ a standard Brownian\nmotion, has a unique solution in the class of finite-measure valued processes.\nThe solution has a smooth density process which has a probabilistic\nrepresentation and shows degeneracy near the absorbing boundary. In the\nlanguage of weighted Sobolev spaces, we describe the precise order of\nintegrability of the density and its derivatives near the origin, and we relate\nthis behaviour to a two-dimensional Brownian motion in a wedge whose angle is a\nfunction of the ratio $\\sigma_{M}/\\sigma_{I}$. Our results are sharp: we\ndemonstrate that better regularity is unattainable.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:51:48 GMT"},{"version":"v2","created":"Thu, 23 Jul 2015 15:06:20 GMT"}],"update_date":"2015-07-24"}
{"id":"1303.6895","submitter":"Ilias Amrani","authors":"Ilias Amrani","title":"The mapping space of unbounded differential graded algebras","comments":"We extend our previous results to any ground commutative ring k","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT math.AG math.KT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we give a concrete description of the higher homotopy groups\n(n>0) of the mapping space Map_{Alg}(R,S) for R and S unbounded differential\ngraded algebras (DGA) over a commutative ring k. In the connective case, we\ndescribe the relation between the higher (negative) Hochschild cohomology\n$HH^{-n+1}(R,S)$ and higher homotopy groups $\\pi_{n} Map_{Alg}(R,S)$, when\n$n>1$.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:55:17 GMT"},{"version":"v2","created":"Tue, 18 Jun 2013 11:55:46 GMT"},{"version":"v3","created":"Mon, 27 Jan 2014 19:22:00 GMT"}],"update_date":"2014-01-28"}
{"id":"1303.6896","submitter":"Pierre Magain Mr","authors":"Pierre Magain and Virginie Chantry","title":"Gravitational lensing evidence against extended dark matter halos","comments":"9 pages, 2 figures, 1 table, submitted to ApJ Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is generally thought that galaxies are embedded in dark matter halos\nextending well beyond their luminous matter. The existence of these galactic\nhalos is mainly derived from the larger than expected velocities of stars and\ngas in the outskirts of spiral galaxies. Much less is known about dark matter\naround early-type (elliptical or lenticular) galaxies. We use gravitational\nlensing to derive the masses of early-type galaxies deflecting light of\nbackground quasars. This provides a robust measurement of the total mass within\nthe Einstein ring, a circle whose diameter is comparable to the separation of\nthe different quasar images. We find that the mass-to-light ratio of the\nlensing galaxies does not depend on radius, from inner galactic regions out to\nseveral half-light radii. Moreover, its value does not exceed the value\npredicted by stellar population models by more than a factor two, which may be\nexplained by baryonic dark matter alone, without any need for exotic matter.\nOur results thus suggest that, if dark matter is present in early-type\ngalaxies, its amount does not exceed the amount of luminous matter and its\ndensity follows that of luminous matter, in sharp contrast to what is found\nfrom rotation curves of spiral galaxies.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:55:54 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6897","submitter":"Kazem Azizi","authors":"T. M. Aliev, K. Azizi, M. Savci","title":"Analysis of $\\gamma^\\ast \\Lambda \\to \\Sigma^0$ transition in QCD","comments":"13 Pages and 4 Figures","journal-ref":null,"doi":"10.1103/PhysRevD.87.096013","report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The $\\gamma^\\ast \\Lambda \\to \\Sigma^0$ transition form factors are\ninvestigated within the light--cone QCD sum rules method. Using the most\ngeneral form of the interpolating current of $\\Sigma^0$ baryon and the\ndistribution amplitudes of $\\Lambda$ baryon we calculate the $Q^2$ dependence\nof the electromagnetic form factors. Our result are compared with the\npredictions of the covariant spectator quark model.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:56:41 GMT"},{"version":"v2","created":"Tue, 14 May 2013 13:50:22 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6898","submitter":"Oktay Mukhtarov","authors":"K. Aydemir and O. Sh. Mukhtarov","title":"Modified Expansion Theorem for Sturm-Liouville problem with transmission\n  conditions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA math.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is devoted to the derivation of expansion a associated with a\ndiscontinuous Sturm-Liouville problems defined on $[-\\pi, 0)\\cup(0,\\pi]$. We\nderive an eigenfunction expansion theorem for the Green's function of the\nproblem as well as a theorem of uniform convergence of a certain class of\nfunctions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:01:43 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6900","submitter":"Tsorng-Whay Pan Dr.","authors":"Suchung Hou, Tsorng-Whay Pan and Roland Glowinski","title":"Circular band formation for incompressible viscous fluid--rigid particle\n  mixtures in a rotating cylinder","comments":"12 pages; 12 figures","journal-ref":null,"doi":"10.1103/PhysRevE.89.023013","report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we have investigated a circular band formation of fluid-rigid\nparticle mixtures in a fully filled cylinder horizontally rotating about its\ncylinder axis by direct numerical simulation. These phenomena are modeled by\nthe Navier-Stokes equations coupled to the Euler-Newton equations describing\nthe rigid solid motion of the non-neutrally particles. The formation of\ncircular bands studied in this paper is not resulted by mutual interaction\nbetween the particles and the periodic inertial waves in the cylinder axis\ndirection (as suggested in Phys. Rev. E, 72, 021407 (2005)), but due to the\ninteraction of particles. When a circular band is forming, the part of the band\nformed by the particles moving downward becomes more compact due to the\nparticle interaction strengthened by the downward acceleration from the\ngravity. The part of a band formed by the particles moving upward is always\nloosening up due to the slow down of the particle motion by the counter effect\nof the gravity. To form a compact circular band (not a loosely one), enough\nparticles are needed to interact among themselves continuously through the\nentire circular band at a rotating rate so that the upward diffusion of\nparticles can be balanced by the compactness process when these particles\nmoving downward.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:27:00 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6901","submitter":"Zsolt Paragi","authors":"Z. Paragi, A. J. van der Horst, T. Belloni, J. C. A. Miller-Jones, J.\n  Linford, G. Taylor, J. Yang, M. A. Garrett, J. Granot, C. Kouveliotou, E.\n  Kuulkers, R. A. M. J. Wijers","title":"VLBI observations of the shortest orbital period black hole binary, MAXI\n  J1659-152","comments":"12 pages, 6 figures, 1 table. Accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stt545","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The X-ray transient MAXI J1659-152 was discovered by Swift/BAT and it was\ninitially identified as a GRB. Soon its Galactic origin and binary nature were\nestablished. There exists a wealth of multi-wavelength monitoring data for this\nsource, providing a great coverage of the full X-ray transition in this\ncandidate black hole binary system. We obtained two epochs of European VLBI\nNetwork (EVN) electronic-VLBI (e-VLBI) and four epochs of Very Long Baseline\nArray (VLBA) data of MAXI J1659-152 which show evidence for outflow in the\nearly phases. The overall source properties (polarization, milliarcsecond-scale\nradio structure, flat radio spectrum) are described well with the presence of a\ncompact jet in the system through the transition from the hard-intermediate to\nthe soft X-ray spectral state. The apparent dependence of source size and the\nradio core position on the observed flux density (luminosity dependent core\nshift) support this interpretation as well. We see no evidence for major\ndiscrete ejecta during the outburst. For the source proper motion we derive 2\nsigma upper limits of 115 microas/day in right ascension, and 37 microas/day in\ndeclination, over a time baseline of 12 days. These correspond to velocities of\n1400 km/s and 440 km/s, respectively, assuming a source distance of 7 kpc.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:14:01 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6902","submitter":"Junhua Zhang","authors":"Junhua Zhang, Joerg Schmalian, Tianqi Li, Jigang Wang","title":"Transient Charge and Energy Balance in Graphene Induced by Ultrafast\n  Photoexcitation","comments":"28 pages, 16 figures. Special section on ultrafast and nonlinear\n  optics in carbon nanomaterials","journal-ref":"J. Phys.: Condens. Matter 25 (2013) 314201","doi":"10.1088/0953-8984/25/31/314201","report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Ultrafast optical pump-probe spectroscopy measurement on monolayer graphene\nobserves significant optical nonlinearities. We show that strongly photoexcited\ngraphene monolayers with 35 fs pulses quasi-instantaneously build up a\nbroadband, inverted Dirac fermion population. Optical gain emerges and directly\nmanifests itself via a negative conductivity at the near-infrared region for\nthe first 200fs, where stimulated emission completely compensates absorption\nloss in the graphene layer. To quantitatively investigate this transient,\nextremely dense photoexcited Dirac-fermion state, we construct a\ntwo-chemical-potential model, in addition to a time-dependent transient carrier\ntemperature above lattice temperature, to describe the population inverted\nelectronic state metastable on the time scale of tens of femtoseconds generated\nby a strong exciting pulse. The calculated transient optical conductivity\nreveals a complete bleaching of absorption, which sets the saturation density\nduring the pulse propagation. Particularly, the model calculation reproduces\nthe negative optical conductivity at lower frequencies in the states close to\nsaturation, corroborating the observed femtosecond stimulated emission and\noptical gain in the wide near-infrared window.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:14:45 GMT"},{"version":"v2","created":"Tue, 30 Jul 2013 18:55:00 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6903","submitter":"Yun Li","authors":"Yun Li, Giovanni I. Martone, Lev P. Pitaevskii, and Sandro Stringari","title":"Superstripes and the excitation spectrum of a spin-orbit-coupled\n  Bose-Einstein condensate","comments":"5 pages, 5 figures","journal-ref":"Phys. Rev. Lett. 110, 235302 (2013)","doi":"10.1103/PhysRevLett.110.235302","report-no":null,"categories":"cond-mat.quant-gas","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using Bogoliubov theory we calculate the excitation spectrum of a spinor\nBose-Einstein condensed gas with equal Rashba and Dresselhaus spin-orbit\ncoupling in the stripe phase. The emergence of a double gapless band structure\nis pointed out as a key signature of Bose-Einstein condensation and of the\nspontaneous breaking of translational invariance symmetry. In the long\nwavelength limit the lower and upper branches exhibit, respectively, a clear\nspin and density nature. For wave vectors close to the first Brillouin zone,\nthe lower branch acquires an important density character responsible for the\ndivergent behavior of the structure factor and of the static response function,\nreflecting the occurrence of crystalline order. The sound velocities are\ncalculated as functions of the Raman coupling for excitations propagating\northogonal and parallel to the stripes. Our predictions provide new\nperspectives for the identification of supersolid phenomena in ultracold atomic\ngases.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:24:42 GMT"},{"version":"v2","created":"Fri, 7 Jun 2013 21:49:23 GMT"}],"update_date":"2013-06-11"}
{"id":"1303.6904","submitter":"Delfim F. M. Torres","authors":"Helena Sofia Rodrigues, M. Teresa T. Monteiro, Delfim F. M. Torres","title":"Bioeconomic Perspectives to an Optimal Control Dengue Model","comments":"This is a preprint of a paper whose final and definitive form will\n  appear in International Journal of Computer Mathematics, DOI:\n  10.1080/00207160.2013.790536. Paper submitted 09-Aug-2012; revised\n  07-Jan-2013; accepted for publication 21-Mar-2013. arXiv admin note:\n  substantial text overlap with arXiv:1207.1949","journal-ref":"Int. J. Comput. Math. 90 (2013), no. 10, 2126--2136","doi":"10.1080/00207160.2013.790536","report-no":null,"categories":"math.OC q-bio.PE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A model with six mutually-exclusive compartments related to dengue is\nstudied. Three vector control tools are considered: insecticides (larvicide and\nadulticide) and mechanical control. The basic reproduction number associated to\nthe model is presented. The problem is studied using an optimal control\napproach. The human data is based on the dengue outbreak that occurred in Cape\nVerde. Control measures are simulated in different scenarios and their\nconsequences analyzed.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:36:02 GMT"}],"update_date":"2013-11-26"}
{"id":"1303.6905","submitter":"Aleksey Tishin","authors":"Andrey Bushev, Sergey Vlasenko, Ilya Glotov, Yuri Monakhov, Aleksey\n  Tishin","title":"The development of the architecture of Distributed Network Intrusion\n  Detection System (D-NIDS)","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents the development of the architecture of Distributed\nNetwork Intrusion Detection System.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:38:47 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6907","submitter":"Florian Sikora","authors":"Cristina Bazgan, Morgan Chopin, Andr\\'e Nichterlein, Florian Sikora","title":"Parameterized Approximability of Maximizing the Spread of Influence in\n  Networks","comments":null,"journal-ref":"Journal of Discrete Algorithms (27), 2014, 54--65","doi":"10.1016/j.jda.2014.05.001","report-no":null,"categories":"cs.DS cs.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we consider the problem of maximizing the spread of influence\nthrough a social network. Given a graph with a threshold value~$thr(v)$\nattached to each vertex~$v$, the spread of influence is modeled as follows: A\nvertex~$v$ becomes \"active\" (influenced) if at least $thr(v)$ of its neighbors\nare active. In the corresponding optimization problem the objective is then to\nfind a fixed number of vertices to activate such that the number of activated\nvertices at the end of the propagation process is maximum. We show that this\nproblem is strongly inapproximable in fpt-time with respect to (w.r.t.)\nparameter $k$ even for very restrictive thresholds. In the case that the\nthreshold of each vertex equals its degree, we prove that the problem is\ninapproximable in polynomial time and it becomes $r(n)$-approximable in\nfpt-time w.r.t. parameter $k$ for any strictly increasing function $r$.\n  Moreover, we show that the decision version is W[1]-hard w.r.t. parameter $k$\nbut becomes fixed-parameter tractable on bounded degree graphs.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:41:51 GMT"},{"version":"v2","created":"Sun, 17 Aug 2014 09:13:01 GMT"}],"update_date":"2014-08-19"}
{"id":"1303.6908","submitter":"Richard Clegg","authors":"R. G. Clegg, M.S. Withall, A.W. Moore, I.W. Phillips, D.J. Parish, M.\n  Rio, R. Landa, H. Haddadi, K. Kyriakopoulos, J. Auge, R. Clayton, D.Salmon","title":"Challenges in the capture and dissemination of measurements from\n  high-speed networks","comments":"21 pages, 4 figures","journal-ref":"IET Communications, Vol 3, Issue 6, June 2009 pp 957-966","doi":"10.1049/iet-com.2008.0068","report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The production of a large-scale monitoring system for a high-speed network\nleads to a number of challenges. These challenges are not purely techinical but\nalso socio-political and legal. The number of stakeholders in a such a\nmonitoring activity is large including the network operators, the users, the\nequipment manufacturers and of course the monitoring researchers. The MASTS\nproject (Measurement at All Scales in Time and Space) was created to instrument\nthe high-speed JANET Lightpath network, and has been extended to incorporate\nother paths supported by JANET(UK).\n  Challenges the project has faced have included: simple access to the network;\nlegal issues involved in the storage and dissemination of the captured\ninformation, which may be personal; the volume of data captured and the rate at\nwhich this data appears at store. To this end the MASTS system will have\nestablished four monitoring points each capturing packets on a high speed link.\nTraffic header data will be continuously collected, anonymised, indexed, stored\nand made available to the research community. A legal framework for the capture\nand storage of network measurement data has been developed which allows the\nanonymised IP traces to be used for research pur poses.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:42:31 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6909","submitter":"Burkhard Eden","authors":"James Drummond, Claude Duhr, Burkhard Eden, Paul Heslop, Jeffrey\n  Pennington, Vladimir A. Smirnov","title":"Leading singularities and off-shell conformal integrals","comments":"60 pages, LaTeX, 2 figures, references added","journal-ref":null,"doi":"10.1007/JHEP08(2013)133","report-no":"HU-Mathematik:2013-06, HU-EP-13/15, IPPP/13/09, DCPT/13/18,\n  SLAC-PUB-15409, LAPTH-016/13, CERN-PH-TH/2013-058","categories":"hep-th hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The three-loop four-point function of stress-tensor multiplets in N=4 super\nYang-Mills theory contains two so far unknown, off-shell, conformal integrals,\nin addition to the known, ladder-type integrals. In this paper we evaluate the\nunknown integrals, thus obtaining the three-loop correlation function\nanalytically. The integrals have the generic structure of rational functions\nmultiplied by (multiple) polylogarithms. We use the idea of leading\nsingularities to obtain the rational coefficients, the symbol - with an\nappropriate ansatz for its structure - as a means of characterising multiple\npolylogarithms, and the technique of asymptotic expansion of Feynman integrals\nto obtain the integrals in certain limits. The limiting behaviour uniquely\nfixes the symbols of the integrals, which we then lift to find the\ncorresponding polylogarithmic functions. The final formulae are numerically\nconfirmed. The techniques we develop can be applied more generally, and we\nillustrate this by analytically evaluating one of the integrals contributing to\nthe same four-point function at four loops. This example shows a connection\nbetween the leading singularities and the entries of the symbol.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:44:32 GMT"},{"version":"v2","created":"Tue, 4 Jun 2013 14:52:32 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6911","submitter":"Thomas W. Mattman","authors":"Jamison Barsotti and Thomas W. Mattman","title":"Intrinsically knotted graphs with 21 edges","comments":"21 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the 14 graphs obtained by $\\nabla\\mathrm{Y}$ moves on K_7\nconstitute a complete list of the minor minimal intrinsically knotted graphs on\n21 edges. We also present evidence in support of a conjecture that the 20 graph\nHeawood family, obtained by a combination of $\\nabla\\mathrm{Y}$ and\n$\\mathrm{Y}\\nabla$ moves on K_7, is the list of graphs of size 21 that are\nminor minimal with respect to the property not 2--apex.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:48:59 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6912","submitter":"Marco Drewes","authors":"Marco Drewes","title":"The Phenomenology of Right Handed Neutrinos","comments":"Invited review for the International Journal of Modern Physics E.\n  This preprint is identical to the published article up to a few rephrasings\n  and a number of additional references that appeared after the article had\n  been accepted for publication","journal-ref":"Int. J. Mod. Phys. E, 22, 1330019 (2013)","doi":"10.1142/S0218301313300191","report-no":"TUM-HEP-881/13","categories":"hep-ph astro-ph.CO hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neutrinos are the only particles in the Standard Model of particle physics\nthat have only been observed with left handed chirality to date. If right\nhanded neutrinos exist, they could be responsible for several phenomena that\nhave no explanation within the Standard Model, including neutrino oscillations,\nthe baryon asymmetry of the universe, dark matter and dark radiation. After a\npedagogical introduction, we review recent progress in the phenomenology of\nright handed neutrinos. We in particular discuss the mass ranges suggested by\nhints for neutrino oscillation anomalies and dark radiation (eV), sterile\nneutrino dark matter scenarios (keV) and experimentally testable theories of\nbaryogenesis (GeV to TeV). We summarize constraints from theoretical\nconsiderations, laboratory experiments, astrophysics and cosmology for each of\nthese.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:49:15 GMT"},{"version":"v2","created":"Wed, 15 May 2013 20:00:10 GMT"},{"version":"v3","created":"Wed, 18 Sep 2013 20:00:03 GMT"}],"update_date":"2013-09-20"}
{"id":"1303.6913","submitter":"Adam Vellender","authors":"A. Vellender, G. Mishuris, A. Piccolroaz","title":"Perturbation analysis for an imperfect interface crack problem using\n  weight function techniques","comments":"Accepted version","journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyse a problem of anti-plane shear in a bi-material plane containing a\nsemi-infinite crack situated on a soft imperfect interface. The plane also\ncontains a small thin inclusion (for instance an ellipse with high\neccentricity) whose influence on the propagation of the main crack we\ninvestigate. An important element of our approach is the derivation of a new\nweight function (a special solution to a homogeneous boundary value problem) in\nthe imperfect interface setting. The weight function is derived using Fourier\ntransform and Wiener-Hopf techniques and allows us to obtain an expression for\nan important constant (which may be used in a fracture criterion) that\ndescribes the leading order of tractions near the crack tip for the unperturbed\nproblem. We present computations that demonstrate how this constant varies\ndepending on the extent of interface imperfection and contrast in material\nstiffness. We then perform perturbation analysis to derive an expression for\nthe change in the leading order of tractions near the tip of the main crack\ninduced by the presence of the small defect, whose sign can be interpreted as\nthe inclusion's presence having an amplifying or shielding effect on the\npropagation of the main crack.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:50:03 GMT"},{"version":"v2","created":"Thu, 28 Mar 2013 12:38:32 GMT"},{"version":"v3","created":"Wed, 24 Apr 2013 12:53:46 GMT"},{"version":"v4","created":"Tue, 20 Aug 2013 15:05:41 GMT"}],"update_date":"2013-08-21"}
{"id":"1303.6914","submitter":"Giorgio Ottaviani","authors":"Luca Chiantini, Massimiliano Mella, Giorgio Ottaviani","title":"One example of general unidentifiable tensors","comments":"7 pages, one Macaulay2 script as ancillary file, two references added","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The identifiability of parameters in a probabilistic model is a crucial\nnotion in statistical inference. We prove that a general tensor of rank 8 in\nC^3\\otimes C^6\\otimes C^6 has at least 6 decompositions as sum of simple\ntensors, so it is not 8-identifiable. This is the highest known example of\nbalanced tensors of dimension 3, which are not k-identifiable, when k is\nsmaller than the generic rank.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:02:00 GMT"},{"version":"v2","created":"Thu, 28 Mar 2013 07:57:35 GMT"},{"version":"v3","created":"Thu, 25 Apr 2013 10:54:32 GMT"}],"update_date":"2013-04-26"}
{"id":"1303.6915","submitter":"Giorgio Ottaviani","authors":"Cristiano Bocci, Luca Chiantini, Giorgio Ottaviani","title":"Refined methods for the identifiability of tensors","comments":"12 pages, three Macaulay2 scripts as ancillary files. v3: final\n  version to appear in Annali di Matematica Pura e Applicata","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that the general tensor of size 2^n and rank k has a unique\ndecomposition as the sum of decomposable tensors if k<= 0.9997 (2^n)/(n+1) (the\nconstant 1 being the optimal value). Similarly, the general tensor of size 3^n\nand rank k has a unique decomposition as the sum of decomposable tensors if k<=\n0.998 (3^n)/(2n+1) (the constant 1 being the optimal value).\n  Some results of this flavor are obtained for tensors of any size, but the\nexplicit bounds obtained are weaker.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:04:38 GMT"},{"version":"v2","created":"Thu, 28 Mar 2013 07:59:17 GMT"},{"version":"v3","created":"Mon, 13 May 2013 12:13:50 GMT"}],"update_date":"2013-05-14"}
{"id":"1303.6916","submitter":"Sebastiano Peotta","authors":"Sebastiano Peotta, Massimiliano Di Ventra","title":"Quantum Shock Waves and Population Inversion in Collisions of Ultracold\n  Atomic Clouds","comments":"11 pages, 6 figures. Enlarged and substantially revised version for\n  publication on Physical Review A. Supplementary online material available\n  upon request","journal-ref":"Phys. Rev. A 89, 013621 (2014)","doi":"10.1103/PhysRevA.89.013621","report-no":null,"categories":"cond-mat.quant-gas cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using Time-Dependent Density Matrix Renormalization Group (TDMRG) we study\nthe collision of one-dimensional atomic clouds confined in a harmonic trap and\nevolving with the Lieb-Liniger Hamiltonian. It is observed that the motion is\nessentially periodic with the clouds bouncing elastically, at least on the time\nscale of the first few oscillations that can be resolved with high accuracy.\nThis is in agreement with the results of the \"quantum Newton cradle\" experiment\nof Kinoshita et al. [Nature 440, 900 (2006)]. We compare the results for the\ndensity profile against a hydrodynamic description, or generalized nonlinear\nSchr\\\"odinger equation, with the pressure term taken from the Bethe Ansatz\nsolution of the Lieb-Liniger model. We find that hydrodynamics can describe the\nbreathing mode of a harmonically trapped cloud for arbitrary long times while\nit breaks down almost immediately for the collision of two clouds due to the\nformation of shock waves (gradient catastrophe). In the case of the clouds'\ncollision TDMRG alone allows to extract the oscillation period which is found\nto be measurably different from the breathing mode period. Concomitantly with\nthe shock waves formation we observe a local energy distribution typical of\npopulation inversion, i.e., an effective negative temperature. Our results are\nan important step towards understanding the hydrodynamics of quantum many-body\nsystems out of equilibrium and the role of integrability in their dynamics.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:05:53 GMT"},{"version":"v2","created":"Fri, 3 Jan 2014 23:23:43 GMT"}],"update_date":"2014-01-27"}
{"id":"1303.6917","submitter":"Anton Kapustin","authors":"Anton Kapustin","title":"Is there life beyond Quantum Mechanics?","comments":"23 pages, latex. v3: commentaries on the axioms expanded, a\n  non-technical summary added, references added, typos fixed. v4: version\n  accepted for publication in Journal of Mathematical Physic (under a different\n  title). Axiomatics is simplified and the number of axioms reduced, some\n  proofs clarified, typos fixed","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph hep-th math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We formulate physically-motivated axioms for a physical theory which for\nsystems with a finite number of degrees of freedom uniquely lead to Quantum\nMechanics as the only nontrivial consistent theory. Complex numbers and the\nexistence of the Planck constant common to all systems arise naturally in this\napproach. The axioms are divided into two groups covering kinematics and basic\nmeasurement theory respectively. We show that even if the second group of\naxioms is dropped, there are no deformations of Quantum Mechanics which\npreserve the kinematic axioms. Thus any theory going beyond Quantum Mechanics\nmust represent a radical departure from the usual a priori assumptions about\nthe laws of Nature.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:11:00 GMT"},{"version":"v2","created":"Thu, 28 Mar 2013 00:53:53 GMT"},{"version":"v3","created":"Tue, 9 Apr 2013 17:04:33 GMT"},{"version":"v4","created":"Mon, 3 Jun 2013 17:57:28 GMT"}],"update_date":"2013-06-04"}
{"id":"1303.6918","submitter":"P. S. Bhupal Dev","authors":"K.S. Babu, P.S. Bhupal Dev, Elaine C.F.S. Fortes and R.N. Mohapatra","title":"Post-Sphaleron Baryogenesis and an Upper Limit on the\n  Neutron-Antineutron Oscillation Time","comments":"22 pages, 3 tables, 10 figures; clarification added on the\n  baryogenesis calculation; version accepted for publication in Phys. Rev. D","journal-ref":null,"doi":"10.1103/PhysRevD.87.115019","report-no":"OSU-HEP-13-02, MAN/HEP/2012/017, UMD-PP-013-003","categories":"hep-ph hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A recently proposed scenario for baryogenesis, called post--sphaleron\nbaryogenesis (PSB) is discussed within a class of quark--lepton unified\nframework based on the gauge symmetry SU(2)_L x SU(2)_R x SU(4)_c realized in\nthe multi--TeV scale. The baryon asymmetry of the universe in this model is\nproduced below the electroweak phase transition temperature after the\nsphalerons have decoupled from the Hubble expansion. These models embed\nnaturally the seesaw mechanism for neutrino masses, and predict color-sextet\nscalar particles in the TeV range which may be accessible to the LHC\nexperiments. A necessary consequence of this scenario is the baryon number\nviolating \\Delta B=2 process of neutron--antineutron (n-\\bar{n}) oscillations.\nIn this paper we show that the constraints of PSB, when combined with the\nneutrino oscillation data and restrictions from flavor changing neutral\ncurrents mediated by the colored scalars imply an upper limit on the n-\\bar{n}\noscillation time of 5 x 10^{10} sec. regardless of the quark--lepton\nunification scale. If this scale is relatively low, in the (200-250) TeV range,\n\\tau_{n-\\bar{n}} is predicted to be less than 10^{10} sec., which is accessible\nto the next generation of proposed experiments.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:12:41 GMT"},{"version":"v2","created":"Thu, 6 Jun 2013 14:56:17 GMT"}],"update_date":"2013-06-26"}
{"id":"1303.6919","submitter":"Yao Tang","authors":"Yao Tang and Mai Vu","title":"A Partial Decode-Forward Scheme For A Network with N relays","comments":"Presented in 47th Annual Conference on Information Sciences and\n  Systems (CISS) 2013","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study a discrete-memoryless relay network consisting of one source, one\ndestination and N relays, and design a scheme based on partial decode-forward\nrelaying. The source splits its message into one common and N+1 private parts,\none intended for each relay. It encodes these message parts using Nth-order\nblock Markov coding, in which each private message part is independently\nsuperimposed on the common parts of the current and N previous blocks. Using\nsimultaneous sliding window decoding, each relay fully recovers the common\nmessage and its intended private message with the same block index, then\nforwards them to the following nodes in the next block. This scheme can be\napplied to any network topology. We derive its achievable rate in a compact\nform. The result reduces to a known decode-forward lower bound for an N-relay\nnetwork and partial decode-forward lower bound for a two-level relay network.\nWe then apply the scheme to a Gaussian two-level relay network and obtain its\ncapacity lower bound considering power constraints at the transmitting nodes.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:17:31 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6920","submitter":"Piotr Garbaczewski","authors":"Mariusz Zaba, Piotr Garbaczewski and Vladimir Stephanovich","title":"Trajectory statistics of confined L\\'{e}vy flights and Boltzmann-type\n  equilibria","comments":"Presented at 25th Marian Smoluchowski Symposium on Statistical\n  Physics, Cracow, Sept. 10-13, 2012","journal-ref":"Acta Phys. Pol. B 44, (2013), 1109-1122","doi":"10.5506/APhysPolB.44.1109","report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyze a specific class of random systems that are driven by a symmetric\nL\\'{e}vy stable noise, where Langevin representation is absent. In view of the\nL\\'{e}vy noise sensitivity to environmental inhomogeneities, the pertinent\nrandom motion asymptotically sets down at the Boltzmann-type equilibrium,\nrepresented by a probability density function (pdf) $\\rho_*(x) \\sim \\exp [-\\Phi\n(x)]$. Here, we infer pdf $\\rho (x,t)$ based on numerical path-wise simulation\nof the underlying jump-type process. A priori given data are jump transition\nrates entering the master equation for $\\rho (x,t)$ and its target pdf\n$\\rho_*(x)$. To simulate the above processes, we construct a suitable\nmodification of the Gillespie algorithm, originally invented in the chemical\nkinetics context. We exemplified our algorithm simulating different jump-type\nprocesses and discuss the dynamics of real physical systems where it can be\nuseful.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:24:57 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6921","submitter":"Satyabrata Patnaik","authors":"G. Sharma, J. Saha and S. Patnaik","title":"Magnetism driven ferroelectricity above liquid nitrogen temperature in\n  Y2CoMnO6","comments":null,"journal-ref":null,"doi":"10.1063/1.4812728","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report multiferroic behavior in double perovskite Y2CoMnO6 with\nferroelectric transition temperature Tc = 80K. The origin of ferroelectricity\nis associated with magnetic ordering of Co2+ and Mn4+ moments in a\nup-up-down-down arrangement. The saturation polarization and magnetization are\nestimated to be 65 uC/m2 and 6.2 Bohr magneton/f.u. respectively. The\nmagnetoelectric coupling parameter, on the other hand, is small as a 5 Tesla\nfield suppresses the electric polarization by only ~8%. This is corroborated\nwith observed hysteretic behaviour at 5K that remains unsaturated even upto 7\nTesla. A model based on exchange-striction is proposed to explain the observed\nhigh temperature ferroelectricity.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:29:49 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6922","submitter":"Cheng Yu","authors":"Dehua Wang and Cheng Yu","title":"Global weak solutions to the inhomogeneous Navier-Stokes-Vlasov\n  equations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A fluid-particle system of the inhomogeneous Navier-Stokes equations and\nVlasov equation in the three dimensional space is considered in this paper. The\ncoupling arises from the drag force in the fluid equations and the acceleration\nin the Vlasov equation. An initial-boundary value problem is studied in a\nbounded domain with large data. The existence of global weak solutions is\nestablished through an approximation scheme, energy estimates, and weak\nconvergence.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:32:20 GMT"},{"version":"v2","created":"Wed, 17 Apr 2013 03:41:05 GMT"}],"update_date":"2013-04-18"}
{"id":"1303.6923","submitter":"Fabien Casenave","authors":"Fabien Casenave, Alexandre Ern and Guillaume Sylvand","title":"Coupled BEM-FEM for the convected Helmholtz equation with non-uniform\n  flow in a bounded domain","comments":"23 pages, 9 figures","journal-ref":"J. Comput. Phys. 257 (2014), 627-644","doi":"10.1016/j.jcp.2013.10.016","report-no":null,"categories":"math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the convected Helmholtz equation modeling linear acoustic\npropagation at a fixed frequency in a subsonic flow around a scattering object.\nThe flow is supposed to be uniform in the exterior domain far from the object,\nand potential in the interior domain close to the object. Our key idea is the\nreformulation of the original problem using the Prandtl--Glauert transformation\non the whole flow domain, yielding (i) the classical Helmholtz equation in the\nexterior domain and (ii) an anisotropic diffusive PDE with skew-symmetric\nfirst-order perturbation in the interior domain such that its transmission\ncondition at the coupling boundary naturally fits the Neumann condition from\nthe classical Helmholtz equation. Then, efficient off-the-shelf tools can be\nused to perform the BEM-FEM coupling, leading to two novel variational\nformulations for the convected Helmholtz equation. The first formulation\ninvolves one surface unknown and can be affected by resonant frequencies, while\nthe second formulation avoids resonant frequencies and involves two surface\nunknowns. Numerical simulations are presented to compare the two formulations.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:46:43 GMT"},{"version":"v2","created":"Mon, 7 Oct 2013 13:27:52 GMT"},{"version":"v3","created":"Wed, 30 Oct 2013 16:28:24 GMT"}],"update_date":"2014-05-16"}
{"id":"1303.6924","submitter":"Elena Zaninoni","authors":"Elena Zaninoni, Maria Grazia Bernardini, Raffaella Margutti, Samantha\n  Oates, and Guido Chincarini","title":"Gamma-ray burst optical light-curve zoo: comparison with X-ray\n  observations","comments":"55 pages, 37 figures, accepted for publication in A&A (this version\n  includes changes made at Proofs stage)","journal-ref":null,"doi":"10.1051/0004-6361/201321221","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a comprehensive analysis of the optical and X-ray light curves\n(LCs) and spectral energy distributions (SEDs) of a large sample of gamma-ray\nburst (GRB) afterglows to investigate the relationship between the optical and\nX-ray emission after the prompt phase. We collected the optical data from the\nliterature and determined the shapes of the optical LCs. Then, using previously\npresented X-ray data we modeled the optical/X-ray SEDs. We studied the SED\nparameter distributions and compared the optical and X-ray LC slopes and\nshapes. The optical and X-ray spectra become softer as a function of time while\nthe gas-to-dust ratios of GRBs are higher than the values calculated for the\nMilky Way and the Large and Magellanic Clouds. For 20% of the GRBs the\ndifference between the optical and X-ray slopes is consistent with 0 or 1=4\nwithin the uncertainties (we did it not consider the steep decay phase), while\nin the remaining 80% the optical and X-ray afterglows show significantly\ndifferent temporal behaviors. Interestingly, we find an indication that the\nonset of the forward shock in the optical LCs (initial peaks or shallow phases)\ncould be linked to the presence of the X-ray flares. Indeed, when X-ray flares\nare present during the steep decay, the optical LC initial peak or end plateau\noccurs during the steep decay; if instead the X-ray flares are absent or occur\nduring the plateau, the optical initial peak or end plateau takes place during\nthe X-ray plateau. The forward-shock model cannot explain all features of the\noptical (e.g. bumps, late re-brightenings) and X-ray (e.g. flares, plateaus)\nLCs. However, the synchrotron model is a viable mechanism for GRBs at late\ntimes. In particular, we found a relationship between the presence of the X-ray\nflares and the shape of the optical LC that indicates a link between the prompt\nemission and the optical afterglow.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:46:52 GMT"},{"version":"v2","created":"Thu, 9 May 2013 20:25:28 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6925","submitter":"R\\'emi Lassalle Phd","authors":"R\\'emi Lassalle","title":"Causal transference plans and their Monge-Kantorovich problems","comments":"This is a preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper investigates causal optimal transportation problems, in the\nframework of two Polish spaces, both endowed with filtrations. Specific\nconcretizations yield primal problems equivalent to several classical problems\nof stochastic control, and of stochastic calculus ; trivial filtrations yield\nusual problems of optimal transport. Within this framework, primal attainments\nand dual formulations are obtained, under standard hypothesis, for the related\nvariational problems. These problems are intrinsically related to martingales.\nFinally, we investigate applications to stochastic frameworks. A\nstraightforward equivalence between specific causal optimization problems, and\nproblems of stochastic control, is obtained. Solutions to a class of stochastic\ndifferential equations are characterized, as optimum to specific causal\nMonge-Kantorovich problems ; the existence of a unique strong solution is\nrelated to corresponding Monge problems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:55:01 GMT"},{"version":"v2","created":"Fri, 2 Oct 2015 14:15:20 GMT"}],"update_date":"2015-10-05"}
{"id":"1303.6926","submitter":"Arun P V Arun P V","authors":"Dr. S.K. Katiyar, Arun P. V.","title":"A Comparative Analysis on the Applicability of Entropy in remote sensing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 18:57:12 GMT"}],"update_date":"2014-05-25"}
{"id":"1303.6927","submitter":"Arun P V Arun P V","authors":"Arun P. V., Dr. S.K. Katiyar","title":"An investigation towards wavelet based optimization of automatic image\n  registration techniques","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Image registration is the process of transforming different sets of data into\none coordinate system and is required for various remote sensing applications\nlike change detection, image fusion, and other related areas. The effect of\nincreased relief displacement, requirement of more control points, and\nincreased data volume are the challenges associated with the registration of\nhigh resolution image data. The objective of this research work is to study the\nmost efficient techniques and to investigate the extent of improvement\nachievable by enhancing them with Wavelet transform. The SIFT feature based\nmethod uses the Eigen value for extracting thousands of key points based on\nscale invariant features and these feature points when further enhanced by the\nwavelet transform yields the best results.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:02:02 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6928","submitter":"Blazenka Melic","authors":"Ernest Ma, Blazenka Melic","title":"Updated S3 Model of Quarks","comments":"14 pages, 2 figures","journal-ref":null,"doi":"10.1016/j.physletb.2013.07.015","report-no":"UCRHEP-T526","categories":"hep-ph hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A model proposed in 2004 using the non-Abelian discrete symmetry S3 for\nunderstanding the flavor structure of quarks and leptons is updated, with\nspecial focus on the quark and scalar sectors. We show how the approximate\nresidual symmetries of this model explain both the pattern of the quark mixing\nmatrix and why the recently observed particle of 126 GeV at the Large Hadron\nCollider is so much like the one Higgs boson of the Standard Model. We identify\nthe strongest phenomenological bounds on the scalar masses of this model, and\npredict a possibly observable decay b -> s tau- mu+, but not b -> s tau+ mu-.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:07:37 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6929","submitter":"Danning Li","authors":"Danning Li and Mei Huang","title":"Dynamical holographic QCD model for glueball and light meson spectra","comments":"49 pages, 23 figures, version accepted by JHEP","journal-ref":"JHEP11(2013)088","doi":"10.1007/JHEP11(2013)088","report-no":null,"categories":"hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we offer a dynamical soft-wall model to describe the\ngluodynamics and chiral dynamics in one systematical framework. We firstly\nconstruct a quenched dynamical holographic QCD (hQCD) model in the\ngraviton-dilaton framework for the pure gluon system, then develop a dynamical\nhQCD model for the two flavor system in the graviton-dilaton-scalar framework\nby adding light flavors on the gluodynamical background. For two forms of\ndilaton background field $\\Phi=\\mu_G^2z^2$ and\n$\\Phi=\\mu_G^2z^2\\tanh(\\mu_{G^2}^4z^2/\\mu_G^2)$, the quadratic correction to\ndilaton background field at infrared encodes important non-perturbative\ngluodynamics and naturally induces a deformed warp factor of the metric. By\nself-consistently solving the deformed metric induced by the dilaton background\nfield, we find that the scalar glueball spectra in the quenched dynamical model\nis in very well agreement with lattice data. For two flavor system in the\ngraviton-dilaton-scalar framework, the deformed metric is self-consistently\nsolved by considering both the chiral condensate and nonperturbative\ngluodynamics in the vacuum, which are responsible for the chiral symmetry\nbreaking and linear confinement, respectively. It is found that the mixing\nbetween the chiral condensate and gluon condensate is important to produce the\ncorrect light flavor meson spectra. The pion form factor and the vector\ncouplings are also investigated in the dynamical hQCD model. Besides, we give\nthe criteria for the existence of linear quark potential from the metric\nstructure, and show a negative quadratic dilaton background field is not\nfavored in the graviton-dilaton framework.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:08:22 GMT"},{"version":"v2","created":"Wed, 30 Oct 2013 01:41:57 GMT"}],"update_date":"2013-11-15"}
{"id":"1303.6930","submitter":"Edward Crane","authors":"Edward Crane","title":"Intrinsic circle domains","comments":"This version differs from version 1 only in the addition of a line to\n  say that the paper has been accepted for publication in Conformal Geometry\n  and Dynamics","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using quasiconformal mappings, we prove that any Riemann surface of finite\nconnectivity and finite genus is conformally equivalent to an intrinsic circle\ndomain U in a compact Riemann surface S. This means that each connected\ncomponent B of S \\ U is either a point or a closed geometric disc with respect\nto the complete constant curvature conformal metric of the Riemann surface (U\nunion B). Moreover the pair (U,S) is unique up to conformal isomorphisms. We\ngive a generalization to countably infinite connectivity. Finally we show how\none can compute numerical approximations to intrinsic circle domains using\ncircle packings and conformal welding.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:17:03 GMT"},{"version":"v2","created":"Mon, 4 Nov 2013 15:52:42 GMT"}],"update_date":"2013-11-05"}
{"id":"1303.6931","submitter":"Berthold Stech","authors":"Berthold Stech","title":"Degenerate states in the scalar boson spectrum. Is the Higgs Boson a\n  Twin ?","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The extension of the standard model to $SU(3)_L\\times SU(3)_R \\times SU(3)_C$\nis considered. Spontaneous symmetry breaking requires two $(3^*, 3, 1)$ Higgs\nfield multiplets with a strong hierarchical structure of their vacuum\nexpectation values. An invariant potential is constructed to provide for these\nvacuum expectation values. This potential gives masses to all scalar fields\napart from the 15 Goldstone bosons. In case there exists a one-to-one\ncorrespondence between the vacuum expectation values of the two field\nmultiplets, the scalar boson spectrum contains degenerate eigenstates. The\nlowest eigenstate has a mass near 123 GeV close to the Higgs-like particle\ndiscovered at the LHC. In one class of solutions this lowest state is a nearly\ndegenerate twin state. Each member is a superposition of fields from both\nmultiplets with about equal strength. The twins are non identical twins, namely\ndifferent combinations of a conventional Higgs and a Higgs field which is not\ncoupled to fermions, only to gauge bosons. A second class of solutions leads\nagain to degenerate states but in this case the state near 123 GeV remains a\nsingle state even for identical low scale vacuum expectation values in both\nmultiplets.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:17:33 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6933","submitter":"Alan Huckleberry","authors":"Alan Huckleberry","title":"Hans Grauert (1930-2011)","comments":"Written for publication in 2013 in the Jahresber. Deutsch.\n  Math.-Vereinigung","journal-ref":null,"doi":null,"report-no":null,"categories":"math.HO math.AG math.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hans Grauert died in September of 2011. This article reviews his life in\nmathematics and recalls some detail his major accomplishments.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:23:57 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6934","submitter":"Marta D'Elia","authors":"Marta D'Elia, Max Gunzburger","title":"The fractional Laplacian operator on bounded domains as a special case\n  of the nonlocal diffusion operator","comments":"27 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyze a nonlocal diffusion operator having as special cases the\nfractional Laplacian and fractional differential operators that arise in\nseveral applications. In our analysis, a nonlocal vector calculus is exploited\nto define a weak formulation of the nonlocal problem. We demonstrate that, when\nsufficient conditions on certain kernel functions hold, the solution of the\nnonlocal equation converges to the solution of the fractional Laplacian\nequation on bounded domains as the nonlocal interactions become infinite. We\nalso introduce a continuous Galerkin finite element discretization of the\nnonlocal weak formulation and we derive a priori error estimates. Through\nseveral numerical examples we illustrate the theoretical results and we show\nthat by solving the nonlocal problem it is possible to obtain accurate\napproximations of the solutions of fractional differential equations\ncircumventing the problem of treating infinite-volume constraints.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:31:58 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6935","submitter":"Xiaocheng  Tang","authors":"Xiaocheng Tang and Katya Scheinberg","title":"Efficiently Using Second Order Information in Large l1 Regularization\n  Problems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a novel general algorithm LHAC that efficiently uses second-order\ninformation to train a class of large-scale l1-regularized problems. Our method\nexecutes cheap iterations while achieving fast local convergence rate by\nexploiting the special structure of a low-rank matrix, constructed via\nquasi-Newton approximation of the Hessian of the smooth loss function. A greedy\nactive-set strategy, based on the largest violations in the dual constraints,\nis employed to maintain a working set that iteratively estimates the complement\nof the optimal active set. This allows for smaller size of subproblems and\neventually identifies the optimal active set. Empirical comparisons confirm\nthat LHAC is highly competitive with several recently proposed state-of-the-art\nspecialized solvers for sparse logistic regression and sparse inverse\ncovariance matrix selection.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:34:05 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6936","submitter":"Rui Mao","authors":"R. Mao, B. D. Kong, C. Gong, S. Xu, T. Jayasekera, K. Cho, K. W. Kim","title":"First-Principles Calculation of Thermal Transport in the Metal/Graphene\n  System","comments":null,"journal-ref":null,"doi":"10.1103/PhysRevB.87.165410","report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Thermal properties in the metal/graphene (Gr) systems are analyzed by using\nan atomistic phonon transport model based on Landauer formalism and\nfirst-principles calculations. The specific structures under investigation\ninclude chemisorbed Ni(111)/Gr, physisorbed Cu(111)/Gr and Au(111)/Gr, as well\nas Pd(111)/Gr with intermediate characteristics. Calculated results illustrate\na strong dependence of thermal transfer on the details of interfacial\nmicrostructures. In particular, it is shown that the chemisorbed case provides\na generally smaller interfacial thermal resistance than the physisorbed due to\nthe stronger bonding. However, our calculation also indicates that the weakly\nchemisorbed interface of Pd/Gr may be an exception, with the largest thermal\nresistance among the considered. Further examination of the electrostatic\npotential and interatomic force constants reveal that the mixed bonding force\nbetween the Pd and C atoms results in incomplete hybridization of Pd and\ngraphene orbital states at the junction, leading effectively to two phonon\ninterfaces and a larger than expected thermal resistance. Comparison with\navailable experimental data shows good agreement. The result clearly suggests\nthe feasibility of phonon engineering for thermal property optimization at the\ninterface.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:34:58 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6937","submitter":"Botong Wang","authors":"Botong Wang","title":"Cohomology jump loci of compact K\\\"ahler manifolds","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We apply the method of Dimca-Papadima to study the cohomology jump loci in\nthe representation variety and the moduli space of vector bundles with\nvanishing chern classes for a compact K\\\"ahler manifold. We introduce modules\nover differential graded Lie algebra to extend results of Dimca-Papadima to a\ngeneral point in the representation variety or the moduli space. We show that\nlocally the cohomology jump loci is isomorphic to the resonance variety via the\nexponential map. This paper generalizes a previous result of the author.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:10 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6938","submitter":"Pasi Jyl\\\"anki","authors":"Pasi Jyl\\\"anki, Aapo Nummenmaa and Aki Vehtari","title":"Expectation Propagation for Neural Networks with Sparsity-promoting\n  Priors","comments":null,"journal-ref":"Journal of Machine Learning Research, 15(May): 1849-1901, 2014","doi":null,"report-no":null,"categories":"stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a novel approach for nonlinear regression using a two-layer neural\nnetwork (NN) model structure with sparsity-favoring hierarchical priors on the\nnetwork weights. We present an expectation propagation (EP) approach for\napproximate integration over the posterior distribution of the weights, the\nhierarchical scale parameters of the priors, and the residual scale. Using a\nfactorized posterior approximation we derive a computationally efficient\nalgorithm, whose complexity scales similarly to an ensemble of independent\nsparse linear models. The approach enables flexible definition of weight priors\nwith different sparseness properties such as independent Laplace priors with a\ncommon scale parameter or Gaussian automatic relevance determination (ARD)\npriors with different relevance parameters for all inputs. The approach can be\nextended beyond standard activation functions and NN model structures to form\nflexible nonlinear predictors from multiple sparse linear models. The effects\nof the hierarchical priors and the predictive performance of the algorithm are\nassessed using both simulated and real-world data. Comparisons are made to two\nalternative models with ARD priors: a Gaussian process with a NN covariance\nfunction and marginal maximum a posteriori estimates of the relevance\nparameters, and a NN with Markov chain Monte Carlo integration over all the\nunknown model parameters.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:26 GMT"}],"update_date":"2015-01-23"}
{"id":"1303.6939","submitter":"Marco Stefano Bianchi","authors":"Marco S. Bianchi, Gaston Giribet, Matias Leoni and Silvia Penati","title":"The 1/2 BPS Wilson loop in ABJM theory at two loops","comments":"5 pages","journal-ref":null,"doi":"10.1103/PhysRevD.88.026009","report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We compute the expectation value of the 1/2 BPS circular Wilson loop in ABJM\ntheory at two loops in perturbation theory. The result shows perfect agreement\nwith the prediction from localization and the proposed framing factor.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:41 GMT"}],"update_date":"2013-08-09"}
{"id":"1303.6940","submitter":"Angnis Schmidt-May","authors":"S. F. Hassan, Angnis Schmidt-May, Mikael von Strauss","title":"Higher Derivative Gravity and Conformal Gravity From Bimetric and\n  Partially Massless Bimetric Theory","comments":"Latex, 34 pages; minor comments and note added, matches published\n  version","journal-ref":"Universe 2015, 1(2), 92-122","doi":"10.3390/universe1020092","report-no":null,"categories":"hep-th gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we establish the correspondence between ghost-free bimetric\ntheory and a class of higher derivative gravity actions, including conformal\ngravity and New Massive Gravity. We also characterize the relation between the\nrespective equations of motion and classical solutions. We illustrate that, in\nthis framework, the spin-2 ghost of higher derivative gravity is an artifact of\nthe truncation to a 4-derivative theory. The analysis also gives a relation\nbetween the proposed partially massless (PM) bimetric theory and conformal\ngravity, showing, in particular, the equivalence of their equations of motion\nat the 4-derivative level. For the PM bimetric theory this provides further\nevidence for the existence of an extra gauge symmetry and the associated loss\nof a propagating mode away from de Sitter backgrounds. The new symmetry is an\nextension of Weyl symmetry which also suggests the PM bimetric theory as a\nghost-free completion of conformal gravity.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:51 GMT"},{"version":"v2","created":"Thu, 23 Jul 2015 12:24:53 GMT"}],"update_date":"2015-07-24"}
{"id":"1303.6941","submitter":"Jim Hague","authors":"J.P. Hague","title":"Enhancement of gaps in thin graphitic films for heterostructure\n  formation","comments":"To appear in Phys. Rev. B","journal-ref":"Phys. Rev. B 89, 155415 (2014)","doi":"10.1103/PhysRevB.89.155415","report-no":null,"categories":"cond-mat.mes-hall cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There are a large number of atomically thin graphitic films with similar\nstructure to graphene. These films have a spread of bandgaps relating to their\nionicity, and also to the substrate on which they are grown. Such films could\nhave a range of applications in digital electronics where graphene is difficult\nto use. I use the dynamical cluster approximation to show how electron-phonon\ncoupling between film and substrate can enhance these gaps in a way that\ndepends on the range and strength of the coupling. One of the driving factors\nin this effect is the proximity to a charge density wave instability for\nelectrons on a honeycomb lattice. The enhancement at intermediate coupling is\nsufficiently large that spatially varying substrates and superstrates could be\nused to create heterostructures in thin graphitic films with position dependent\nelectron-phonon coupling and gaps, leading to advanced electronic components.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:05 GMT"},{"version":"v2","created":"Fri, 21 Jun 2013 13:48:10 GMT"},{"version":"v3","created":"Thu, 27 Mar 2014 10:42:05 GMT"}],"update_date":"2014-04-28"}
{"id":"1303.6942","submitter":"Benjamin Hunt","authors":"B. Hunt, J. D. Sanchez-Yamagishi, A. F. Young, K. Watanabe, T.\n  Taniguchi, P. Moon, M. Koshino, P. Jarillo-Herrero and R. C. Ashoori","title":"Massive Dirac fermions and Hofstadter butterfly in a van der Waals\n  heterostructure","comments":"6+11 pages, 4 figures main text, 15 figures supplementary text","journal-ref":"Science Online, May 16 2013","doi":"10.1126/science.1237240","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Van der Waals heterostructures comprise a new class of artificial materials\nformed by stacking atomically-thin planar crystals. Here, we demonstrate band\nstructure engineering of a van der Waals heterostructure composed of a\nmonolayer graphene flake coupled to a rotationally-aligned hexagonal boron\nnitride substrate. The spatially-varying interlayer atomic registry results\nboth in a local breaking of the carbon sublattice symmetry and a long-range\nmoir\\'e superlattice potential in the graphene. This interplay between short-\nand long-wavelength effects results in a band structure described by isolated\nsuperlattice minibands and an unexpectedly large band gap at charge neutrality,\nboth of which can be tuned by varying the interlayer alignment.\nMagnetocapacitance measurements reveal previously unobserved fractional quantum\nHall states reflecting the massive Dirac dispersion that results from broken\nsublattice symmetry. At ultra-high fields, integer conductance plateaus are\nobserved at non-integer filling factors due to the emergence of the Hofstadter\nbutterfly in a symmetry-broken Landau level.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:42 GMT"}],"update_date":"2013-05-22"}
{"id":"1303.6943","submitter":"Wenqing Hu","authors":"Mark Freidlin, Wenqing Hu","title":"Wave front propagation for a reaction-diffusion equation in narrow\n  random channels","comments":"31 pages, 1 figure, revised version. arXiv admin note: text overlap\n  with arXiv:1210.5226","journal-ref":"Nonlinearity, 26, 8, 2013, pp. 2333--2356","doi":"10.1088/0951-7715/26/8/2333","report-no":null,"categories":"math.PR math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a reaction-diffusion equation in narrow random channels. We\napproximate the generalized solution to this equation by the corresponding one\non a random graph. By making use of large deviation analysis we study the\nasymptotic wave front propagation.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:26 GMT"},{"version":"v2","created":"Thu, 20 Jun 2013 16:33:58 GMT"}],"update_date":"2013-07-15"}
{"id":"1303.6944","submitter":"Pedro Miana","authors":"Valentin Keyantuo, Pedro J. Miana and Luis S\\'anchez-Lajusticia","title":"Sharp extensions for convoluted solutions of abstract Cauchy problems","comments":"24 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we give sharp extension results for convoluted solutions of\nabstract Cauchy problems in Banach spaces. The main technique is the use of\nalgebraic structure (for usual convolution product $\\ast$) of these solutions\nwhich are defined by a version of the Duhamel formula. We define algebra\nhomomorphisms from a new class of test-functions and apply our results to\nconcrete operators. Finally, we introduce the notion of $k$-distribution\nsemigroups to extend previous concepts of distribution semigroups.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:27 GMT"}],"update_date":"2013-03-28"}
{"id":"1303.6946","submitter":"Oktay Mukhtarov","authors":"O. Sh. Mukhtarov and K. Aydemir","title":"Asymptotic properties of boundary-value problem with transmission\n  conditions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this study by applying an own technique we investigate some asymptotic\napproximation properties of new type discontinuous boundary-value problems,\nwhich consists of a Sturm-Liouville equation together with\neigenparameter-dependent boundary and transmission conditions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 16:54:21 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6947","submitter":"Oktay Mukhtarov","authors":"K. Aydemir and O. Sh. Mukhtarov","title":"Boundary value problem with transmission conditions","comments":"arXiv admin note: substantial text overlap with arXiv:1303.6898","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One important innovation here is that for the Sturm-Liouville considered\nequation together with eigenparameter dependent boundary conditions and two\nsupplementary transmission conditions at one interior point. We develop Green's\nfunction method for spectral analysis of the considered problem in modified\nHilbert space.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:06:58 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6948","submitter":"Oktay Mukhtarov","authors":"O. Sh. Mukhtarov and K. Aydemir","title":"Asymptotic formulas for eigenvalues and eigenfunctions of boundary value\n  problem","comments":"arXiv admin note: substantial text overlap with arXiv:1303.6888","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we are concerned with a new class of BVP' s consisting of\neigendependent boundary conditions and two supplementary transmission\nconditions at one interior point. By modifying some techniques of classical\nSturm-Liouville theory and suggesting own approaches we find asymptotic\nformulas for the eigenvalues and eigenfunction.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 17:11:28 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6949","submitter":"Donghui Jeong","authors":"Liang Dai, Donghui Jeong, Marc Kamionkowski and Jens Chluba","title":"The Pesky Power Asymmetry","comments":"5 pages, 4 figures","journal-ref":null,"doi":"10.1103/PhysRevD.87.123005","report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Physical models for the hemispherical power asymmetry in the cosmic microwave\nbackground (CMB) reported by the Planck Collaboration must satisfy CMB\nconstraints to the homogeneity of the Universe and quasar constraints to power\nasymmetries. We survey a variety of models for the power asymmetry and show\nthat consistent models include a modulated scale-dependent isocurvature\ncontribution to the matter power spectrum or a modulation of the reionization\noptical depth, gravitational-wave amplitude, or scalar spectral index. We\npropose further tests to distinguish between the different scenarios.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:01 GMT"}],"update_date":"2013-06-26"}
{"id":"1303.6950","submitter":"Garrett Hickman","authors":"G. T. Hickman, Xin Wang, J. P. Kestner, and S. Das Sarma","title":"Dynamically corrected gates for an exchange-only qubit","comments":"5 pages, 3 figures, + 5 pages supplemental information","journal-ref":"Phys. Rev. B 88, 161303(R) (2013)","doi":"10.1103/PhysRevB.88.161303","report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We provide analytical composite pulse sequences that perform dynamical\ndecoupling concurrently with arbitrary rotations for a qubit coded in the spin\nstate of a triple quantum dot. The sequences are designed to respect realistic\nexperimental constraints such as strictly nonnegative couplings. Logical errors\nand leakage errors are simultaneously corrected. A short pulse sequence is\npresented to compensate nuclear noise and a longer sequence is presented to\nsimultaneously compensate nuclear and charge noise. The capability developed in\nthis work provides a clear prescription for combatting the relevant sources of\nnoise that currently hinder exchange-only qubit experiments.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:01 GMT"},{"version":"v2","created":"Wed, 23 Oct 2013 15:55:48 GMT"}],"update_date":"2013-10-24"}
{"id":"1303.6951","submitter":"Tullia Sbarrato","authors":"T. Sbarrato, G. Ghisellini, M. Nardini, G. Tagliaferri, J. Greiner, A.\n  Rau, P. Schady","title":"Blazar candidates beyond redshift 4 observed with GROND","comments":"12 pages, 10 figures, 4 tables. Accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stt882","report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The search for extremely massive high redshift blazars is essential to put\nstrong constraints on the supermassive black holes formation theories. Up to\nnow, the few blazars known to have a redshift larger than 4 have been\ndiscovered serendipitously. We try a more systematic approach. Assuming\nradio-loudness as a proxy for the jet orientation, we select a sample of\nextremely radio-loud quasars. We measure their black hole masses with a method\nbased on fitting the thermal emission from the accretion disc. We achieve a\nprecision of a factor of two for our measures, thanks to the observations\nperformed with the Gamma-Ray Burst Optical Near-Infrared Detector (GROND). The\ninfrared to optical GROND data allow us to observe directly the peak of the\ndisc emission, thus constraining the overall disc luminosity. We obtain a small\nrange of masses, that peaks at 10^{9.3}Msun. If some of our candidates will be\nconfirmed as blazars, these results would introduce interesting constraints on\nthe mass function of extremely massive black holes at very high redshift.\nMoreover, all our blazar candidates have high accretion rates. This result,\nalong with the high masses, opens an interesting view on the need of a fast\ngrowth of the heaviest black holes at very high redshift.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:01 GMT"},{"version":"v2","created":"Thu, 16 May 2013 10:34:42 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6952","submitter":"Daekyoung Kang","authors":"Daekyoung Kang, Christopher Lee, and Iain W. Stewart","title":"Using 1-Jettiness to Measure 2 Jets in DIS 3 Ways","comments":"53 pages, 13 figures, 3 tables. Version published in Physical Review\n  D","journal-ref":"Phys.Rev.D88:054004,2013","doi":"10.1103/PhysRevD.88.054004","report-no":"MIT-CTP 4375, LA-UR-13-20960","categories":"hep-ph hep-ex nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We predict cross sections in deep inelastic scattering (DIS) for the\nproduction of two jets---one along the proton beam direction created by initial\nstate radiation (ISR) and another created by final state radiation after the\nhard collision. Our results include fixed order corrections and a summation of\nlarge logarithms up to next-to-next-to-leading logarithmic (NNLL) accuracy in\nresummed perturbation theory. We make predictions for three versions of a DIS\nevent shape 1-jettiness, each of which constrains hadronic final states to be\nwell collimated into two jets along the beam and final-state jet directions,\nbut which differ in their sensitivity to the transverse momentum of the ISR\nfrom the proton beam. We use the tools of soft collinear effective theory\n(SCET) to derive factorization theorems for these three versions of\n1-jettiness. The sensitivity to the ISR gives rise to significantly different\nstructures in the corresponding factorization theorems---for example,\ndependence on either the ordinary or the generalized kperp-dependent beam\nfunction. Despite the differences among 1-jettiness definitions, we show that\nthe leading nonperturbative correction that shifts the tail region of their\ndistributions is given by a single universal nonperturbative parameter Omega1,\neven accounting for hadron mass effects. Finally, we give numerical results for\nQ^2 and x values explored at the HERA collider, emphasizing that the target of\nour factorization-based analyses is to open the door for higher-precision jet\nphenomenology in DIS.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:02 GMT"},{"version":"v2","created":"Wed, 11 Sep 2013 18:09:44 GMT"}],"update_date":"2013-09-12"}
{"id":"1303.6953","submitter":"Vincenzo Cirigliano","authors":"Vincenzo Cirigliano, Susan Gardner, Barry Holstein","title":"Beta Decays and Non-Standard Interactions in the LHC Era","comments":"To appear in Prog. Part. Nucl. Phys","journal-ref":null,"doi":"10.1016/j.ppnp.2013.03.005","report-no":null,"categories":"hep-ph nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the role of precision measurements of beta decays and light meson\nsemi-leptonic decays in probing physics beyond the Standard Model in the LHC\nera. We describe all low-energy charged-current processes within and beyond the\nStandard Model using an effective field theory framework. We first discuss the\ntheoretical hadronic input which in these precision tests plays a crucial role\nin setting the baseline for new physics searches. We then review the current\nand upcoming constraints on the various non-standard operators from the study\nof decay rates, spectra, and correlations in a broad array of light-quark\nsystems. We finally discuss the interplay with LHC searches, both within models\nand in an effective theory approach. Our discussion illustrates the independent\nyet complementary nature of precision beta decay measurements as probes of new\nphysics, showing them to be of continuing importance throughout the LHC era.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:02 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6954","submitter":"Adrian Del Maestro","authors":"B. Kulchytskyy, G. Gervais, and A. Del Maestro","title":"Local Superfluidity at the Nanoscale","comments":"Added a figure and extended discussion","journal-ref":"Physical Review B 88, 064512 (2013)","doi":"10.1103/PhysRevB.88.064512","report-no":null,"categories":"cond-mat.mes-hall cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We have performed quantum Monte Carlo simulations measuring the finite size\nand temperature superfluid response of helium-4 to the linear and rotational\nmotion of the walls of a nanopore. Within the two-fluid model, the portion of\nthe normal liquid dragged along with the boundaries is dependent on the type of\nmotion and the resulting anisotropic superfluid density saturates far below\nunity at T=0.5 K. The origin of the saturation is uncovered by computing the\nspatial distribution of superfluidity, with only the core of the nanopore\nexhibiting any evidence of phase coherence. The superfluid core displays\nscaling behavior consistent with Luttinger liquid theory, thereby providing an\nexperimental test for the emergence of a one dimensional quantum liquid.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:04 GMT"},{"version":"v2","created":"Tue, 3 Sep 2013 01:06:36 GMT"}],"update_date":"2013-09-04"}
{"id":"1303.6955","submitter":"Thomas Hartman","authors":"Thomas Hartman","title":"Entanglement Entropy at Large Central Charge","comments":"28 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Two-dimensional conformal field theories with a large central charge and a\nsmall number of low-dimension operators are studied using the conformal block\nexpansion. A universal formula is derived for the Renyi entropies of N disjoint\nintervals in the ground state, valid to all orders in a series expansion. This\nis possible because the full perturbative answer in this regime comes from the\nexchange of the stress tensor and other descendants of the vacuum state.\nTherefore, the Renyi entropy is related to the Virasoro vacuum block at large\ncentral charge. The entanglement entropy, computed from the Renyi entropy by an\nanalytic continuation, decouples into a sum of single-interval entanglements.\nThis field theory result agrees with the Ryu-Takayanagi formula for the\nholographic entanglement entropy of a 2d CFT, applied to any number of\nintervals, and thus can be interpreted as a microscopic calculation of the area\nof minimal surfaces in 3d gravity.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:05 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6956","submitter":"Andrew Potter","authors":"Andrew C. Potter and Patrick A. Lee","title":"Edge-Ferromagnetism from Majorana Flat-Bands: Application to Split\n  Tunneling-Conductance Peaks in the High-Tc Cuprates","comments":"10 pages, 5 figures","journal-ref":"Phys. Rev. Lett. 112, 117002 (2014)","doi":"10.1103/PhysRevLett.112.117002","report-no":null,"categories":"cond-mat.supr-con cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In mean-field descriptions of nodal d-wave superconductors, generic edges\nexhibit dispersionless Majorana fermion bands at zero-energy. These states give\nrise to an extensive ground-state degeneracy, and are protected by\ntime-reversal (TR) symmetry. We argue that the infinite density of states of\nthese flat-bands make them inherently unstable to interactions, and show that\nrepulsive interactions lead to edge FM which splits the flat bands. This edge\nFM offers an explanation for the observation of splitting of zero-bias peaks in\nedge tunneling in High-Tc cuprate superconductors. We argue that this mechanism\nfor splitting is more likely than previously proposed scenarios, and describe\nits experimental consequences.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:06 GMT"}],"update_date":"2014-03-26"}
{"id":"1303.6957","submitter":"Jennifer Yee","authors":"J.C. Yee (The Ohio State University)","title":"WFIRST Planet Masses from Microlens Parallax","comments":"11 pages, 2 figures. Replaced 10/10/13 to reflect the version\n  published in ApJL","journal-ref":null,"doi":"10.1088/2041-8205/770/2/L31","report-no":null,"categories":"astro-ph.EP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  I present a method using only a few ground-based observations of magnified\nmicrolensing events to routinely measure the parallaxes of WFIRST events if\nWFIRST is in an L2 orbit. This could be achieved for all events with Amax > 30\nusing target-ofopportunity observations of select WFIRST events, or with a\ncomplementary, ground-based survey of the WFIRST field, which can push beyond\nthis magnification limit. When combined with a measurement of the angular size\nof the Einstein ring, which is almost always measured in planetary events,\nthese parallax measurements will routinely give measurements of the lens masses\nand hence, the absolute masses of the planets. They can also lead to mass\nmeasurements for dark, isolated objects such as brown dwarfs, free-floating\nplanets, and stellar remnants if the size of the Einstein ring is measured.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:06 GMT"},{"version":"v2","created":"Thu, 10 Oct 2013 16:14:04 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6958","submitter":"Tony Pan","authors":"Tony Pan, Daniel J. Patnaude, Abraham Loeb","title":"Super-luminous X-ray Emission from the Interaction of Supernova Ejecta\n  with Dense Circumstellar Shells","comments":"Submitted to MNRAS. 12 pages, 4 figures","journal-ref":null,"doi":"10.1093/mnras/stt780","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For supernova powered by the conversion of kinetic energy into radiation due\nto the interactions of the ejecta with a dense circumstellar shell, we show\nthat there could be X-ray analogues of optically super-luminous SNe with\ncomparable luminosities and energetics. We consider X-ray emission from the\nforward shock of SNe ejecta colliding into an optically-thin CSM shell, derive\nsimple expressions for the X-ray luminosity as a function of the circumstellar\nshell characteristics, and discuss the different regimes in which the shock\nwill be radiative or adiabatic, and whether the emission will be dominated by\nfree-free radiation or line-cooling. We find that even with normal supernova\nexplosion energies of 10^51 erg, there exists CSM shell configurations that can\nliberate a large fraction of the explosion energy in X-rays, producing\nunabsorbed X-ray luminosities approaching 10^44 erg/s events lasting a few\nmonths, or even 10^45 erg/s flashes lasting days. Although the large column\ndensity of the circumstellar shell can absorb most of the flux from the initial\nshock, the most luminous events produce hard X-rays that are less susceptible\nto photoelectric absorption, and can counteract such losses by completely\nionizing the intervening material. Regardless, once the shock traverses the\nentire circumstellar shell, the full luminosity could be available to\nobservers.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:08 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6959","submitter":"Daniel Angl\\'es-Alc\\'azar","authors":"Daniel Angl\\'es-Alc\\'azar (1), Romeel Dav\\'e (1 and 2), Feryal \\\"Ozel\n  (1), Benjamin D. Oppenheimer (3) ((1) Arizona, (2) Cape Town, (3) Leiden)","title":"Cosmological Zoom Simulations of z = 2 Galaxies: The Impact of Galactic\n  Outflows","comments":"22 pages, 13 figures, ApJ accepted","journal-ref":null,"doi":"10.1088/0004-637X/782/2/84","report-no":null,"categories":"astro-ph.CO astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use high-resolution cosmological zoom simulations with ~200 pc resolution\nat z = 2 and various prescriptions for galactic outflows in order to explore\nthe impact of winds on the morphological, dynamical, and structural properties\nof eight individual galaxies with halo masses ~ 10^11--2x10^12 Msun at z = 2.\nWe present a detailed comparison to spatially and spectrally resolved H{\\alpha}\nand other observations of z ~ 2 galaxies. We find that simulations without\nwinds produce massive, compact galaxies with low gas fractions, super-solar\nmetallicities, high bulge fractions, and much of the star formation\nconcentrated within the inner kpc. Strong winds are required to maintain high\ngas fractions, redistribute star-forming gas over larger scales, and increase\nthe velocity dispersion of simulated galaxies, more in agreement with the\nlarge, extended, turbulent disks typical of high-redshift star-forming\ngalaxies. Winds also suppress early star formation to produce high-redshift\ncosmic star formation efficiencies in better agreement with observations.\nSizes, rotation velocities, and velocity dispersions all scale with stellar\nmass in accord with observations. Our simulations produce a diversity of\nmorphological characteristics - among our three most massive galaxies, we find\na quiescent grand-design spiral, a very compact star-forming galaxy, and a\nclumpy disk undergoing a minor merger; the clumps are evident in H{\\alpha} but\nnot in the stars. Rotation curves are generally slowly rising, particularly\nwhen calculated using azimuthal velocities rather than enclosed mass. Our\nresults are broadly resolution-converged. These results show that cosmological\nsimulations including outflows can produce disk galaxies similar to those\nobserved during the peak epoch of cosmic galaxy growth.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:08 GMT"},{"version":"v2","created":"Fri, 3 Jan 2014 22:00:03 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6960","submitter":"Tony Pan","authors":"Tony Pan, Abraham Loeb","title":"Finding Core Collapse Supernova from the Epoch of Reionization Behind\n  Cluster Lenses","comments":"Submitted to MNRAS Letters. 5 pages, 5 figures","journal-ref":null,"doi":"10.1093/mnrasl/slt089","report-no":null,"categories":"astro-ph.HE astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current surveys are underway to utilize gravitational lensing by galaxy\nclusters with Einstein radii >35\" in the search for the highest redshift\ngalaxies. Associated supernova from the epoch of reionization would have their\nfluxes boosted above the detection threshold, extending their duration of\nvisibility. We predict that the James Webb Space Telescope (JWST) will be able\nto discover lensed core-collapse supernovae at redshifts exceeding z=7-8.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:11 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6961","submitter":"Simon Portegies Zwart","authors":"Edward P. J. van den Heuvel (Amsterdam), Simon Portegies Zwart\n  (Sterrewacht Leiden)","title":"Are Super-Luminous supernovae and Long GRBs produced exclusively in\n  young dense star clusters?","comments":"ApJ (23 pages, in press)","journal-ref":null,"doi":"10.1088/0004-637X/779/2/114","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Super Luminous supernovae (SLSN) occur almost exclusively in small galaxies\n(SMC/LMC-like or smaller), and the few SLSN observed in larger star-forming\ngalaxies always occur close to the nuclei of their hosts. Another type of\npeculiar and highly energetic supernovae are the broad-line type Ic SNe (SN\nIc-BL) that are associated with long-duration gamma-ray bursts (LGRBs). Also\nthese have a strong preference for occurring in small (SMC/LMC-like or smaller)\nstar-forming galaxies, and in these galaxies LGRBs always occur in the\nbrightest spots. Studies of nearby star-forming galaxies that are similar to\nthe hosts of LGRBs show that these brightest spots are giant HII regions\nproduced by massive dense young star clusters with many hundreds of O- and\nWolf-Rayet-type stars. Such dense young clusters are also found in abundance\nwithin a few hundred parsecs from the nucleus of larger galaxies like our own.\nWe argue that the SLSN and the SN Ic-BL/LGRBs are exclusive products of two\ntypes of dynamical interactions in dense young star clusters. In our model the\nhigh angular momentum of the collapsing stellar cores required for the\n\"engines\" of a SN Ic-BL results from the post-main sequence mergers of\ndynamically produced cluster binaries with almost equal-mass components. The\nmerger produces a critically rotating single helium star with sufficent angular\nmomentum to produce a LGRB; the observed \"metal aversio\" of LGRBs is a natural\nconsequence of the model. We argue that, on the other hand, SLSN could be the\nproducts of runaway multiple collisions in dense clusters, and we present (and\nquantize) plausible scenarios of how the different types of SLSNs can be\nproduced.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:12 GMT"},{"version":"v2","created":"Mon, 28 Oct 2013 03:07:08 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6962","submitter":"Lawrence Hall","authors":"L. J. Hall and G. G. Ross","title":"Discrete Symmetries and Neutrino Mass Perturbations for \\theta_{13}","comments":"20 pages","journal-ref":null,"doi":"10.1007/JHEP11(2013)091","report-no":"CERN-PH-TH/2012-175","categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent measurement of the third lepton mixing angle, \\theta_{13}, has\nshown that, although small compared to \\theta_{12} and \\theta_{23}, it is much\nlarger than anticipated in schemes that generate Tri-Bi-Maximal (TBM) or Golden\nRatio (GR) mixing. We develop a model-independent formalism for perturbations\naway from exact TBM or GR mixing in the neutrino sector. Each resulting\nperturbation scheme reflects an underlying symmetry structure and involves a\nsingle complex parameter. We show that such perturbations can readily fit the\nobserved value of \\theta_{13}, which is then correlated with a change in the\nother mixing angles. We also determine the implication for the lepton CP\nviolating phases. For comparison we determine the predictions for Bi-Maximal\nmixing corrected by charged lepton mixing and we discuss the accuracy that will\nbe needed to distinguish between the various schemes.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:12 GMT"},{"version":"v2","created":"Sat, 2 Nov 2013 01:56:11 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6963","submitter":"Bela Bauer","authors":"Bela Bauer and Brendan P. Keller and Michele Dolfi and Simon Trebst\n  and Andreas W. W. Ludwig","title":"Gapped and gapless spin liquid phases on the Kagome lattice from chiral\n  three-spin interactions","comments":"5+5 pages, 6+6 figures. Manuscript partially superseded by\n  arXiv:1401.3017","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We argue that a relatively simple model containing only SU(2)-invariant\nchiral three-spin interactions on a Kagome lattice of S=1/2 spins can give rise\nto both a gapped and a gapless quantum spin liquid. Our arguments are rooted in\na formulation in terms of network models of edge states and are backed up by a\ncareful numerical analysis. For a uniform choice of chirality on the lattice,\nwe realize the Kalmeyer-Laughlin state, i.e. a gapped spin liquid which is\nidentified as the nu=1/2 bosonic Laughlin state. For staggered chiralities, a\ngapless spin liquid emerges which exhibits gapless spin excitations along lines\nin momentum space, a feature that we probe by studying quasi-two-dimensional\nsystems of finite width. We thus provide a single, appealingly simple spin\nmodel (i) for what is probably the simplest realization of the\nKalmeyer-Laughlin state to date, as well as (ii) for a non-Fermi liquid state\nwith lines of gapless SU(2) spin excitations.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:00:12 GMT"},{"version":"v2","created":"Sun, 7 Sep 2014 18:15:38 GMT"}],"update_date":"2014-09-09"}
{"id":"1303.6964","submitter":"Muhammad Adeel Ajaib","authors":"M. Adeel Ajaib, Ilia Gogoladze, Qaisar Shafi and Cem Salih Un","title":"A Predictive Yukawa Unified SO(10) Model: Higgs and Sparticle Masses","comments":"27 pages, 9 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:1112.2206","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We revisit a class of supersymmetric SO(10) models with t-b-tau Yukawa\ncoupling unification condition, with emphasis on the prediction of the Higgs\nmass. We discuss qualitative features in this model that lead to a Higgs mass\nprediction close to 125 GeV. We show this with two distinct computing packages,\nIsajet and SuSpect, and also show that they yield similar global features in\nthe parameter space of this model. We find that t-b-tau Yukawa coupling\nunification prefers values of the CP-odd Higgs mass m_{A} to be around 600 GeV,\nwith all colored sparticle masses above 3 TeV. We also briefly discuss\nprospects for testing this scenario with the ongoing and planned direct dark\nmatter detection experiments. In this class of models with t-b-tau Yukawa\nunification, the neutralino dark matter particle is heavy\n(m_{\\tilde{\\chi}_1^{0}} \\gtrsim 400 \\rm \\ GeV), which coannihilates with a stau\nto yield the correct relic abundance.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:01:41 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6965","submitter":"Canran Xu","authors":"Canran Xu and Maxim G. Vavilov","title":"Full Counting Statistics of Photons Emitted by Double Quantum Dot","comments":"9 pages, 7 figures","journal-ref":"Phys. Rev. B 88, 195307 (2013)","doi":"10.1103/PhysRevB.88.195307","report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyze the full counting statistics of photons emitted by a double\nquantum dot (DQD) coupled to a high-quality microwave resonator by electric\ndipole interaction. We show that at the resonant condition between the energy\nsplitting of the DQD and the photon energy in the resonator, photon statistics\nexhibits both a sub-Poissonian distribution and antibunching. In the ideal\ncase, when the system decoherence stems only from photodetection, the photon\nnoise is reduced below one-half of the noise for the Poisson distribution and\nis consistent with current noise. The photon distribution remains\nsub-Poissonian even at moderate decoherence in the DQD. We demonstrate that\nJosephson junction based photomultipliers can be used to experimentally assess\nstatistics of emitted photons.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:02:08 GMT"},{"version":"v2","created":"Thu, 21 Nov 2013 22:43:28 GMT"}],"update_date":"2013-11-25"}
{"id":"1303.6966","submitter":"John O. Dabiri","authors":"John O. Dabiri, Sanjeeb Bose, Brad J. Gemmell, Sean P. Colin, and John\n  H. Costello","title":"An algorithm to estimate unsteady and quasi-steady pressure fields from\n  velocity field measurements","comments":"A free MATLAB implementation of this algorithm is available at\n  http://dabiri.caltech.edu/software.html","journal-ref":"Journal of Experimental Biology (2014) 217: 331-336","doi":"10.1242/jeb.092767","report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe and characterize a method for estimating the pressure field\ncorresponding to velocity field measurements, such as those obtained by using\nparticle image velocimetry. The pressure gradient is estimated from a time\nseries of velocity fields for unsteady calculations or from a single velocity\nfield for quasi-steady calculations. The corresponding pressure field is\ndetermined based on median polling of several integration paths through the\npressure gradient field in order to reduce the effect of measurement errors\nthat accumulate along individual integration paths. Integration paths are\nrestricted to the nodes of the measured velocity field, thereby eliminating the\nneed for measurement interpolation during this step and significantly reducing\nthe computational cost of the algorithm relative to previous approaches. The\nmethod is validated by using numerically-simulated flow past a stationary,\ntwo-dimensional bluff body and a computational model of a three-dimensional,\nself-propelled anguilliform swimmer to study the effects of spatial and\ntemporal resolution, domain size, signal-to-noise ratio, and out-of-plane\neffects. Particle image velocimetry measurements of a freely-swimming jellyfish\nmedusa and a freely-swimming lamprey are analyzed using the method to\ndemonstrate the efficacy of the approach when applied to empirical data.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:04:46 GMT"},{"version":"v2","created":"Mon, 20 Jan 2014 23:58:13 GMT"}],"update_date":"2014-01-22"}
{"id":"1303.6967","submitter":"Elizabeth Adams","authors":"Elizabeth A. K. Adams, Riccardo Giovanelli, Martha P. Haynes","title":"A Catalog of Ultra-compact High Velocity Clouds from the ALFALFA Survey:\n  Local Group Galaxy Candidates?","comments":"24 pages, 16 figures, published in ApJ, article updated for\n  corrections to published version","journal-ref":"Elizabeth A. K. Adams et al. 2013 ApJ, 768, 77","doi":"10.1088/0004-637X/768/1/77","report-no":null,"categories":"astro-ph.CO astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a catalog of 59 ultra-compact high velocity clouds (UCHVCs)\nextracted from the 40% complete ALFALFA HI-line survey. The ALFALFA UCHVCs have\nmedian flux densities of 1.34 Jy km/s, median angular diameters of 10', and\nmedian velocity widths of 23 km/s. We show that the full UCHVC population\ncannot easily be associated with known populations of high velocity clouds. Of\nthe 59 clouds presented here, only 11 are also present in the compact cloud\ncatalog extracted from the commensal GALFA-HI survey, demonstrating the utility\nof this separate dataset and analysis. Based on their sky distribution and\nobserved properties, we infer that the ALFALFA UCHVCs are consistent with the\nhypothesis that they may be very low mass galaxies within the Local Volume. In\nthat case, most of their baryons would be in the form of gas, and because of\ntheir low stellar content, they remain unidentified by extant optical surveys.\nAt distances of ~1 Mpc, the UCHVCs have neutral hydrogen (HI) masses of ~10^5\n-10^6 M_sun, HI diameters of ~2-3 kpc, and indicative dynamical masses within\nthe HI extent of ~10^7 - 10^8 M_sun, similar to the Local Group ultra-faint\ndwarf Leo T. The recent ALFALFA discovery of the star-forming, metal-poor, low\nmass galaxy Leo P demonstrates that this hypothesis is true in at least one\ncase. In the case of the individual UCHVCs presented here, confirmation of\ntheir extragalactic nature will require further work, such as the\nidentification of an optical counterpart to constrain their distance.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:05:06 GMT"},{"version":"v2","created":"Wed, 17 Apr 2013 14:45:42 GMT"}],"update_date":"2013-04-18"}
{"id":"1303.6968","submitter":"Deatrick Foster","authors":"D. L. Foster (1 and 2), P. A. Charles (3), D. A. Swartz (4), R. Misra\n  (5), and K. G. Stassun (2 and 6) ((1) SAAO, (2) Vanderbilt U., (3) U. of\n  Southampton, (4) USRA, NASA MSFC, (5) IUCAA, (6) Fisk U.)","title":"Monitoring the Very-Long-Term Variability of X-ray Sources in the Giant\n  Elliptical Galaxy M87","comments":"19 pages, 19 figures, 1 table, Accepted for publication in MNRAS.\n  Updated to correct typos in previous version","journal-ref":null,"doi":"10.1093/mnras/stt557","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report on our search for very-long-term variability (weeks to years) in\nX-ray binaries (XRBs) in the giant elliptical galaxy M87. We have used archival\nChandra imaging observations to characterise the long-term variability of 8 of\nthe brightest members of the XRB population in M87. The peak brightness of some\nof the sources exceeded the ultra luminous X-ray source (ULX) threshold\nluminosity of ~ 10^{39} erg/s, and one source could exhibit dips or eclipses.\nWe show that for one source, if it has similar modulation amplitude as in\nSS433, then period recoverability analysis on the current data would detect\nperiodic modulations, but only for a narrow range of periods less than 120\ndays. We conclude that a dedicated monitoring campaign, with appropriately\ndefined sampling, is essential if we are to investigate properly the nature of\nthe long-term modulations such as those seen in Galactic sources.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:07:36 GMT"},{"version":"v2","created":"Mon, 6 May 2013 19:56:44 GMT"}],"update_date":"2013-05-07"}
{"id":"1303.6969","submitter":"Jeffrey Winicour","authors":"J. Winicour","title":"The affine-null metric formulation of Einstein's equations","comments":"Version to appear in Physical Review D","journal-ref":null,"doi":"10.1103/PhysRevD.87.124027","report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The details are presented of a new evolution algorithm for the characteristic\ninitial-boundary value problem based upon an affine parameter rather than the\nareal radial coordinate used in the Bondi-Sachs formulation. The advantages\nover the Bondi-Sachs version are discussed, with particular emphasis on the\napplication to the characteristic extraction of the gravitational waveform from\nCauchy simulations of general relativistic astrophysical systems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:08:46 GMT"},{"version":"v2","created":"Fri, 14 Jun 2013 17:00:26 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6970","submitter":"Denis Klevers","authors":"Mirjam Cveti\\v{c} and Denis Klevers and Hernan Piragua","title":"F-Theory Compactifications with Multiple U(1)-Factors: Constructing\n  Elliptic Fibrations with Rational Sections","comments":"68 pages, 5 figures, 3 tables; v2: minor changes, 1 figure added; v3:\n  typos corrected, references added","journal-ref":null,"doi":"10.1007/JHEP06(2013)067","report-no":"UPR-1249-T","categories":"hep-th hep-ph math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study F-theory compactifications with U(1)xU(1) gauge symmetry on\nelliptically fibered Calabi-Yau manifolds with a rank two Mordell-Weil group.\nWe find that the natural presentation of an elliptic curve E with two rational\npoints and a zero point is the generic Calabi-Yau onefold in dP_2. We determine\nthe birational map to its Tate and Weierstrass form and the coordinates of the\ntwo rational points in Weierstrass form. We discuss its resolved elliptic\nfibrations over a general base B and classify them in the case of B=P^2. A\nthorough analysis of the generic codimension two singularities of these\nelliptic Calabi-Yau manifolds is presented. This determines the general\nU(1)xU(1)-charges of matter in corresponding F-theory compactifications. The\nmatter multiplicities for the fibration over P^2 are determined explicitly and\nshown to be consistent with anomaly cancellation. Explicit toric examples are\nconstructed, both with U(1)xU(1) and SU(5)xU(1)xU(1) gauge symmetry. As a\nby-product, we prove the birational equivalence of the two elliptic fibrations\nwith elliptic fibers in the two blow-ups Bl_(1,0,0)P^2(1,2,3) and\nBl_(0,1,0)P^2(1,1,2) employing birational maps and extremal transitions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:09:50 GMT"},{"version":"v2","created":"Tue, 9 Apr 2013 22:01:56 GMT"},{"version":"v3","created":"Wed, 3 Jul 2013 00:37:31 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6971","submitter":"Cody Jones","authors":"Cody Jones","title":"Composite Toffoli gate with two-round error detection","comments":"8 pages, 8 figures","journal-ref":"Phys. Rev. A 87, 052334 (2013)","doi":"10.1103/PhysRevA.87.052334","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a fault-tolerant construction to implement a composite quantum\noperation of four overlapping Toffoli gates. The same construction can produce\ntwo independent Toffoli gates. This result lowers resource overheads in designs\nfor quantum computers by more than an order of magnitude. The procedure uses\nClifford operations and 64 copies of the non-Clifford gate $T = \\exp[i \\pi (I -\n\\sigma^z) /8]$. Quantum codes detect errors in the circuit. When the dominant\nsource of error is $T$-gate failure with probability $p$, then the composite\nToffoli circuit has postselected failure rate of $3072p^4$ to lowest order.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:09:55 GMT"}],"update_date":"2013-08-06"}
{"id":"1303.6972","submitter":"Peng Zhao","authors":"Peter Sarnak and Peng Zhao, Appendix by Michael Woodbury","title":"The Quantum Variance of the Modular Surface","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The variance of observables of quantum states of the Laplacian on the modular\nsurface is calculated in the semiclassical limit. It is shown that this\nhermitian form is diagonalized by the irreducible representations of the\nmodular quotient and on each of these it is equal to the classical variance of\nthe geodesic flow after the insertion of a subtle arithmetical special value of\nthe corresponding $L$-function.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:10:32 GMT"},{"version":"v2","created":"Tue, 7 May 2013 15:10:19 GMT"},{"version":"v3","created":"Tue, 13 Feb 2018 15:41:55 GMT"}],"update_date":"2018-02-14"}
{"id":"1303.6973","submitter":"Elizabeth  Jurisich","authors":"Ben L. Cox and Elizabeth G. Jurisich","title":"Realizations of the three point algebra $\\mathfrak{sl}(2, \\mathcal R)\n  \\oplus\\left(\\Omega_{\\mathcal R}/d{\\mathcal R}\\right)$","comments":"arXiv admin note: text overlap with arXiv:0902.1273. This version has\n  a correction to a scalar in Cor 2.3. The representations of the algebra are\n  unaffected","journal-ref":"Pacific Journal of Mathematics vol. 270, No. 1, 2014","doi":"10.2140/pjm.2014.270.27","report-no":null,"categories":"math.RT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe the universal central extension of the three point current\nalgebra $\\mathfrak{sl}(2,\\mathcal R)$ where $\\mathcal R=\\mathbb\nC[t,t^{-1},u\\,|\\,u^2=t^2+4t ]$ and construct realizations of it in terms of\nsums of partial differential operators.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:28:30 GMT"},{"version":"v2","created":"Mon, 26 Aug 2013 00:49:26 GMT"},{"version":"v3","created":"Sun, 22 Feb 2015 23:10:21 GMT"}],"update_date":"2015-02-24"}
{"id":"1303.6974","submitter":"Jan Korger","authors":"Jan Korger, Andrea Aiello, Vanessa Chille, Peter Banzer, Christoffer\n  Wittmann, Norbert Lindlein, Christoph Marquardt, Gerd Leuchs","title":"Observation of the geometric spin Hall effect of light","comments":"9 pages, 6 figures","journal-ref":"Phys. Rev. Lett. 112, 113902 (2014)","doi":"10.1103/PhysRevLett.112.113902","report-no":null,"categories":"physics.optics physics.class-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The spin Hall effect of light (SHEL) is the photonic analogue of spin Hall\neffects occurring for charge carriers in solid-state systems. Typical examples\nof this intriguing phenomenon occur when a light beam refracts at an air-glass\ninterface, or when it is projected onto an oblique plane, the latter effect\nbeing known as geometric SHEL. It amounts to a polarization-dependent\ndisplacement perpendicular to the plane of incidence. Here, we experimentally\ndemonstrate the geometric SHEL for a light beam transmitted across an oblique\npolarizer. We find that the spatial intensity distribution of the transmitted\nbeam depends on the incident state of polarization and its centroid undergoes a\npositional displacement exceeding one wavelength. This novel phenomenon is\nvirtually independent from the material properties of the polarizer and, thus,\nreveals universal features of spin-orbit coupling.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:28:51 GMT"},{"version":"v2","created":"Wed, 3 Apr 2013 09:55:07 GMT"},{"version":"v3","created":"Fri, 21 Jun 2013 13:40:02 GMT"},{"version":"v4","created":"Tue, 22 Oct 2013 09:28:36 GMT"}],"update_date":"2014-03-26"}
{"id":"1303.6975","submitter":"Krzysztof Urbanowski","authors":"K. Urbanowski, K. Raczynska","title":"Possible Emission of Cosmic $X$-- and $\\gamma$--rays by Unstable\n  Particles at Late Times","comments":"15 pages, 5 figures","journal-ref":"Physics Letters B731(2014)236","doi":"10.1016/j.physletb.2014.02.043","report-no":null,"categories":"astro-ph.HE hep-ph hep-th quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Not all astrophysical mechanisms of the emission of electromagnetic radiation\nincluding $X$-- and $\\gamma$-- rays coming from the space are clear. We find\nthat charged unstable particles as well as neutral unstable particles with\nnon--zero magnetic moment which live sufficiently long may emit electromagnetic\nradiation. This new mechanism is connected with the properties of unstable\nparticles at the post exponential time region. Analyzing the transition time\nregion between exponential and non-exponential form of the survival amplitude\nit is found that the instantaneous energy of the unstable particle can take\nvery large values, much larger than the energy of this state for times from the\nexponential time region. Basing on the results obtained for the model\nconsidered, it is shown that this purely quantum mechanical effect may be\nresponsible for causing unstable particles to emit electromagnetic--, $X$-- or\n$\\gamma$--rays at some time intervals from the transition time regions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:34:52 GMT"},{"version":"v2","created":"Fri, 29 Mar 2013 16:53:58 GMT"},{"version":"v3","created":"Sat, 15 Mar 2014 22:33:36 GMT"}],"update_date":"2014-03-18"}
{"id":"1303.6976","submitter":"Monica Patriche","authors":"Monica Patriche","title":"The reduction of qualitative games","comments":"21 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT math.OC","license":"http://creativecommons.org/licenses/by/3.0/","abstract":"  We extend the study of the iterated elimination of strictly dominated\nstrategies (IESDS) from Nash strategic games to a class of qualitative games.\nAlso in this case, the IESDS process leads us to a kind of 'rationalizable'\nresult. We define several types of dominance relation and game reduction and\nestablish conditions under which a unique and nonempty maximal reduction\nexists. We generalize, in this way, some results due to Dufwenberg and Stegeman\n(2002) and Apt (2007).\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:48:10 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6977","submitter":"Christos Dimitrakakis","authors":"Christos Dimitrakakis, Nikolaos Tziortziotis","title":"ABC Reinforcement Learning","comments":"Corrected version of paper appearing in ICML 2013","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper introduces a simple, general framework for likelihood-free\nBayesian reinforcement learning, through Approximate Bayesian Computation\n(ABC). The main advantage is that we only require a prior distribution on a\nclass of simulators (generative models). This is useful in domains where an\nanalytical probabilistic model of the underlying process is too complex to\nformulate, but where detailed simulation models are available. ABC-RL allows\nthe use of any Bayesian reinforcement learning technique, even in this case. In\naddition, it can be seen as an extension of rollout algorithms to the case\nwhere we do not know what the correct model to draw rollouts from is. We\nexperimentally demonstrate the potential of this approach in a comparison with\nLSPI. Finally, we introduce a theorem showing that ABC is a sound methodology\nin principle, even when non-sufficient statistics are used.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:51:33 GMT"},{"version":"v2","created":"Wed, 8 May 2013 12:54:53 GMT"},{"version":"v3","created":"Tue, 18 Jun 2013 09:42:59 GMT"},{"version":"v4","created":"Fri, 28 Jun 2013 11:18:26 GMT"}],"update_date":"2013-07-01"}
{"id":"1303.6978","submitter":"German Lugones","authors":"V. R. C. Mour\\~ao Roque and G. Lugones","title":"Unveiling the cosmological QCD phase transition through the eLISA/NGO\n  detector","comments":"to appear in Physical Review D","journal-ref":"Phys. Rev. D 87, 083516 (2013)","doi":"10.1103/PhysRevD.87.083516","report-no":null,"categories":"astro-ph.CO hep-lat hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the evolution of turbulence in the early universe at the QCD epoch\nusing a state-of-the-art equation of state derived from lattice QCD\nsimulations. Since the transition is a crossover we assume that temperature and\nvelocity fluctuations were generated by some event in the previous history of\nthe Universe and survive until the QCD epoch due to the extremely large\nReynolds number of the primordial fluid. The fluid at the QCD epoch is assumed\nto be non-viscous, based on the fact that the viscosity per entropy density of\nthe quark gluon plasma obtained from heavy-ion collision experiments at the\nRHIC and the LHC is extremely small.\n  Our hydrodynamic simulations show that the velocity spectrum is very\ndifferent from the Kolmogorov power law considered in studies of primordial\nturbulence that focus on first order phase transitions. This is due to the fact\nthat there is no continuous injection of energy in the system and the viscosity\nof the fluid is negligible. Thus, as kinetic energy cascades from the larger to\nthe smaller scales, a large amount of kinetic energy is accumulated at the\nsmallest scales due to the lack of dissipation.\n  We have obtained the spectrum of the gravitational radiation emitted by the\nmotion of the fluid finding that, if typical velocity and temperature\nfluctuations have an amplitude $(\\Delta v) /c \\gtrsim 10^{-2}$ and/or $\\Delta\nT/T_c \\gtrsim 10^{-3}$, they would be detected by eLISA at frequencies larger\nthan $\\sim 10^{-4}$ Hz.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:57:51 GMT"}],"update_date":"2013-08-21"}
{"id":"1303.6979","submitter":"Monica Patriche","authors":"Monica Patriche","title":"Equilibrium existence results for a class of discontinuous games","comments":"28 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce the notions of w-lower semicontinuous and almost w-lower\nsemicontinuous correspondence with respect to a given set and prove a new\nfixed-point theorem. We also introduce the notion of correspondence with\ne-LSCS-property. As applications we obtain some new equilibrium theorems for\nabstract economies and for generalized multiobjective games.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:04:50 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6980","submitter":"Alexander Philippov","authors":"Alexander A. Philippov and Roman R. Rafikov","title":"Analysis of Spin-Orbit Misalignment in Eclipsing Binary DI Herculis","comments":"Accepted by ApJ, 12 pages, 10 figures","journal-ref":null,"doi":"10.1088/0004-637X/768/2/112","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Eclipsing binary DI Herculis (DI Her) is known to exhibit anomalously slow\napsidal precession, below the rate predicted by the general relativity. Recent\nmeasurements of the Rossiter-McLauglin effect indicate that stellar spins in DI\nHer are almost orthogonal to the orbital angular momentum, which explains the\nanomalous precession in agreement with the earlier theoretical suggestion by\nShakura. However, these measurements yield only the projections of the\nspin-orbit angles onto the sky plane, leaving the spin projection onto our line\nof sight unconstrained. Here we describe a method of determining the full\nthree-dimensional spin orientation of the binary components relying on the use\nof the gravity darkening effect, which is significant for the rapidly rotating\nstars in DI Her. Gravity darkening gives rise to nonuniform brightness\ndistribution over the stellar surface, the pattern of which depends on the\nstellar spin orientation. Using archival photometric data obtained during\nmultiple eclipses spread over several decades we are able to constrain the\nunknown spin angles in DI Her with this method, finding that spin axes of both\nstars lie close to the plane of the sky. Our procedure fully accounts for the\nprecession of stellar spins over the long time span of observations.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:20:00 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6981","submitter":"Rafael Stern","authors":"Rafael Bassi Stern, Joseph Born Kadane","title":"Coherence of countably many bets","comments":"15 pages","journal-ref":null,"doi":"10.1007/s10959-013-0489-9","report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  De Finetti's betting argument is used to justify finitely additive\nprobabilities when only finitely many bets are considered. Under what\ncircumstances can countably many bets be used to justify countable additivity?\nIn this framework, one faces issues such as the convergence of the returns of\nthe bet. Generalizations of de Finetti's argument depend on what type of\nconditions on convergence are required of the bets under consideration. Two new\nsuch conditions are compared with others presented in the literature.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:20:20 GMT"}],"update_date":"2013-05-08"}
{"id":"1303.6982","submitter":"Monica Patriche","authors":"Monica Patriche","title":"Fixed Point Theorems and applications in Theory of Games","comments":"20 pages Accepted for publication in Fixed Point Theory","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/3.0/","abstract":"  We introduce the notions of weakly *-concave and weakly naturally\nquasi-concave correspondence and prove fixed point theorems and continuous\nselection theorems for these kind of correspondences. As applications in the\ngame theory, by using a tehnique based on a continuous selection, we establish\nnew existence results for the equilibrium of the abstract economies. The\nconstraint correspondences are weakly naturally quasi-concave. We show that the\nequilibrium exists without continuity assumptions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:24:54 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6983","submitter":"Philip Richerme","authors":"Philip Richerme, Crystal Senko, Simcha Korenblit, Jacob Smith, Aaron\n  Lee, Rajibul Islam, Wesley C. Campbell, Christopher Monroe","title":"Quantum Catalysis of Magnetic Phase Transitions in a Quantum Simulator","comments":"New data in Fig. 3, and much of the paper rewritten","journal-ref":"Phys. Rev. Lett. 111, 100506 (2013)","doi":"10.1103/PhysRevLett.111.100506","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We control quantum fluctuations to create the ground state magnetic phases of\na classical Ising model with a tunable longitudinal magnetic field using a\nsystem of 6 to 10 atomic ion spins. Due to the long-range Ising interactions,\nthe various ground state spin configurations are separated by multiple\nfirst-order phase transitions, which in our zero temperature system cannot be\ndriven by thermal fluctuations. We instead use a transverse magnetic field as a\nquantum catalyst to observe the first steps of the complete fractal devil's\nstaircase, which emerges in the thermodynamic limit and can be mapped to a\nlarge number of many-body and energy-optimization problems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:25:12 GMT"},{"version":"v2","created":"Tue, 25 Jun 2013 19:04:42 GMT"}],"update_date":"2013-09-06"}
{"id":"1303.6984","submitter":"Ruslan Vaulin","authors":"Rahul Biswas, Lindy Blackburn, Junwei Cao, Reed Essick, Kari Alison\n  Hodge, Erotokritos Katsavounidis, Kyungmin Kim, Young-Min Kim, Eric-Olivier\n  Le Bigot, Chang-Hwan Lee, John J. Oh, Sang Hoon Oh, Edwin J. Son, Ruslan\n  Vaulin, Xiaoge Wang and Tao Ye","title":"Application of machine learning algorithms to the study of noise\n  artifacts in gravitational-wave data","comments":"21 pages, 8 figures","journal-ref":null,"doi":"10.1103/PhysRevD.88.062003","report-no":null,"categories":"astro-ph.IM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The sensitivity of searches for astrophysical transients in data from the\nLIGO is generally limited by the presence of transient, non-Gaussian noise\nartifacts, which occur at a high-enough rate such that accidental coincidence\nacross multiple detectors is non-negligible. Furthermore, non-Gaussian noise\nartifacts typically dominate over the background contributed from stationary\nnoise. These \"glitches\" can easily be confused for transient gravitational-wave\nsignals, and their robust identification and removal will help any search for\nastrophysical gravitational-waves. We apply Machine Learning Algorithms (MLAs)\nto the problem, using data from auxiliary channels within the LIGO detectors\nthat monitor degrees of freedom unaffected by astrophysical signals. The number\nof auxiliary-channel parameters describing these disturbances may also be\nextremely large; an area where MLAs are particularly well-suited. We\ndemonstrate the feasibility and applicability of three very different MLAs:\nArtificial Neural Networks, Support Vector Machines, and Random Forests. These\nclassifiers identify and remove a substantial fraction of the glitches present\nin two very different data sets: four weeks of LIGO's fourth science run and\none week of LIGO's sixth science run. We observe that all three algorithms\nagree on which events are glitches to within 10% for the sixth science run\ndata, and support this by showing that the different optimization criteria used\nby each classifier generate the same decision surface, based on a\nlikelihood-ratio statistic. Furthermore, we find that all classifiers obtain\nsimilar limiting performance, suggesting that most of the useful information\ncurrently contained in the auxiliary channel parameters we extract is already\nbeing used.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:25:27 GMT"}],"update_date":"2013-10-02"}
{"id":"1303.6985","submitter":"Irfan Siap","authors":"Irfan Siap and Ismail Aydogdu","title":"Counting The Generator Matrices of $\\mathbb{Z}_{2}\\mathbb{Z}_{8}$-Codes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we count the number of matrices whose rows generate different\n$\\mathbb{Z}_2\\mathbb{Z}_8$ additive codes. This is a natural generalization of\nthe well known Gaussian numbers that count the number of matrices whose rows\ngenerate vector spaces with particular dimension over finite fields. Due to\nthis similarity we name this numbers as Mixed Generalized Gaussian Numbers\n(MGN). The MGN formula by specialization leads to the well known formula for\nthe number of binary codes and the number of codes over $\\mathbb{Z}_8,$ and for\nadditive $\\mathbb{Z}_2\\mathbb{Z}_4$ codes. Also, we conclude by some properties\nand examples of the MGN numbers that provide a good source for new number\nsequences that are not listed in The On-Line Encyclopedia of Integer Sequences.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:29:16 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6986","submitter":"John Sheckelton","authors":"John P. Sheckelton, James R. Neilson, Daniel G. Soltan, and Tyrel M.\n  McQueen","title":"Possible valence-bond condensation in the frustrated cluster magnet\n  LiZn2Mo3O8","comments":"30 pages, 10 figures","journal-ref":"Nature Materials 11 (2012) 493-496","doi":"10.1038/nmat3329","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The emergence of complex electronic behaviour from simple ingredients has\nresulted in the discovery of numerous states of matter. Many examples are found\nin systems exhibiting geometric magnetic frustration, which prevents\nsimultaneous satisfaction of all magnetic interactions. This frustration gives\nrise to complex magnetic properties such as chiral spin structures\norbitally-driven magnetism, spin-ice behavior exhibiting Dirac strings with\nmagnetic monopoles, valence bond solids, and spin liquids. Here we report the\nsynthesis and characterization of LiZn2Mo3O8, a geometrically frustrated\nantiferromagnet in which the magnetic moments are localized on small transition\nmetal clusters rather than individual ions. By doing so, first order\nJahn-Teller instabilities and orbital ordering are prevented, allowing the\nstrongly interacting magnetic clusters in LiZn2Mo3O8 to probably give rise to\nan exotic condensed valence-bond ground state reminiscent of the proposed\nresonating valence bond state. Our results also link magnetism on clusters to\ngeometric magnetic frustration in extended solids, demonstrating a new approach\nfor unparalleled chemical control and tunability in the search for collective,\nemergent electronic states of matter.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:34:31 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6987","submitter":"Roger Johnson","authors":"R. D. Johnson, P. Barone, A. Bombardi, R. J. Bean, S. Picozzi, P. G.\n  Radaelli, Y. S. Oh, S-W. Cheong, and L. C. Chapon","title":"X-ray imaging and multiferroic coupling of cycloidal magnetic domains in\n  ferroelectric monodomain BiFeO3","comments":"Published in Physical Review Letters","journal-ref":"R. D. Johnson et al., PRL 110, 217206 (2013)","doi":"10.1103/PhysRevLett.110.217206","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Magnetic domains at the surface of a ferroelectric monodomain BiFeO3 single\ncrystal have been imaged by hard X-ray magnetic scattering. Magnetic domains up\nto several hundred microns in size have been observed, corresponding to\ncycloidal modulations of the magnetization along the wave-vector\nk=2\\pi(\\delta,\\delta,0) and symmetry equivalent directions. The rotation\ndirection of the magnetization in all magnetic domains, determined by\ndiffraction of circularly polarized light, was found to be unique and in\nagreement with predictions of a combined approach based on a spin-model\ncomplemented by relativistic density-functional simulations. Imaging of the\nsurface shows that the largest adjacent domains display a 120 degree vortex\nstructure.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:39:37 GMT"},{"version":"v2","created":"Fri, 24 May 2013 09:58:30 GMT"}],"update_date":"2013-05-27"}
{"id":"1303.6988","submitter":"Dongwook Lee","authors":"Dongwook Lee","title":"A Solution Accurate, Efficient and Stable Unsplit Staggered Mesh Scheme\n  for Three Dimensional Magnetohydrodynamics","comments":"31 pages, 21 figures","journal-ref":null,"doi":"10.1016/j.jcp.2013.02.049","report-no":null,"categories":"physics.comp-ph astro-ph.HE math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we extend the unsplit staggered mesh scheme (USM) for 2D\nmagnetohydrodynamics (MHD) (Lee and Deane, 2009) to a full 3D MHD scheme. The\nscheme is a finite-volume Godunov method consisting of a constrained transport\n(CT) method and an efficient and accurate single-step, directionally unsplit\nmultidimensional data reconstruction-evolution algorithm, which extends the\noriginal 2D corner transport upwind (CTU) method (Colella, 1990). We present\ntwo types of data reconstruction-evolution algorithms for 3D: (1) a reduced CTU\nscheme and (2) a full CTU scheme. The reduced 3D CTU scheme is a variant of a\nsimple 3D extension of the 2D CTU method by Colella (1990) and is considered as\na direct extension from the 2D USM scheme. The full 3D CTU scheme is our\nprimary 3D solver which includes all multidimensional cross-derivative terms\nfor stability. The latter method is logically analogous to the 3D unsplit CTU\nmethod by Saltzman. The major novelties in our algorithms are twofold. First,\nwe extend the reduced CTU scheme to the full CTU scheme which is able to run\nwith CFL numbers close to unity. Both methods utilize the transverse update\ntechnique developed in the 2D USM algorithm to account for transverse fluxes\nwithout solving intermediate Riemann problems, which in turn gives\ncost-effective 3D methods by reducing the total number of Riemann solves. The\nproposed algorithms are simple and efficient especially when including\nmultidimensional MHD terms that maintain in-plane magnetic field dynamics.\nSecond, we introduce a new CT scheme that makes use of proper upwind\ninformation in taking averages of electric fields.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:48:52 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6989","submitter":"Wojciech Dorabiala","authors":"Bernard Badzioch, David Blanc, and Wojciech Dorabiala","title":"Recognizing mapping spaces","comments":"24 pages, incorporated corrections based on referee's report, to\n  appear in Journal of Pure and Applied Algebra","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given a fixed object $A$ in a suitable pointed simplicial model category\n$\\C$, we study the problem of recovering the target $Y$ from the pointed\nmapping space \\w{\\mapa(A,Y)} (up to $A$-equivalence). We describe a recognition\nprinciple, modelled on the classical ones for loop spaces, but using the more\ngeneral notion of an \\emph{\\Ama[.]} It has an associated transfinite procedure\nfor recovering \\w{\\CWA Y} from \\w[,]{\\mapa(A,Y)} inspired by Dror-Farjoun's\nconstruction of \\ww{\\CWA{}}-approximations.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:49:57 GMT"},{"version":"v2","created":"Thu, 23 May 2013 18:38:29 GMT"}],"update_date":"2013-05-24"}
{"id":"1303.6990","submitter":"Omar Gamel","authors":"Omar Gamel and Daniel F. V. James","title":"The Complete Positivity of Classical Polarization Maps","comments":"6 pages","journal-ref":"Optics Letters, Vol. 36, Issue 15, pp. 2821-2823 (2011)","doi":"10.1364/OL.36.002821","report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mueller and Jones matrices have been thoroughly studied as mathematical tools\nto describe the manipulation of the polarization state of classical light. In\nparticular, the most general physical transformation on the polarization state\nhas been represented as an ensemble of Jones matrices, as $\\sum_i V_i \\Phi\nV^{\\dagger}_i$. But this has generally been directly assumed without proof by\nmost authors. In this Letter, we derive this expression from simple physical\nprinciples and the matrix theory of positive maps.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:56:18 GMT"},{"version":"v2","created":"Sun, 6 Oct 2013 16:10:38 GMT"},{"version":"v3","created":"Tue, 29 Sep 2015 18:34:49 GMT"}],"update_date":"2015-09-30"}
{"id":"1303.6991","submitter":"Monica Patriche","authors":"Monica Patriche","title":"On the maximal reduction of games","comments":"20 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/3.0/","abstract":"  We study the conditions under which the iterated elimination of strictly\ndominated strategies is order independent and we identify a class of\ndiscontinuous games for which order does not matter. In this way, we answer the\nopen problem raised by M. Dufwenberg and M. Stegeman (2002) and generalize\ntheir main results. We also establish new theorems concerning the existence and\nuniqueness of the maximal game reduction when the pure strategies are dominated\nby mixed strategies.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:03:14 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6992","submitter":"William Kleiber","authors":"William Kleiber, Stephan R. Sain, Matthew J. Heaton, Michael\n  Wiltberger, C. Shane Reese, Derek Bingham","title":"Parameter tuning for a multi-fidelity dynamical model of the\n  magnetosphere","comments":"Published in at http://dx.doi.org/10.1214/13-AOAS651 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)","journal-ref":"Annals of Applied Statistics 2013, Vol. 7, No. 3, 1286-1310","doi":"10.1214/13-AOAS651","report-no":"IMS-AOAS-AOAS651","categories":"stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Geomagnetic storms play a critical role in space weather physics with the\npotential for far reaching economic impacts including power grid outages, air\ntraffic rerouting, satellite damage and GPS disruption. The LFM-MIX is a\nstate-of-the-art coupled magnetospheric-ionospheric model capable of simulating\ngeomagnetic storms. Imbedded in this model are physical equations for turning\nthe magnetohydrodynamic state parameters into energy and flux of electrons\nentering the ionosphere, involving a set of input parameters. The exact values\nof these input parameters in the model are unknown, and we seek to quantify the\nuncertainty about these parameters when model output is compared to\nobservations. The model is available at different fidelities: a lower fidelity\nwhich is faster to run, and a higher fidelity but more computationally intense\nversion. Model output and observational data are large spatiotemporal systems;\nthe traditional design and analysis of computer experiments is unable to cope\nwith such large data sets that involve multiple fidelities of model output. We\ndevelop an approach to this inverse problem for large spatiotemporal data sets\nthat incorporates two different versions of the physical model. After an\ninitial design, we propose a sequential design based on expected improvement.\nFor the LFM-MIX, the additional run suggested by expected improvement\ndiminishes posterior uncertainty by ruling out a posterior mode and shrinking\nthe width of the posterior distribution. We also illustrate our approach using\nthe Lorenz `96 system of equations for a simplified atmosphere, using known\ninput parameters. For the Lorenz `96 system, after performing sequential runs\nbased on expected improvement, the posterior mode converges to the true value\nand the posterior variability is reduced.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:09:56 GMT"},{"version":"v2","created":"Thu, 5 Dec 2013 09:17:02 GMT"}],"update_date":"2013-12-06"}
{"id":"1303.6993","submitter":"Alfred Bennun","authors":"Alfred Bennun","title":"The coupling of thermodynamics with the organizational water-protein\n  intra-dynamics driven by the H-bonds dissipative potential of cluster water","comments":"9 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.MN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Red cell-Hb-CSF functions as a sensor adapting response to Hb\nheterotropic equilibriums. At the lungs O2 and Mg2+, each one increasing\naffinity for the other stabilize the relax (R) form [(O2)4Hb(Mg)2].(H2O)R. At\ntissue level, the inclusion of H+ and 2,3-DPG excludes O2 and Mg2+ to stabilize\nthe tense (T) form 2,3-DPG-deoxyHb-(H2O)T. Both senses are integrated into a\ncycle T into R and R into T, without involving a direct reversal. The\ndissipative potential of water cluster (H2O)n interacts with the hydrophilic\nasymmetries of Hb, to restrict randomness of the kinetic sense implicated in a\nsingle peak for activation energy (Ea). The hydration shells could sequence an\nenhanced Ea into several peaks, to sequentially activate transitions states.\nHence, changes in dipole state, sliding, pKa, n-H-bonds, etc., could became\nconcatenated for vectoriality. (H2O)n by the loss of H-bonds couple with to the\nhydration turnover of proteins and ions to result in incomplete water cluster\n(H2O)n*, with a lower-n. (H2O)n* became a carrier of heat/entropy into the\ncerebrospinal fluid (CSF) which has to be replaced 3.7 times per day. OxyHb\nformation involves sliding-down of alpha vs beta chains, to shift alpha1 and\nalpha2 Pro 44 into allowing the entrance of a fully hydrated\n[Mg.(H2O)6](H2O)12-14(2+) (or Zn2+) into the hydrophilic beta2-alpha1 and\nbeta1-alpha2 interfaces. OxyHb pKa of 6.4 leads to H+-dissociation increasing\nnegative charge of R-groups. This at beta2-alpha1 sequence two tetradentate\nchelates, first an Mg2+, bonding with beta2 His 92 and a second Mg2+ with\nalpha1 His 87, to cooperatively release hindrance. The interconversion of\noxy-to-deoxyHb, pKa=8, leads to the amphoteric imidazole to became positively\ncharged and proximal histidines return into hindrance position, releasing the\nincomplete hydrated Mg.(H2O)inc(2+) and O2 into CSF.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:14:45 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6994","submitter":"Tobias Meng","authors":"Tobias Meng and Daniel Loss","title":"Strongly anisotropic spin response as a signature of the helical regime\n  in Rashba nanowires","comments":"7 pages, 1 figure, final version","journal-ref":"Phys. Rev. B 88, 035437 (2013)","doi":"10.1103/PhysRevB.88.035437","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rashba nanowires in a magnetic field exhibit a helical regime when the\nspin-orbit momentum is close to the Fermi momentum, k_F \\approx k_{SO}. We show\nthat this regime is characterized by a strongly anisotropic electron spin\nsusceptibility, with an exponentially suppressed signal along one direction in\nspin space, and that there are no low frequency spin fluctuations along this\ndirection. Since the spin response in the gapless regime k_F \\not \\approx\nk_{SO} has a power law behavior in all three directions, spin measurements\nprovide a signature of the helical regime that complements spin-insensitive\nconductance measurements.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:18:00 GMT"},{"version":"v2","created":"Mon, 5 Aug 2013 08:24:11 GMT"}],"update_date":"2013-08-06"}
{"id":"1303.6995","submitter":"Norimi Yokozaki","authors":"Masahiro Ibe and Tsutomu T. Yanagida and Norimi Yokozaki","title":"Muon g-2 and 125 GeV Higgs in Split-Family Supersymmetry","comments":"20 pages, 5 figures","journal-ref":null,"doi":"10.1007/JHEP08(2013)067","report-no":null,"categories":"hep-ph hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss the minimal supersymmetric standard model with \"split-family\"\nspectrum where the sfermions in the first two generations are in the hundreds\nGeV to a TeV range while the sfermions in the third generation are in the range\nof tens TeV. With the split-family spectrum, the deviation of the muon g-2 and\nthe observed Higgs boson mass are explained simultaneously. It is predicted\nthat the gluino and the squarks in the first two generations are within the\nreach of the LHC experiments in most favored parameter space for the universal\ngaugino mass, which can be tested by searching for events with missing\ntransverse energy or events with stable charged massive particles. We also\npoint out that the split-family scenario can be consistent with the focus point\nscenario for the non-universal gaugino masses where the required mu-term is in\nthe hundreds GeV range.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:18:14 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6996","submitter":"Victor Acosta","authors":"Victor M. Acosta, Kasper Jensen, Charles Santori, Dmitry Budker, and\n  Rymond G. Beausoleil","title":"Electromagnetically-induced transparency in a diamond spin ensemble\n  enables all-optical electromagnetic field sensing","comments":"12 pages, 12 figures","journal-ref":"Phys. Rev. Lett. 110, 213605 (2013)","doi":"10.1103/PhysRevLett.110.213605","report-no":null,"categories":"physics.optics cond-mat.mtrl-sci physics.atom-ph physics.ins-det quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use electromagnetically-induced transparency (EIT) to probe the narrow\nelectron-spin resonance of nitrogen-vacancy centers in diamond. Working with a\nmulti-pass diamond chip at temperatures 6-30 K, the zero-phonon absorption line\n(637 nm) exhibits an optical depth of 6 and inhomogenous linewidth of ~30 GHz\nfull-width-at-half-maximum (FWHM). Simultaneous optical excitation at two\nfrequencies separated by the ground-state zero-field splitting (2.88 GHz),\nreveals EIT resonances with a contrast exceeding 6% and FWHM down to 0.4 MHz.\nThe resonances provide an all-optical probe of external electric and magnetic\nfields with a projected photon-shot-noise-limited sensitivity of 0.2\nV/cm/sqrt(Hz) and 0.1 nT/sqrt(Hz), respectively. Operation of a prototype\ndiamond-EIT magnetometer measures a noise floor of less than 1 nT/sqrt(Hz) for\nfrequencies above 10 Hz and Allan deviation of 1.3 +/- 1.1 nT for 100 s\nintervals. The results demonstrate the potential of diamond-EIT devices for\napplications ranging from quantum-optical memory to few-photon nonlinear\noptics, precision measurement, and tests of fundamental physics.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:32:19 GMT"},{"version":"v2","created":"Fri, 24 May 2013 20:44:21 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.6997","submitter":"Yuancheng Fan","authors":"Yuancheng Fan, Jin Han, Hongqiang Li","title":"Gaussian Beam Collimation via Transformation Media","comments":"6 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Conventional method for Gaussian beam collimation is to expand the beam waist\nto achieve a smaller divergence angle. Recent transformation optics offers an\nunconventional path to control the electromagnetic field. In this paper we show\nthat a Gaussian beam can be converted into a plane wave-like beam by\ntransformation media within the scale of several wavelengths. Design details\nand full-wave simulation results via finite element method are provided.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:40:17 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.6998","submitter":"Paolo Stellari","authors":"Mart\\'i Lahoz, Emanuele Macr\\`i, Paolo Stellari","title":"ACM bundles on cubic fourfolds containing a plane","comments":"18 pages. This is the last section of the previous version of\n  arXiv:1303.6998 which is now spit into two parts. Explanations added","journal-ref":"In: Brauer groups and obstruction problems: Moduli spaces and\n  arithmetic, 155-175, Progr. Math. 320, Birkhauser/Springer (2017)","doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study ACM bundles on cubic fourfolds containing a plane exploiting the\ngeometry of the associated quadric fibration and Kuznetsov's treatment of their\nbounded derived categories of coherent sheaves. More precisely, we recover the\nK3 surface naturally associated to the fourfold as a moduli space of Gieseker\nstable ACM bundles of rank four.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:47:52 GMT"},{"version":"v2","created":"Sat, 15 Feb 2014 19:32:28 GMT"},{"version":"v3","created":"Sun, 8 Feb 2015 14:51:05 GMT"},{"version":"v4","created":"Mon, 20 Nov 2017 20:42:22 GMT"}],"update_date":"2017-11-22"}
{"id":"1303.6999","submitter":"Bertrand Cloez","authors":"Bertrand Cloez, Martin Hairer","title":"Exponential ergodicity for Markov processes with random switching","comments":"Published at http://dx.doi.org/10.3150/13-BEJ577 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)","journal-ref":"Bernoulli 2015, Vol. 21, No. 1, 505-536","doi":"10.3150/13-BEJ577","report-no":"IMS-BEJ-BEJ577","categories":"math.PR math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study a Markov process with two components: the first component evolves\naccording to one of finitely many underlying Markovian dynamics, with a choice\nof dynamics that changes at the jump times of the second component. The second\ncomponent is discrete and its jump rates may depend on the position of the\nwhole process. Under regularity assumptions on the jump rates and Wasserstein\ncontraction conditions for the underlying dynamics, we provide a concrete\ncriterion for the convergence to equilibrium in terms of Wasserstein distance.\nThe proof is based on a coupling argument and a weak form of the Harris\ntheorem. In particular, we obtain exponential ergodicity in situations which do\nnot verify any hypoellipticity assumption, but are not uniformly contracting\neither. We also obtain a bound in total variation distance under a suitable\nregularising assumption. Some examples are given to illustrate our result,\nincluding a class of piecewise deterministic Markov processes.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:52:35 GMT"},{"version":"v2","created":"Mon, 13 Apr 2015 12:33:30 GMT"}],"update_date":"2015-04-14"}
{"id":"1303.7000","submitter":"Hua Sun","authors":"Hua Sun and Syed A. Jafar","title":"Index Coding Capacity: How far can one go with only Shannon\n  Inequalities?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An interference alignment perspective is used to identify the simplest\ninstances (minimum possible number of edges in the alignment graph, no more\nthan 2 interfering messages at any destination) of index coding problems where\nnon-Shannon information inequalities are necessary for capacity\ncharacterization. In particular, this includes the first known example of a\nmultiple unicast (one destination per message) index coding problem where\nnon-Shannon information inequalities are shown to be necessary. The simplest\nmultiple unicast example has 7 edges in the alignment graph and 11 messages.\nThe simplest multiple groupcast (multiple destinations per message) example has\n6 edges in the alignment graph, 6 messages, and 10 receivers. For both the\nsimplest multiple unicast and multiple groupcast instances, the best outer\nbound based on only Shannon inequalities is $\\frac{2}{5}$, which is tightened\nto $\\frac{11}{28}$ by the use of the Zhang-Yeung non-Shannon type information\ninequality, and the linear capacity is shown to be $\\frac{5}{13}$ using the\nIngleton inequality. Conversely, identifying the minimal challenging aspects of\nthe index coding problem allows an expansion of the class of solved index\ncoding problems up to (but not including) these instances.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:53:13 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7001","submitter":"Alfio Bonanno","authors":"Alfio Bonanno, Vadim Urpin","title":"Rotational suppression of the Tayler instability in stellar radiation\n  zones","comments":"7 pages, 5 figures, to appear on MNRAS. arXiv admin note: text\n  overlap with arXiv:1302.2523","journal-ref":null,"doi":"10.1093/mnras/stt451","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The study of the magnetic field in stellar radiation zones is an important\ntopic in modern astrophysics because the magnetic field can play an important\nrole in several transport phenomena such as mixing and angular momentum\ntransport. We consider the influence of rotation on stability of a\npredominantly toroidal magnetic field in the radiation zone. We find that the\neffect of rotation on the stability depends on the magnetic configuration of\nthe basic state. If the toroidal field increases sufficiently rapidly with the\nspherical radius, the instability cannot be suppressed entirely even by a very\nfast rotation although the strength of the instability can be significantly\nreduced. On the other hand, if the field increases slowly enough with the\nradius or decreases, the instability has a threshold and can be completely\nsuppressed in rapidly rotating stars. We find that in the regions where the\ninstability is entirely suppressed a particular type of magnetohydrodynamic\nwaves may exist which are marginally stable.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:56:47 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7002","submitter":"Giovanni Montana","authors":"Christopher Minas, Edward Curry and Giovanni Montana","title":"A Distance-Based Test of Association Between Paired Heterogeneous\n  Genomic Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Due to rapid technological advances, a wide range of different measurements\ncan be obtained from a given biological sample including single nucleotide\npolymorphisms, copy number variation, gene expression levels, DNA methylation\nand proteomic profiles. Each of these distinct measurements provides the means\nto characterize a certain aspect of biological diversity, and a fundamental\nproblem of broad interest concerns the discovery of shared patterns of\nvariation across different data types. Such data types are heterogeneous in the\nsense that they represent measurements taken at very different scales or\ndescribed by very different data structures. We propose a distance-based\nstatistical test, the generalized RV (GRV) test, to assess whether there is a\ncommon and non-random pattern of variability between paired biological\nmeasurements obtained from the same random sample. The measurements enter the\ntest through distance measures which can be chosen to capture particular\naspects of the data. An approximate null distribution is proposed to compute\np-values in closed-form and without the need to perform costly Monte Carlo\npermutation procedures. Compared to the classical Mantel test for association\nbetween distance matrices, the GRV test has been found to be more powerful in a\nnumber of simulation settings. We also report on an application of the GRV test\nto detect biological pathways in which genetic variability is associated to\nvariation in gene expression levels in ovarian cancer samples, and present\nresults obtained from two independent cohorts.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:00:49 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7003","submitter":"Mario Silveirinha G.","authors":"Mario Silveirinha","title":"Effective Medium Response of Metallic Nanowire Arrays with a Kerr-type\n  Dielectric Host","comments":"43 pages in press (to appear in Phys. Rev. B)","journal-ref":"Phys. Rev. B, 87, 165127, 2013","doi":"10.1103/PhysRevB.87.165127","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We derive an effective medium model to characterize the macroscopic\nelectromagnetic response of metallic nanowire arrays embedded in a host\ndielectric with a Kerr-type nonlinear permittivity function. It is shown that\nthe macroscopic electromagnetic fields are coupled to the conduction current in\nthe nanowires and to an additional quasi-static potential through a system of\nnonlinear equations. We prove that a weak nonlinearity leads to an\nelectromagnetic response closer to that of an indefinite medium, and to\nisofrequency contours with increased hyperbolicity. For high-field intensities\nthe negative refraction of electromagnetic waves at an air nanowire material\ninterface is enhanced when the nanowires are embedded in a self-focusing Kerr\nmedium.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:06:46 GMT"},{"version":"v2","created":"Sat, 30 Mar 2013 14:01:31 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7004","submitter":"Wayne Hu","authors":"Peter Adshead, Wayne Hu, and V Miranda","title":"Bispectrum in Single-Field Inflation Beyond Slow-Roll","comments":"20 pages, 6 figures (typo in A22 corrected)","journal-ref":"Phys. Rev. D88 023507 (2013)","doi":"10.1103/PhysRevD.88.023507","report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We develop an integral form for the bispectrum in general single-field\ninflation whose domain of validity includes models of inflation where the\nbackground evolution is not constrained to be slowly varying everywhere. Our\nintegral form preserves the squeezed-limit consistency relation, allows for\nfast evaluation of the bispectrum for all triangle configurations expediting\nthe efficient comparison of slow-roll violating models with data, and provides\ncomplete and compact slow-roll expressions correct to first order in slow-roll\nparameters. Motivated by the recent Planck results, we consider as an example a\nsharp step in the warped-brane tension of DBI inflation and provide analytic\nsolutions for the peak of the resulting bispectrum. For the step in the warp\nthat reproduces the oscillations in the power spectrum favored by the Planck\ndata, the corresponding equilateral bispectrum is both extremely large and\nhighly scale dependent. The bispectrum serves as a means of distinguishing such\na model from alternative scenarios that generate otherwise indistinguishable\npower spectra, such as a step in the potential in canonical single-field\ninflation.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:10:09 GMT"},{"version":"v2","created":"Fri, 20 Apr 2018 19:03:29 GMT"}],"update_date":"2018-09-18"}
{"id":"1303.7005","submitter":"Abner Salgado","authors":"Ricardo H. Nochetto, Abner J. Salgado and Ignacio Tomas","title":"The micropolar Navier-Stokes equations: A priori error analysis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The unsteady Micropolar Navier-Stokes Equations (MNSE) are a system of\nparabolic partial differential equations coupling linear velocity and pressure\nwith angular velocity: material particles have both translational and\nrotational degrees of freedom. We propose and analyze a first order\nsemi-implicit fully-discrete scheme for the MNSE, which decouples the\ncomputation of the linear and angular velocities, is unconditionally stable and\ndelivers optimal convergence rates under assumptions analogous to those used\nfor the Navier-Stokes equations. With the help of our scheme we explore some\nqualitative properties of the MNSE related to ferrofluid manipulation and\npumping. Finally, we propose a second order scheme and show that it is almost\nunconditionally stable.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:19:43 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7006","submitter":"Bhavin Khatri","authors":"Bhavin S. Khatri and Richard A. Goldstein","title":"Evolutionary stochastic dynamics of speciation and a simple\n  genotype-phenotype map for protein binding DNA","comments":"5 pages, 2 figures","journal-ref":"Journal of Theoretical Biology, 378 (2015), p56-64","doi":"10.1016/j.jtbi.2015.04.027","report-no":null,"categories":"q-bio.PE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Speciation is of fundamental importance to understanding the huge diversity\nof life on Earth. In contrast to current phenomenological models, we develop a\nbiophysically motivated approach to study speciation involving the co-evolution\nof protein binding DNA for two geographically isolated populations. Our results\npredict that, despite neutral diffusion of hybrids in trait space, smaller\npopulations have a higher rate of speciation, due to sequence entropy poising\npopulations more closely to incompatible regions of phenotype space. A key\nlesson of this work is that non-trivial contributions of sequence entropy give\nrise to a strong population size dependence on speciation rates.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:32:59 GMT"},{"version":"v2","created":"Sun, 12 May 2013 10:27:34 GMT"}],"update_date":"2015-05-18"}
{"id":"1303.7007","submitter":"Astrakharchik Grigori E","authors":"G.E. Astrakharchik and I. Brouzos","title":"Trapped one-dimensional ideal Fermi gas with a single impurity","comments":"5 pages, 4 figures","journal-ref":"Phys. Rev. A 88, 021602(R) (2013)","doi":"10.1103/PhysRevA.88.021602","report-no":null,"categories":"cond-mat.quant-gas","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Properties of a single impurity in a one-dimensional Fermi gas are\ninvestigated in homogeneous and trapped geometries. In a homogeneous system we\nuse McGuire's expression [J. B. McGuire, J. Math. Phys. 6, 432 (1965)] to\nobtain interaction and kinetic energies, as well as the local pair correlation\nfunction. The energy of a trapped system is obtained (i) by generalizing\nMcGuire expression (ii) within local density approximation (iii) using\nperturbative approach in the case of a weakly interacting impurity and (iv)\ndiffusion Monte Carlo method. We demonstrate that a closed formula based on the\nexact solution of the homogeneous case provides a precise estimation for the\nenergy of a trapped system for arbitrary coupling constant of the impurity even\nfor a small number of fermions. We analyze energy contributions from kinetic,\ninteraction and potential components, as well as spatial properties such as the\nsystem size. Finally, we calculate the frequency of the breathing mode. Our\nanalysis is directly connected and applicable to the recent experiments in\nmicrotraps.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:42:56 GMT"}],"update_date":"2014-03-14"}
{"id":"1303.7008","submitter":"Fukano Hidenori S","authors":"Hidenori S. Fukano and Kimmo Tuominen","title":"Top-seesaw assisted technicolor model with 126 GeV Higgs boson","comments":"6 pages, 4figures, contribution to SCGT12 \"KMI-GCOE Workshop on\n  Strong Coupling Gauge Theories in the LHC Perspective\", 4-7 Dec. 2012, Nagoya\n  University","journal-ref":null,"doi":"10.1142/9789814566254_0027","report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss a model which involves the top quark condensation and the walking\ntechnicolor. We focus on the scalar boson in such a model from the viewpoint of\nthe observed scalar boson at the LHC.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:55:09 GMT"}],"update_date":"2017-08-23"}
{"id":"1303.7009","submitter":"Benjamin Nachman","authors":"Benjamin Nachman and Christopher G. Lester","title":"Significance Variables","comments":"21 pages, 7 figures","journal-ref":"Phys. Rev. D 88, 075013 (2013)","doi":"10.1103/PhysRevD.88.075013","report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many particle physics analyses which need to discriminate some background\nprocess from a signal ignore event-by-event resolutions of kinematic variables.\nAdding this information, as is done for missing momentum significance, can only\nimprove the power of existing techniques. We therefore propose the use of\nsignificance variables which combine kinematic information with event-by-event\nresolutions. We begin by giving some explicit examples of constructing optimal\nsignificance variables. Then, we consider three applications: new heavy gauge\nbosons, Higgs to $\\tau\\tau$, and direct stop squark pair production. We find\nthat significance variables can provide additional discriminating power over\nthe original kinematic variables: $\\sim$ 20% improvement over $m_T$ in the case\nof $H\\rightarrow\\tau\\tau$ case, and $\\sim$ 30% impovement over $m_{T2}$ in the\ncase of the direct stop search.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 23:57:11 GMT"}],"update_date":"2013-10-30"}
{"id":"1303.7010","submitter":"Mikhail Shifman","authors":"M. Shifman, A. Yung","title":"Abrikosov-Nielsen-Olesen string with Non-Abelian Moduli and \"Spin-Orbit\"\n  Interaction","comments":"5 pages, no figures; v.2 One reference added, one footnote added.\n  Final version to appear in Phys. Rev. Letters; v3. Corrections in\n  proofreading incorporated","journal-ref":null,"doi":"10.1103/PhysRevLett.110.201602","report-no":"FTPI-MINN-13/11, UMN-TH-3143/13","categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is generally believed that the spontaneous breaking of the Poincar\\'e\ngroup by flux tubes (strings) generate only two zero modes localized on the\nstring and associated with the spontaneous breaking of translational invariance\n(the so-called Low-Manohar argument). Being perfectly true in many instances it\nis nevertheless nonuniversal, and have to be amended in the case of order\nparameters carrying spatial indices. We show that under certain circumstances\nadditional zero (or quasizero) modes can appear due to spin symmetry.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 00:00:53 GMT"},{"version":"v2","created":"Tue, 30 Apr 2013 19:58:08 GMT"},{"version":"v3","created":"Wed, 8 May 2013 16:56:01 GMT"}],"update_date":"2013-05-22"}
{"id":"1303.7011","submitter":"Niels Gronbech Jensen","authors":"Niels Gr{\\o}nbech-Jensen, Natha Robert Hayre, Oded Farago","title":"Application of the G-JF Discrete-Time Thermostat for Fast and Accurate\n  Molecular Simulations","comments":"Five pages, one figure. Version accepted for publication. Previous\n  title: A new Langevin thermostat for fast and accurate molecular simulations","journal-ref":"Computer Physics Communications Vol.185, p.524 (2014)","doi":"10.1016/j.cpc.2013.10.006","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.soft physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A new Langevin-Verlet thermostat that preserves the fluctuation-dissipation\nrelationship for discrete time steps, is applied to molecular modeling and\ntested against several popular suites (AMBER, GROMACS, LAMMPS) using a small\nmolecule as an example that can be easily simulated by all three packages.\nContrary to existing methods, the new thermostat exhibits no detectable changes\nin the sampling statistics as the time step is varied in the entire numerical\nstability range. The simple form of the method, which we express in the three\ncommon forms (Velocity-Explicit, Stormer-Verlet, and Leap-Frog), allows for\neasy implementation within existing molecular simulation packages to achieve\nfaster and more accurate results with no cost in either computing time or\nprogramming complexity.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 00:10:18 GMT"},{"version":"v2","created":"Tue, 21 May 2013 03:16:29 GMT"},{"version":"v3","created":"Tue, 22 Oct 2013 21:23:21 GMT"}],"update_date":"2013-12-17"}
{"id":"1303.7012","submitter":"Abedelaziz  Mohaisen","authors":"Abedelaziz Mohaisen and Omar Alrawi","title":"Unveiling Zeus","comments":"Accepted to SIMPLEX 2013 (a workshop held in conjunction with WWW\n  2013)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Malware family classification is an age old problem that many Anti-Virus (AV)\ncompanies have tackled. There are two common techniques used for\nclassification, signature based and behavior based. Signature based\nclassification uses a common sequence of bytes that appears in the binary code\nto identify and detect a family of malware. Behavior based classification uses\nartifacts created by malware during execution for identification. In this paper\nwe report on a unique dataset we obtained from our operations and classified\nusing several machine learning techniques using the behavior-based approach.\nOur main class of malware we are interested in classifying is the popular Zeus\nmalware. For its classification we identify 65 features that are unique and\nrobust for identifying malware families. We show that artifacts like file\nsystem, registry, and network features can be used to identify distinct malware\nfamilies with high accuracy---in some cases as high as 95%.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 00:11:54 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7013","submitter":"C. M. Chandrashekar","authors":"C. M. Chandrashekar and Th. Busch","title":"Quantum percolation and transition point of a directed discrete-time\n  quantum walk","comments":"17 pages, 9 figures ; Published version","journal-ref":"Scientific Reports 4, 6583 (2014)","doi":"10.1038/srep06583","report-no":null,"categories":"quant-ph cond-mat.dis-nn cond-mat.other cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantum percolation describes the problem of a quantum particle moving\nthrough a disordered system. While certain similarities to classical\npercolation exist, the quantum case has additional complexity due to the\npossibility of Anderson localisation. Here, we consider a directed\ndiscrete-time quantum walk as a model to study quantum percolation of a\ntwo-state particle on a two-dimensional lattice. Using numerical analysis we\ndetermine the fraction of connected edges required (transition point) in the\nlattice for the two-state particle to percolate with finite (non-zero)\nprobability for three fundamental lattice geometries, finite square lattice,\nhoneycomb lattice, and nanotube structure and show that it tends towards unity\nfor increasing lattice sizes. To support the numerical results we also use a\ncontinuum approximation to analytically derive the expression for the\npercolation probability for the case of the square lattice and show that it\nagrees with the numerically obtained results for the discrete case. Beyond the\nfundamental interest to understand the dynamics of a two-state particle on a\nlattice (network) with disconnected vertices, our study has the potential to\nshed light on the transport dynamics in various quantum condensed matter\nsystems and the construction of quantum information processing and\ncommunication protocols.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 00:17:38 GMT"},{"version":"v2","created":"Mon, 2 Dec 2013 23:48:41 GMT"},{"version":"v3","created":"Thu, 2 Oct 2014 01:01:11 GMT"}],"update_date":"2014-10-03"}
{"id":"1303.7014","submitter":"Junhua Zhang","authors":"Junhua Zhang, Tianqi Li, Jigang Wang, Joerg Schmalian","title":"Post-transient relaxation in graphene after an intense laser pulse","comments":"10 pages, 4 figures, submitted as contribution of the IMPACT Special\n  Topics series of the EPJ","journal-ref":null,"doi":"10.1140/epjst/e2013-01920-2","report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  High intensity laser pulses were recently shown to induce a population\ninverted transient state in graphene [T. Li et al. Phys. Rev. Lett. 108, 167401\n(2012)]. Using a combination of hydrodynamic arguments and a kinetic theory we\ndetermine the post-transient state relaxation of hot, dense, population\ninverted electrons towards equilibrium. The cooling rate and charge-imbalance\nrelaxation rate are determined from the Boltzmann-equation including\nelectron-phonon scattering. We show that the relaxation of the population\ninversion, driven by inter-band scattering processes, is much slower than the\nrelaxation of the electron temperature, which is determined by intra-band\nscattering processes. This insight may be of relevance for the application of\ngraphene as an optical gain medium.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 00:44:41 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7015","submitter":"Xiaojun Zhou","authors":"Xiaojun Zhou","title":"A Multiobjective State Transition Algorithm for Single Machine\n  Scheduling","comments":"10 pages, 4 figures","journal-ref":"Advances in Global Optimization, 2015, 95: 79-88","doi":"10.1007/978-3-319-08377-3_9","report-no":null,"categories":"math.OC cs.IT math.CO math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, a discrete state transition algorithm is introduced to solve a\nmultiobjective single machine job shop scheduling problem. In the proposed\napproach, a non-dominated sort technique is used to select the best from a\ncandidate state set, and a Pareto archived strategy is adopted to keep all the\nnon-dominated solutions. Compared with the enumeration and other heuristics,\nexperimental results have demonstrated the effectiveness of the multiobjective\nstate transition algorithm.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 00:47:17 GMT"}],"update_date":"2015-09-22"}
{"id":"1303.7016","submitter":"Deepali Lodhia","authors":"Deepali Lodhia, Daniel Brown, Frank Brueckner, Ludovico Carbone, Paul\n  Fulda, Keiko Kokeyama and Andreas Freise","title":"Phase effects due to beam misalignment on diffraction gratings","comments":"14 pages, 8 figures, submitted to Optics Express","journal-ref":null,"doi":"10.1364/OE.21.029578","report-no":null,"categories":"physics.optics gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  All-reflective interferometer configurations have been proposed for the next\ngeneration of gravitational wave detectors, with diffractive elements replacing\ntransmissive optics. However, an additional phase noise creates more stringent\nconditions for alignment stability. A framework for alignment stability with\nthe use of diffractive elements was required using a Gaussian model. We\nsuccessfully create such a framework involving modal decomposition to replicate\nsmall displacements of the beam (or grating) and show that the modal model does\nnot contain the phase changes seen in an otherwise geometric planewave\napproach. The modal decomposition description is justified by verifying\nexperimentally that the phase of a diffracted Gaussian beam is independent of\nthe beam shape, achieved by comparing the phase change between a zero-order and\nfirst-order mode beam. To interpret our findings we employ a rigorous\ntime-domain simulation to demonstrate that the phase changes resulting from a\nmodal decomposition are correct, provided that the coordinate system which\nmeasures the phase is moved simultaneously with the effective beam\ndisplacement. This indeed corresponds to the phase change observed in the\ngeometric planewave model. The change in the coordinate system does not\ninstinctively occur within the analytical framework, and therefore requires\neither a manual change in the coordinate system or an addition of the geometric\nplanewave phase factor.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 01:04:52 GMT"}],"update_date":"2017-07-26"}
{"id":"1303.7017","submitter":"Guang-Yu Guo","authors":"Guang-Yu Guo, Vasily Klimov, Shulin Sun, and Wei-Jin Zheng","title":"Metamaterial slab-based super-absorbers and perfect nanodetectors for\n  single dipole sources","comments":"Accepted for publication in Optics Express","journal-ref":"Optics Express 21, 11348 (2013)","doi":"10.1364/OE.21.011338","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose to use double negative (DNG) metamaterial slabs to build effective\nsuper-absorbers and perfect nanodetectors for single divergent sources. We\ndemonstrate by numerical simulations that an absorbing nanoparticle properly\nplaced inside a DNG slab back-covered with a perfect electric conductor or\nperfect magnetic conductor mirror can absorb up to 100% radiation energy of a\nsingle dipole source placed outside the slab. Furthermore, we also show that\neven the simple DNG slab without any absorbing nanoparticle could be used as a\nperfect absorber for both plane and divergent beams. The proposed systems may\nfocus the radiation in nanoscale and thus have applications in optical\nnanodevices for a variety of different purposes.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 01:13:25 GMT"}],"update_date":"2013-05-03"}
{"id":"1303.7018","submitter":"John Luecke","authors":"Ken Baker, Cameron Gordon, and John Luecke","title":"Bridge number and integral Dehn surgery","comments":null,"journal-ref":"Algebr. Geom. Topol. 16 (2016) 1-40","doi":"10.2140/agt.2016.16.1","report-no":null,"categories":"math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a 3-manifold M, let K be a knot and R be an annulus which meets K\ntransversely. We define the notion of the pair (R,K) being caught by a surface\nQ in the exterior of the link given by K and the boundary curves of R. For a\ncaught pair (R,K), we consider the knot K^n gotten by twisting K n times along\nR and give a lower bound on the bridge number of K^n with respect to Heegaard\nsplittings of M -- as a function of n, the genus of the splitting, and the\ncatching surface Q. As a result, the bridge number of K^n tends to infinity\nwith n. In application, we look at a family of knots K^n found by Teragaito\nthat live in a small Seifert fiber space M and where each K^n admits a Dehn\nsurgery giving the 3-sphere. We show that the bridge number of K^n with respect\nto any genus 2 Heegaard splitting of M tends to infinity with n. This contrasts\nwith other work of the authors as well as with the conjectured picture for\nknots in lens spaces that admit Dehn surgeries giving the 3-sphere.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 01:23:15 GMT"}],"update_date":"2016-03-09"}
{"id":"1303.7019","submitter":"Kicheon Kang","authors":"Kicheon Kang","title":"Local Geometric Phase and Quantum State Tomography in a Superconducting\n  Qubit","comments":"5 pages, 1 figure","journal-ref":null,"doi":"10.3938/jkps.64.567","report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate quantum state reconstruction of a superconducting qubit\nthreaded by an Aharonov-Bohm flux, with particular attention to the local\ngeometric phase. A state reconstruction scheme is introduced with a proper\naccount of the local geometric phase generated by Faraday's law of induction.\nOur scheme is based on measurement of three complementary quantities, that is,\nthe extra charge and two local currents. Incorporating time-reversal symmetry\nand the Faraday's law, we show that the full density matrix can be\nreconstructed without ambiguity in the choice of gauge. This procedure clearly\ndemonstrates that the quantum Faraday effect plays an essential role in the\ndynamics of a quantum system that involves Aharonov-Bohm flux.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 01:31:02 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7020","submitter":"Markus Grassl","authors":"Salman Beigi, Jianxin Chen, Markus Grassl, Zhengfeng Ji, Qiang Wang\n  and Bei Zeng","title":"Symmetries of Codeword Stabilized Quantum Codes","comments":"15 pages, 1 figure. Accepted by TQC 2013. Version 2: Funding\n  information added; typos corrected","journal-ref":null,"doi":"10.4230/LIPIcs.TQC.2013.192","report-no":null,"categories":"quant-ph cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Symmetry is at the heart of coding theory. Codes with symmetry, especially\ncyclic codes, play an essential role in both theory and practical applications\nof classical error-correcting codes. Here we examine symmetry properties for\ncodeword stabilized (CWS) quantum codes, which is the most general framework\nfor constructing quantum error-correcting codes known to date. A CWS code Q can\nbe represented by a self-dual additive code S and a classical code C, i.,e.,\nQ=(S,C), however this representation is in general not unique. We show that for\nany CWS code Q with certain permutation symmetry, one can always find a\nself-dual additive code S with the same permutation symmetry as Q such that\nQ=(S,C). As many good CWS codes have been found by starting from a chosen S,\nthis ensures that when trying to find CWS codes with certain permutation\nsymmetry, the choice of S with the same symmetry will suffice. A key step for\nthis result is a new canonical representation for CWS codes, which is given in\nterms of a unique decomposition as union stabilizer codes. For CWS codes, so\nfar mainly the standard form (G,C) has been considered, where G is a graph\nstate. We analyze the symmetry of the corresponding graph of G, which in\ngeneral cannot possess the same permutation symmetry as Q. We show that it is\nindeed the case for the toric code on a square lattice with translational\nsymmetry, even if its encoding graph can be chosen to be translational\ninvariant.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 01:48:26 GMT"},{"version":"v2","created":"Mon, 8 Apr 2013 13:17:24 GMT"}],"update_date":"2013-12-30"}
{"id":"1303.7021","submitter":"Guoliang Lv","authors":"Guoliang Lu, Chunhua Zhu, Philipp Podsiadlowski","title":"Dust Formation in the Ejecta of Common Envelope Systems","comments":"11pages, 7 figures, accepted for publication by ApJ","journal-ref":null,"doi":"10.1088/0004-637X/768/2/193","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The material that is ejected in a common-envelope (CE) phase in a close\nbinary system provides an ideal environment for dust formation. By constructing\na simple toy model to describe the evolution of the density and the temperature\nof CE ejecta and using the \\emph{AGBDUST} code to model dust formation, we show\nthat dust can form efficiently in this environment. The actual dust masses\nproduced in the CE ejecta depend strongly on their temperature and density\nevolution. We estimate the total dust masses produced by CE evolution by means\nof a population synthesis code and show that, compared to dust production in\nAGB stars, the dust produced in CE ejecta may be quite significant and could\neven dominate under certain circumstances.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 02:04:15 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7022","submitter":"Seung Hwan Hong","authors":"Seung Hwan Hong and Han-Yong Choi","title":"Angle and frequency dependence of self-energy from spin fluctuations\n  mediated d-wave pairing for high temperature superconductors","comments":"15 pages, 13 figures, Submitted to: J. Phys.: Condens. Matter","journal-ref":null,"doi":"10.1088/0953-8984/25/36/365702","report-no":null,"categories":"cond-mat.supr-con","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigated the characteristics of the spin fluctuations mediated\nsuperconductivity employing the Eliashberg formalism. The effective interaction\nbetween electrons was modeled in terms of the spin susceptibility measured by\nthe inelastic neutron scattering experiments on single crystal La2-xSrxCuO4\nsuperconductors. The diagonal self-energy and off-diagonal self-energy were\ncalculated by solving the coupled Eliashberg equation self-consistently for\nchosen spin susceptibility and tight-binding dispersion of electrons. The full\nmomentum and frequency dependence of the self-energy is presented for the\noptimal, overdoped, and underdoped LSCO cuprates in superconductive state.\nThese results may be compared with the experimentally deduced self-energy from\nARPES experiments.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 02:15:07 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7023","submitter":"Tomohiro Matsuda","authors":"Seishi Enomoto, Tomohiro Matsuda","title":"Curvaton mechanism after multi-field inflation","comments":"10 pages, 2 figures, accepted for publication in PRD","journal-ref":null,"doi":"10.1103/PhysRevD.87.083513","report-no":null,"categories":"hep-ph astro-ph.CO hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The evolution of the curvature perturbation after multi-field inflation is\nstudied in the light of the curvaton mechanism. Past numerical studies show\nthat many-field inflation causes significant evolution of the curvature\nperturbation after inflation, which generates significant non-Gaussianity at\nthe same time. We reveal the underlying mechanism of the evolution and show\nthat the evolution is possible in a typical two-field inflation model.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 02:28:48 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7024","submitter":"Lei Zhang","authors":"Lei Zhang","title":"$Sp_{2n}(F_{q^{2}})$-Invariants In Irreducible Unipotent Representations\n  of $Sp_{4n}(F_{q})$","comments":"29 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RT math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that for any irreducible representation of $Sp_{4n}(F_{q})$, the\nsubspace of all its $Sp_{2n}(F_{q^{2}})$-invariants is at most one-dimensional.\nIn terms of Lusztig symbols, we give a complete list of irreducible unipotent\nrepresentations of $Sp_{4n}(F_{q})$ which have a nonzero\n$Sp_{2n}(F_{q^{2}})$-invariant and, in particular, we prove that every\nirreducible unipotent cuspidal representation has a one-dimensional subspace of\n$Sp_{2n}(F_{q^{2}})$-invariants. As an application, we give an elementary proof\nof the fact that the unipotent cuspidal representation is defined over $Q$,\nwhich was proved by Lusztig.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 02:43:40 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7025","submitter":"Paco Talero Lopez","authors":"Paco Talero, Orlando Organista and Luis H. Barbosa","title":"Velocities: mean, average and instantaneous in uniform accelerated\n  motion, some pedagogical comments","comments":"4 pages,2 figures. Submitted to Revista Brasileira de Ensino de\n  Fisica, in Portuguese","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ed-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The relation among instantaneous, mean and average velocities in\none-dimensional motion with constant acceleration is studied. It was shown that\nthe instant velocity evaluated in the time $t_{p}=\\left(t_2+t_1\\right)/2$ is\nsimilar to the mean and average velocities evaluated between the times $t_1$\nand $t_2$. The reason for relations illustrated before were shown in detail.\nAlso, the results obtained were used to propose a pedagogical strategy in order\nto study the one-dimensional motion with constant acceleration as a natural\nextension of one-dimensional motion with constant velocity.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 02:47:07 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7026","submitter":"Farzad Hessar","authors":"Farzad Hessar, and Sumit Roy","title":"Minimum Energy Source Coding for Asymmetric Modulation with Application\n  to RFID","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Minimum energy (ME) source coding is an effective technique for efficient\ncommunication with energy-constrained devices, such as sensor network nodes. In\nthis paper, the principles of generalized ME source coding is developed that is\nbroadly applicable. Two scenarios - fixed and variable length codewords - are\nanalyzed. The application of this technique to RFID systems where ME source\ncoding is particularly advantageous due to the asymmetric nature of data\ncommunications is demonstrated, a first to the best of our knowledge.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:00:02 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7027","submitter":"Hiroki Sako","authors":"Hiroki Sako","title":"Property A for coarse spaces","comments":"11 pages. We give proofs for basic facts, which have been omitted in\n  arXiv:1212.5900","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG math.OA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Property A introduced by Guoliang Yu is an amenability-type property for\nmetric spaces. In this article, we study property A for uniformly locally\nfinite coarse spaces. Main examples of coarse spaces are a metric space, a set\nequipped with a discrete group action, and a sequence of finitely generated\ngroups. The purpose of this article is to give complete proofs to related basic\nfacts.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:11:47 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7028","submitter":"Gabriel Menezes","authors":"G. Menezes, B. F. Svaiter and N. F. Svaiter","title":"Riemann zeta zeros and prime number spectra in quantum field theory","comments":"Revised version, 18 pages","journal-ref":"Int. J. Mod. Phys. A 28, 1350128 (2013)","doi":"10.1142/S0217751X13501285","report-no":null,"categories":"math-ph hep-th math.MP math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Riemann hypothesis states that all nontrivial zeros of the zeta function\nlie in the critical line $\\Re(s)=1/2$. Hilbert and P\\'olya suggested that one\npossible way to prove the Riemann hypothesis is to interpret the nontrivial\nzeros in the light of spectral theory. Following this approach, we discuss a\nnecessary condition that such a sequence of numbers should obey in order to be\nassociated with the spectrum of a linear differential operator of a system with\ncountably infinite number of degrees of freedom described by quantum field\ntheory. The sequence of nontrivial zeros is zeta regularizable. Then,\nfunctional integrals associated with hypothetical systems described by\nself-adjoint operators whose spectra is given by this sequence can be\nconstructed. However, if one considers the same situation with primes numbers,\nthe associated functional integral cannot be constructed, due to the fact that\nthe sequence of prime numbers is not zeta regularizable. Finally, we extend\nthis result to sequences whose asymptotic distributions are not \"far away\" from\nthe asymptotic distribution of prime numbers.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:16:10 GMT"},{"version":"v2","created":"Fri, 2 Aug 2013 20:27:37 GMT"}],"update_date":"2014-01-29"}
{"id":"1303.7029","submitter":"Chol-Rim Min Mr","authors":"Kang-Il Ri, Yun-Ho An and Chang-Il Rim","title":"The Relation Between Diagrams of a Knot and Its Unknotting Number","comments":"Withdrawn because the theorem 4 is not correct","journal-ref":"International Symposium in Commemoration of the 65th Anniversary\n  of the Foundation of Kim Il Sung University (Mathematics)20-21. Sep.\n  Juche100(2011), Pyongyang DPR Korea, 79-83, 2012","doi":null,"report-no":"KISU-MATH-2011-E-C-010","categories":"math.GT math.DG math.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The unknotting number is the classical invariant of a knot. However, its\ndetermination is difficult in general. To obtain the unknotting number from\ndefinition one has to investigate all possible diagrams of the knot. We tried\nto show the unknotting number can be obtained from any one diagram of the knot.\nTo do this we tried to prove the unknotting number is not changed under\nRiedemiester moves, but such a proposition is not correct. Reidemeister II move\ncan change unknotting number. See Nakanishi-Bleiler example. So this article is\nwithdrawn.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:28:28 GMT"},{"version":"v2","created":"Mon, 24 Jun 2013 11:10:18 GMT"}],"update_date":"2013-06-25"}
{"id":"1303.7030","submitter":"Stefano Rini","authors":"Stefano Rini, Ernest Kurniawany, Levan Ghaghanidze, and Andrea\n  Goldsmithy","title":"Energy Efficient Cooperative Strategies for Relay-Assisted Downlink\n  Cellular Systems, Part I: Theoretical Framework","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The impact of cognition on the energy efficiency of a downlink cellular\nsystem in which multiple relays assist the transmission of the base station is\nconsidered. The problem is motivated by the practical importance of\nrelay-assisted solutions in mobile networks, such as LTE-A, in which\ncooperation among relays holds the promise of greatly improving the energy\nefficiency of the system. We study the fundamental tradeoff between the power\nconsumption at the base station and the level of cooperation and cognition at\nthe relay nodes. By distributing the same message to multiple relays, the base\nstation consumes more power but it enables cooperation among the relays, thus\nmaking the transmission between relays to destination a multiuser cognitive\nchannel. Cooperation among the relays allows for a reduction of the power used\nto transmit from the relays to the end users due to interference management and\nthe coherent combining gains. These gain are present even in the case of\npartial or unidirectional transmitter cooperation, which is the case in\ncognitive channels such as the cognitive interference channel and the\ninterference channel with a cognitive relay. We therefore address the problem\nof determining the optimal level of cooperation at the relays which results in\nthe smallest total power consumption when accounting for the power reduction\ndue to cognition. A practical design examples and numerical simulation are\npresented in a companion paper (part II).\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:32:20 GMT"},{"version":"v2","created":"Fri, 29 Mar 2013 17:03:12 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7031","submitter":"Seng Ghee Tan","authors":"Ji Chen, Mansoor Bin Abdul Jalil, Seng Ghee Tan","title":"Spin Torque on Magnetic Textures Coupled to the Surface of a\n  Three-Dimensional Topological Insulator","comments":"17 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate theoretically the spin torque and magnetization dynamic in a\nthin ferromagnetic (FM) layer with spatially varying magnetization. The FM\nlayer is deposited on the surface of a topological insulator (TI). In the limit\nof the adiabatic relaxation of electron spin along the magnetization, the\ninteraction between the exchange interaction and the Rashba-like surface\ntexture of a TI yields a topological gauge field. Under the gauge field and an\napplied current, spin torque is induced according to the direction of the\ncurrent. We derived the corresponding effective anisotropy field and hence the\nmodified Landau-Lifshitz-Gilbert equation, which describes the spin torque and\nthe magnetization dynamic. In addition, we study the effective field for\nexemplary magnetic textures, such as domain wall, skyrmion, and vortex\nconfigurations. The estimated strength of the effective field is comparable to\nthe switching fields of typical FM materials, and hence can significantly\ninfluence the dynamics of the FM layer.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:34:09 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7032","submitter":"Zhe Yao","authors":"Zhe Yao, Vincent Gripon and Michael G. Rabbat","title":"A Massively Parallel Associative Memory Based on Sparse Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.DC cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Associative memories store content in such a way that the content can be\nlater retrieved by presenting the memory with a small portion of the content,\nrather than presenting the memory with an address as in more traditional\nmemories. Associative memories are used as building blocks for algorithms\nwithin database engines, anomaly detection systems, compression algorithms, and\nface recognition systems. A classical example of an associative memory is the\nHopfield neural network. Recently, Gripon and Berrou have introduced an\nalternative construction which builds on ideas from the theory of error\ncorrecting codes and which greatly outperforms the Hopfield network in\ncapacity, diversity, and efficiency. In this paper we implement a variation of\nthe Gripon-Berrou associative memory on a general purpose graphical processing\nunit (GPU). The work of Gripon and Berrou proposes two retrieval rules,\nsum-of-sum and sum-of-max. The sum-of-sum rule uses only matrix-vector\nmultiplication and is easily implemented on the GPU. The sum-of-max rule is\nmuch less straightforward to implement because it involves non-linear\noperations. However, the sum-of-max rule gives significantly better retrieval\nerror rates. We propose a hybrid rule tailored for implementation on a GPU\nwhich achieves a 880-fold speedup without sacrificing any accuracy.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:49:57 GMT"},{"version":"v2","created":"Sun, 21 Jul 2013 14:29:21 GMT"}],"update_date":"2013-07-23"}
{"id":"1303.7033","submitter":"Manfred Bucher","authors":"Manfred Bucher","title":"Coulomb-oscillator explanation of striped STM images of superconductive\n  copper oxides","comments":"8 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.gen-ph","license":"http://creativecommons.org/licenses/by-nc-sa/3.0/","abstract":"  Asymmetric scanning tunneling microscopy (STM) of the CuO2 plane of\nCa2-xNaxCuO2Cl2, x = 0.125, shows a square domain structure with edge length\nfour times the compound's lattice constant a0 (Cu-O-Cu distance). The domain\nstructure is a direct consequence of the 4a0 by 4a0 superlattice formed by\nvertical Na+ pairs (oriented parallel to the crystal's c axis) that substitute\nCa2+ ions. The surrounding O2- ions are displaced away from, and the Cu2+ ions\ntoward the Na+ pairs. Contrary to the fourfold symmetry of the CuO2 plane, the\nstable displacement configuration has a twofold symmetry, dominated by large\nand, respectively, small displacement of opposite O2- ions being nearest\nneighbors to each vertical Na+ pair. The ion displacements give rise to\nsufficient squeeze of certain O2- ions that, by the Coulomb-oscillator model of\nsuperconductivity, prevents lateral overswing of their excited 3s electrons.\nThe axial 3s oscillations are predominantly oriented in the directions of O2-\nion displacements. The observed ladder pattern in the domains provides a direct\nimaging of the 3s Coulomb oscillators. The 'sidepieces' of the ladders\ncorrespond to long unidirectional pathways for 3s electrons in the CuO2 plane.\nThey account for superconductivity. The findings lend support to the validity\nof the Coulomb-oscillator model of superconductivity.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 04:03:30 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7034","submitter":"Stefano Rini","authors":"Stefano Riniy, Ernest Kurniawan, Levan Ghaghanidze, and Andrea\n  Goldsmith","title":"Energy Efficient Cooperative Strategies for Relay-Assisted Downlink\n  Cellular Systems Part II: Practical Design","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a companion paper [1], we present a general approach to evaluate the\nimpact of cognition in a downlink cellular system in which multiple relays\nassist the transmission of the base station. This approach is based on a novel\ntheoretical tool which produces transmission schemes involving rate-splitting,\nsuperposition coding and interference decoding for a network with any number of\nrelays and receivers. This second part focuses on a practical design example\nfor a network in which a base station transmits to three receivers with the aid\nof two relay nodes. For this simple network, we explicitly evaluate the impact\nof relay cognition and precisely characterize the trade offs between the total\nenergy consumption and the rate improvements provided by relay cooperation.\nThese closedform expressions provide important insights on the role of\ncognition in larger networks and highlights interesting interference management\nstrategies. We also present a numerical simulation setup in which we fully\nautomate the derivation of achievable rate region for a general relay-assisted\ndownlink cellular network. Our simulations clearly show the great advantages\nprovided by cooperative strategies at the relays as compared to the\nuncoordinated scenario under varying channel conditions and target rates. These\nresults are obtained by considering a large number of transmission strategies\nfor different levels of relay cognition and numerically determining one that is\nthe most energy efficient. The limited computational complexity of the\nnumerical evaluations makes this approach suitable for the optimization of\ntransmission strategies for larger networks.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 04:09:12 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7035","submitter":"We-Fu Chang","authors":"We-Fu Chang, Wei-Ping Pan, and Fanrong Xu","title":"An effective gauge-Higgs operators analysis of new physics associated\n  with the Higgs","comments":"32 pages, 11 figures; UV complete model section revised, typos\n  corrected, and refernces added","journal-ref":"Phys.Rev.D88,033004(2013)","doi":"10.1103/PhysRevD.88.033004","report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the new physics(NP) related to the recent discovered 125 GeV Higgs\nby employing an important subset of the standard model(SM) gauge invariant\ndimension-six operators constructed by the the SM Higgs and gauge fields.\nExplicitly, we perform a model-independent study on the production and decays\nof the Higgs, the electric dipole moments(EDM) of the neutron and the electron,\nand we take into account the anomalous magnetic dipole moments of muon and\nelectron as well.\n  We find that, even all Higgs decay channels agree with the SM predictions,\nthe SM theoretical uncertainties provide a lot of room to host NP associated\nwith the 125 GeV boson. A linear relation is revealed in our numerical study\nthat $\\mu_{ZZ}\\simeq \\mu_{WW}$ and $ 0.6 \\lesssim \\mu_{ZZ,WW} \\lesssim 1.4$ at\n95% CL with or without the EDM's constraints. The neutron and electron EDM's\nseverely constrain the relevant Wilson coefficients. Therefore the CP violating\ncomponents in the $h\\rightarrow WW, ZZ$ channels are too small, $\\sim{\\cal\nO}(10^{-5})$, to be detected at LHC. However, we point out that even the parity\nof the 125GeV boson has been largely determined to be even in the $h\\to ZZ$\nchannel, one should pay special attention to the potentially large CP violation\nin the $h\\to \\gamma\\gamma$ and $h\\to \\gamma Z$ channels. This should be\nseriously checked in the future spin correlation experiments.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 04:18:18 GMT"},{"version":"v2","created":"Wed, 14 Aug 2013 21:14:49 GMT"}],"update_date":"2013-08-16"}
{"id":"1303.7036","submitter":"Dibyendu Roy","authors":"Dibyendu Roy, C. J. Bolech, and Nayana Shah","title":"Nature of the zero-bias conductance peak associated with Majorana bound\n  states in topological phases of semiconductor-superconductor hybrid\n  structures","comments":"10 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rashba spin-orbit coupled semiconductor-superconductor hybrid structures in\nthe presence of Zeeman splitting have emerged as the first experimentally\nrealizable topological superconductor supporting zero-energy Majorana bound\nstates. However, recent experimental studies in these hybrid structures are not\nin complete agreement with the theoretical predictions, for example, the\nobserved height of the zero-bias conductance peak (ZBCP) associated with the\nMajorana bound states is less than 10% of the predicted quantized value 2e^2/h.\nWe try to understand the sources of various discrepancies between the recent\nexperiments and the earlier theories by starting from a microscopic theory and\nstudying non-equilibrium transport in these systems at arbitrary temperatures\nand applied bias voltages. Our approach involves quantum Langevin equations and\nnon-equilibrium Green's functions. Here we are able to model the tunnel\ncoupling between the one-dimensional semiconductor-superconductor hybrid\nstructure and the metallic leads realistically; study the role of tunnel\ncoupling on the height of the ZBCP and the subgap conductance; predict the\nnature of the splitting of the ZBCP with an increasing magnetic field beyond\nthe critical field; show the behavior of the ZBCP with an increasing\ngate-controlled onsite potential; and study the evolution of the full\ndifferential conductance across the topological quantum phase transition. When\nthe applied magnetic field is quite large compared to the Rashba splitting and\nthe bulk energy gap is much reduced, we find the ZBCP even for an onsite\npotential much larger than the applied magnetic field. The height of the\ncorresponding ZBCP depends on the tunnel coupling even at zero temperature and\ncan be much smaller than 2e^2/h.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 04:36:29 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7037","submitter":"Jonathan Spreer","authors":"Benjamin A. Burton, Thomas Lewiner, Jo\\~ao Paix\\~ao, Jonathan Spreer","title":"Parameterized Complexity of Discrete Morse Theory","comments":"To appear in Proceedings of the Twenty-Ninth Annual Symposium on\n  Computational Geometry (SoCG). 25 pages, 8 figures, 2 tables","journal-ref":"ACM Trans. Math. Softw., 42(1):24 pages, 2016","doi":"10.1145/2738034","report-no":null,"categories":"cs.CG cs.CC math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Optimal Morse matchings reveal essential structures of cell complexes which\nlead to powerful tools to study discrete geometrical objects, in particular\ndiscrete 3-manifolds. However, such matchings are known to be NP-hard to\ncompute on 3-manifolds, through a reduction to the erasability problem.\n  Here, we refine the study of the complexity of problems related to discrete\nMorse theory in terms of parameterized complexity. On the one hand we prove\nthat the erasability problem is W[P]-complete on the natural parameter. On the\nother hand we propose an algorithm for computing optimal Morse matchings on\ntriangulations of 3-manifolds which is fixed-parameter tractable in the\ntreewidth of the bipartite graph representing the adjacency of the 1- and\n2-simplexes. This algorithm also shows fixed parameter tractability for\nproblems such as erasability and maximum alternating cycle-free matching. We\nfurther show that these results are also true when the treewidth of the dual\ngraph of the triangulated 3-manifold is bounded. Finally, we investigate the\nrespective treewidths of simplicial and generalized triangulations of\n3-manifolds.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 04:49:25 GMT"}],"update_date":"2018-10-24"}
{"id":"1303.7038","submitter":"Jorge Mastache","authors":"Jorge Mastache, Axel de la Macorra","title":"Extra relativistic degrees of freedom without extra particles using\n  Planck data","comments":"9 pages, 7 figures, 2 Tables","journal-ref":null,"doi":"10.1103/PhysRevD.88.043506","report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A recent number of analysis of cosmological data have shown indications for\nthe presence of extra radiation beyond the standard model at equality and\nnucleosynthesis epoch, which has been usually interpreted as an effective\nnumber of neutrinos, Neff > 3.046. In this work we establish the theoretical\nbasis for a particle physics-motivated model (Bound Dark Matter, BDM) which\nexplain the need of extra radiation. The BDM model describes dark matter\nparticles which are relativistic at a scale below a < ac, these particles\nacquire mass with an initial velocity, vc, at scales a > ac due to\nnon-perturbative methods, as protons and neutrons do, this process is described\nby a time dependent equation of state, w_bdm(a). Owing to this behavior the\namount of extra radiation change as a function of the scale factor, this entail\nthat the extra relativistic degrees of freedom Nex may also vary as a function\nof the scale factor. This is favored by data at CMB and BBN epochs. We compute\nthe range of values of the BDM model parameters, xc = ac*vc, that explain the\nvalues obtained for the 4He at BBN and Neff at equality. Combining different\nanalysis we compute the value xc = 4.13x10^{-5} and vc = 0.37. We conclude that\nwe can account for the apparent extra neutrino degrees of freedom Nex using a\nphase transition in the dark matter with a time dependent equation of state\nwith no need for introducing extra relativistic particles.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 04:53:44 GMT"},{"version":"v2","created":"Mon, 29 Apr 2013 20:16:29 GMT"}],"update_date":"2013-08-14"}
{"id":"1303.7039","submitter":"Sarabjot Singh","authors":"Sarabjot Singh and Jeffrey G. Andrews","title":"Joint Resource Partitioning and Offloading in Heterogeneous Cellular\n  Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In heterogeneous cellular networks (HCNs), it is desirable to offload mobile\nusers to small cells, which are typically significantly less congested than the\nmacrocells. To achieve sufficient load balancing, the offloaded users often\nhave much lower SINR than they would on the macrocell. This SINR degradation\ncan be partially alleviated through interference avoidance, for example time or\nfrequency resource partitioning, whereby the macrocell turns off in some\nfraction of such resources. Naturally, the optimal offloading strategy is\ntightly coupled with resource partitioning; the optimal amount of which in turn\ndepends on how many users have been offloaded. In this paper, we propose a\ngeneral and tractable framework for modeling and analyzing joint resource\npartitioning and offloading in a two-tier cellular network. With it, we are\nable to derive the downlink rate distribution over the entire network, and an\noptimal strategy for joint resource partitioning and offloading. We show that\nload balancing, by itself, is insufficient, and resource partitioning is\nrequired in conjunction with offloading to improve the rate of cell edge users\nin co-channel heterogeneous networks.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 04:54:35 GMT"},{"version":"v2","created":"Wed, 21 Aug 2013 03:07:31 GMT"}],"update_date":"2013-08-22"}
{"id":"1303.7040","submitter":"E.K. Liu","authors":"X. M. Zhang, R S. Ma, X. C. Liu, E. K. Liu, G. D. Liu, Z. Y. Liu, W.\n  H. Wang, and G. H. Wu","title":"Topological Insulators in Hexagonal Wurtzite-type Binary Compounds","comments":"20 pages, 5 figures, submitted for publication","journal-ref":"EPL, 103 (2013) 57012","doi":"10.1209/0295-5075/103/57012","report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose new topological insulators in hexagonal wurtzite-type binary\ncompounds based on the first principles calculations. It is found that two\ncompounds AgI and AuI are three-dimensional topological insulators with a\nnaturally opened band-gap at Fermi level. From band inversion mechanism point\nview, this new family of topological insulators is similar with HgTe, which has\ns (Gamma 6) - p (Gamma 8) band inversion. Our results strongly support that the\nspin-orbit coupling is not an essential factor to the band inversion mechanism;\non the contrary, it is mainly responsible to the formation of a global band gap\nfor the studied topological insulators. We further theoretically explore the\nfeasibility of tuning the topological order of the studied compounds with two\ntypes of strains. The results show that the uniaxial strain can contribute\nextremely drastic impacts to the band inversion behavior, which provide an\neffective approach to induce topological phase transition.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 05:05:35 GMT"}],"update_date":"2013-10-21"}
{"id":"1303.7041","submitter":"Monica Patriche","authors":"Monica Patriche","title":"The core of the games with fractional linear utility functions","comments":"15 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/3.0/","abstract":"  We consider fractional linear programming production games for the\nsingle-objective and multiobjective cases. We use the method of Chakraborty and\nGupta (2002) in order to transform the fractional linear programming problems\ninto linear programming problems. A cooperative game is attached and we prove\nthe non-emptiness of the core by using the duality theory from the linear\nprogramming. In the multiobjective case, we give a characterization of the\nStable outcome of the associate cooperative game, which is balanced. We also\nconsider the cooperative game associated to an exchange economy with a finite\nnumber of agents.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 05:29:34 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7042","submitter":"John Page Dr","authors":"W.K. Hildebrand, A. Strybulevych, S.E. Skipetrov, B.A. van Tiggelen,\n  and J.H. Page","title":"Observation of infinite-range intensity correlations above, at and below\n  the 3D Anderson localization transition","comments":"13 pages, 11 figures (main text plus supplemental information).\n  Updated version includes an improved introductory paragraph, minor text\n  revisions, a revised title and additional supplemental information on the\n  experimental details","journal-ref":"Physical Review Letters, 112, 073902 (2014)","doi":"10.1103/PhysRevLett.112.073902","report-no":null,"categories":"cond-mat.dis-nn cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate long-range intensity correlations on both sides of the\nAnderson transition of classical waves in a three-dimensional (3D) disordered\nmaterial. Our ultrasonic experiments are designed to unambiguously detect a\nrecently predicted infinite-range C0 contribution, due to local density of\nstates fluctuations near the source. We find that these C0 correlations, in\naddition to C2 and C3 contributions, are significantly enhanced near mobility\nedges. Separate measurements of the inverse participation ratio reveal a link\nbetween C0 and the anomalous dimension \\Delta_2, implying that C0 may also be\nused to explore the critical regime of the Anderson transition.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 05:40:58 GMT"},{"version":"v2","created":"Thu, 11 Jul 2013 16:16:38 GMT"},{"version":"v3","created":"Sat, 23 Nov 2013 00:42:02 GMT"}],"update_date":"2014-02-27"}
{"id":"1303.7043","submitter":"Chunhua Shen","authors":"Fumin Shen, Chunhua Shen, Qinfeng Shi, Anton van den Hengel, Zhenmin\n  Tang","title":"Inductive Hashing on Manifolds","comments":"Appearing in IEEE Conf. Computer Vision and Pattern Recognition, 2013","journal-ref":null,"doi":"10.1109/CVPR.2013.205","report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Learning based hashing methods have attracted considerable attention due to\ntheir ability to greatly increase the scale at which existing algorithms may\noperate. Most of these methods are designed to generate binary codes that\npreserve the Euclidean distance in the original space. Manifold learning\ntechniques, in contrast, are better able to model the intrinsic structure\nembedded in the original high-dimensional data. The complexity of these models,\nand the problems with out-of-sample data, have previously rendered them\nunsuitable for application to large-scale embedding, however. In this work, we\nconsider how to learn compact binary embeddings on their intrinsic manifolds.\nIn order to address the above-mentioned difficulties, we describe an efficient,\ninductive solution to the out-of-sample data problem, and a process by which\nnon-parametric manifold learning may be used as the basis of a hashing method.\nOur proposed approach thus allows the development of a range of new hashing\ntechniques exploiting the flexibility of the wide variety of manifold learning\napproaches available. We particularly show that hashing on the basis of t-SNE .\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 05:45:21 GMT"}],"update_date":"2016-11-17"}
{"id":"1303.7044","submitter":"Hwa Jeong Lee","authors":"Kyungpyo Hong, Ho Lee, Hwa Jeong Lee, and Seungsang Oh","title":"Upper bound on the total number of knot $n$-mosaics","comments":"6 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Lomonaco and Kauffman introduced a knot mosaic system to give a definition of\na quantum knot system which can be viewed as a blueprint for the construction\nof an actual physical quantum system. A knot $n$-mosaic is an $n \\times n$\nmatrix of 11 kinds of specific mosaic tiles representing a knot or a link by\nadjoining properly that is called suitably connected. $D_n$ denotes the total\nnumber of all knot $n$-mosaics. Already known is that $D_1=1$, $D_2=2$, and\n$D_3=22$. In this paper we establish the lower and upper bounds on $D_n$\n$$\\frac{2}{275}(9 \\cdot 6^{n-2} + 1)^2 \\cdot 2^{(n-3)^2} \\ \\leq \\ D_n \\ \\leq \\\n\\frac{2}{275}(9 \\cdot 6^{n-2} + 1)^2 \\cdot (4.4)^{(n-3)^2}.$$ and find the\nexact number of $D_4 = 2594$.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:02:21 GMT"},{"version":"v2","created":"Tue, 9 Apr 2013 07:56:34 GMT"},{"version":"v3","created":"Mon, 10 Nov 2014 12:38:34 GMT"}],"update_date":"2014-11-11"}
{"id":"1303.7045","submitter":"Sudip Kumar haldar","authors":"Sudip Kumar Haldar, Barnali Chakrabarti, Tapan Kumar Das, Anindya\n  Biswas","title":"Correlated many-body calculation to study characteristics of Shannon\n  information entropy for ultracold trapped interacting bosons","comments":"Accepted in Physical Review A (2013)","journal-ref":"Phys. Rev. A 88, 033602 (2013)","doi":"10.1103/PhysRevA.88.033602","report-no":null,"categories":"cond-mat.quant-gas quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A correlated many-body calculation is presented to characterize the Shannon\ninformation entropy of trapped interacting bosons. We reformulate the one-body\nShannon information entropy in terms of the one-body probability density. The\nminimum limit of the entropy uncertainty relation (EUR) is approached by making\n$N$ very small in our numerical work. We examine the effect of correlations in\nthe calculation of information entropy. Comparison with the mean-field result\nshows that the correlated basis function is indeed required to characterize the\nimportant features of the information entropies. We also accurately calculate\nthe point of critical instability of an attractive BEC, which is in close\nagreement with the experimental value. Next we calculate two-body entropies in\nposition and momentum spaces and study quantum correlations in the attractive\nBEC.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:05:05 GMT"},{"version":"v2","created":"Tue, 13 Aug 2013 04:29:02 GMT"}],"update_date":"2013-09-16"}
{"id":"1303.7046","submitter":"Kazunori Noguchi","authors":"Kazunori Noguchi","title":"Ramified coverings of small categories","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CT math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a ramified covering of small categories, and we show three\nproperties of the notion: the Riemann-Hurwitz formula holds for a ramified\ncovering of finite categories, the zeta function of $C$ divides that of\n$\\widetilde{C}$ for a ramified covering $\\map{P}{\\widetilde{C}}{C}$ of finite\ncategories, and the classifying space of a $d$-fold ramified covering of small\ncategories is also a $d$-fold ramified covering in the sense of Dold\n\\cite{Dol86}.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:09:22 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7047","submitter":"Jesse Vaitkus","authors":"Jesse A. Vaitkus and Andrew D. Greentree","title":"Digital three-state adiabatic passage","comments":"8 pages, 9 figures, comments welcome","journal-ref":"Phys. Rev. A 87, 063820 (2013)","doi":"10.1103/PhysRevA.87.063820","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explore protocols for three-state adiabatic passage where the tunnel\nmatrix elements are varied digitally, rather than smoothly as is the case with\nconventional adiabatic passage. In particular, we focus on the STIRAP and\nrelated three-state schemes where the control is applied stepwise, with either\nequal spaced levels for the tunnel matrix elements or uniform pulse lengths.\nOur results show that the evolution typically shows the hallmarks of\nconventional adiabatic passage, although with additional resonances exhibiting\nno state transfer.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:16:11 GMT"},{"version":"v2","created":"Fri, 17 May 2013 07:15:37 GMT"}],"update_date":"2013-07-09"}
{"id":"1303.7048","submitter":"Zuoqiang Shi","authors":"Thomas Y. Hou, Zuoqiang Shi, Peyman Tavallali","title":"Convergence of a data-driven time-frequency analysis method","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a recent paper, Hou and Shi introduced a new adaptive data analysis method\nto analyze nonlinear and non-stationary data. The main idea is to look for the\nsparsest representation of multiscale data within the largest possible\ndictionary consisting of intrinsic mode functions of the form $\\{a(t)\n\\cos(\\theta(t))\\}$, where $a \\in V(\\theta)$, $V(\\theta)$ consists of the\nfunctions smoother than $\\cos(\\theta(t))$ and $\\theta'\\ge 0$. This problem was\nformulated as a nonlinear $L^0$ optimization problem and an iterative nonlinear\nmatching pursuit method was proposed to solve this nonlinear optimization\nproblem. In this paper, we prove the convergence of this nonlinear matching\npursuit method under some sparsity assumption on the signal. We consider both\nwell-resolved and sparse sampled signals. In the case without noise, we prove\nthat our method gives exact recovery of the original signal.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:20:13 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7049","submitter":"Fang Li","authors":"Fang Li, Zongzhu Lin","title":"Approach to artinian algebras via natural quivers","comments":"19 pages","journal-ref":"Trans Amer Math Soc 364(3)(2012) 1395-1411","doi":null,"report-no":null,"categories":"math.RT math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given an Artinian algebra $A$ over a field $k$, there are several\ncombinatorial objects associated to $A$. They are the diagram $D_A$ as defined\nin [DK], the natural quiver $\\Delta_A$ defined in \\cite{Li} (cf. Section 2),\nand a generalized version of $k$-species $(A/r, r/r^2)$ with $r$ being the\nJacobson radical of $A$. When $A$ is splitting over the field $k$, the diagram\n$D_A$ and the well-known ext-quiver $\\Gamma_A$ are the same. The main objective\nof this paper is to investigate the relations among these combinatorial objects\nand in turn to use these relations to give a characterization of the algebra\n$A$.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:27:54 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7050","submitter":"Victor Chernozhukov","authors":"Victor Chernozhukov, Christian Hansen","title":"Quantile Models with Endogeneity","comments":"32 pages","journal-ref":"Annual Review of Economics, vol 5, 2013","doi":"10.1146/annurev-economics-080511-110952","report-no":null,"categories":"stat.AP econ.EM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article, we review quantile models with endogeneity. We focus on\nmodels that achieve identification through the use of instrumental variables\nand discuss conditions under which partial and point identification are\nobtained. We discuss key conditions, which include monotonicity and\nfull-rank-type conditions, in detail. In providing this review, we update the\nidentification results of Chernozhukov and Hansen (2005, Econometrica). We\nillustrate the modeling assumptions through economically motivated examples. We\nalso briefly review the literature on estimation and inference.\n  Key Words: identification, treatment effects, structural models, instrumental\nvariables\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:32:37 GMT"}],"update_date":"2017-10-03"}
{"id":"1303.7051","submitter":"Hannes Diener","authors":"J. Berger, D. Bridges, H. Diener, H. Schwichtenberg","title":"Constructive aspects of Riemann's permutation theorem for series","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The notions of permutable and weak-permutable convergence of a series\n$\\sum_{n=1}^{\\infty}a_{n}$ of real numbers are introduced. Classically, these\ntwo notions are equivalent, and, by Riemann's two main theorems on the\nconvergence of series, a convergent series is permutably convergent if and only\nif it is absolutely convergent. Working within Bishop-style constructive\nmathematics, we prove that Ishihara's principle \\BDN implies that every\npermutably convergent series is absolutely convergent. Since there are models\nof constructive mathematics in which the Riemann permutation theorem for series\nholds but \\BDN does not, the best we can hope for as a partial converse to our\nfirst theorem is that the absolute convergence of series with a permutability\nproperty classically equivalent to that of Riemann implies \\BDN. We show that\nthis is the case when the property is weak-permutable convergence.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:54:06 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7052","submitter":"Kenichi Kasamatsu","authors":"Kenichi Kasamatsu, Hiromitsu Takeuchi, Makoto Tsubota, Muneto Nitta","title":"Wall-vortex composite solitons in two-component Bose-Einstein\n  condensates","comments":"16 pages. 11 figures","journal-ref":"Phys.Rev.A88:013620,2013","doi":"10.1103/PhysRevA.88.013620","report-no":null,"categories":"cond-mat.quant-gas hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study composite solitons, consisting of domain walls and vortex lines\nattaching to the walls in two-component Bose-Einstein condensates. When the\ntotal density of two components is homogeneous, the system can be mapped to the\nO(3) nonlinear sigma model for the pseudospin representing the two-component\norder parameter and the analytical solutions of the composite solitons can be\nobtained. Based on the analytical solutions, we discuss the detailed structure\nof the composite solitons in two-component condensates by employing the\ngeneralized nonlinear sigma model, where all degrees of freedom of the original\nGross-Pitaevskii theory are active. The density inhomogeneity results in\nreduction of the domain wall tension from that in the sigma model limit. We\nfind that the domain wall pulled by a vortex is logarithmically bent as a\nmembrane pulled by a pin, and it bends more flexibly than not only the domain\nwall in the sigma model but also the expectation from the reduced tension.\nFinally, we study the composite soliton structure for actual experimental\nsituations with trapped immiscible condensates under rotation through numerical\nsimulations of the coupled Gross-Pitaevskii equations.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 06:57:46 GMT"}],"update_date":"2013-07-17"}
{"id":"1303.7053","submitter":"Vasiliy Rodionov","authors":"V.N.Rodionov","title":"Non-Hermitian $\\cal PT$-symmetric quantum mechanics of relativistic\n  particles with the restriction of mass","comments":"14 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph hep-ph hep-th math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The modified Dirac equations for the massive particles with the replacement\nof the physical mass $m$ with the help of the relation $m\\rightarrow m_1+\n\\gamma_5 m_2$ are investigated. It is shown that for a fermion theory with a\n$\\gamma_5$-mass term, the limiting of the mass specter by the value $ m_{max}=\n{m_1}^2/2m_2$ takes place. In this case the different regions of the unbroken\n$\\cal PT$ symmetry may be expressed by means of the restriction of the physical\nmass $m\\leq m_{max}$. It should be noted that in the approach which was\ndeveloped by C.Bender et al. for the $\\cal PT$-symmetric version of the massive\nThirring model with $\\gamma_5$-mass term, the region of the unbroken $\\cal\nPT$-symmetry was found in the form $m_1\\geq m_2$ \\cite{ft12}. However on the\nbasis of the mass limitation $m\\leq m_{max}$ we obtain that the domain $m_1\\geq\nm_2$ consists of two different parametric sectors: i) $0\\leq m_2 \\leq\nm_1/\\sqrt{2}$ -this values of mass parameters $m_1,m_2$ correspond to the\ntraditional particles for which in the limit $m_{max}\\rightarrow \\infty$ the\nmodified models are converting to the ordinary Dirac theory with the physical\nmass $m$; ii)$m_1/\\sqrt{2}\\leq m_2 \\leq m_1$ - this is the case of the unusual\nparticles for which equations of motion does not have a limit, when\n$m_{max}\\rightarrow \\infty$. The presence of this possibility lets hope for\nthat in Nature indeed there are some \"exotic fermion fields\".\n  As a matter of fact the formulated criterions may be used as a major test in\nthe process of the division of considered models into ordinary and exotic\nfermion theories. It is tempting to think that the quanta of the exotic fermion\nfield have a relation to the structure of the \"dark matter\".\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:00:32 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7054","submitter":"Shen Feng","authors":"Shen Feng and Soung C. Liew","title":"Wireless Broadcast with Physical-Layer Network Coding","comments":"23 pages, 18 figures, 6 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.NI math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work investigates the maximum broadcast throughput and its achievability\nin multi-hop wireless networks with half-duplex node constraint. We allow the\nuse of physical-layer network coding (PNC). Although the use of PNC for unicast\nhas been extensively studied, there has been little prior work on PNC for\nbroadcast. Our specific results are as follows: 1) For single-source broadcast,\nthe theoretical throughput upper bound is n/(n+1), where n is the \"min\nvertex-cut\" size of the network. 2) In general, the throughput upper bound is\nnot always achievable. 3) For grid and many other networks, the throughput\nupper bound n/(n+1) is achievable. Our work can be considered as an attempt to\nunderstand the relationship between max-flow and min-cut in half-duplex\nbroadcast networks with cycles (there has been prior work on networks with\ncycles, but not half-duplex broadcast networks).\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:09:26 GMT"},{"version":"v2","created":"Sun, 4 Aug 2013 06:34:05 GMT"}],"update_date":"2013-08-06"}
{"id":"1303.7055","submitter":"Xue Chang","authors":"Xue Chang, Chun Liu, Yi-Lei Tang","title":"Phenomenological Aspects of R-parity Violating Supersymmetry with A\n  Vector-like Extra Generation","comments":"30 pages, 1 table, 7 figures. Accepted for publication in Phys. Rev.\n  D","journal-ref":"Phys. Rev. D 87, 075012 (2013)","doi":"10.1103/PhysRevD.87.075012","report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/3.0/","abstract":"  Phenomenological analysis to the R-parity violating supersymmetry with a\nvector-like extra generation is performed in detail. It is found that, via the\ntrilinear couplings, the correct neutrino spectrum can be obtained. The Higgs\nmass rises to 125 GeV by new up-type Yukawa couplings of vector-like quarks\nwith no need of very heavy superpartners. Phenomena of new heavy fermions at\nLHC are predicted.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:18:16 GMT"},{"version":"v2","created":"Sun, 31 Mar 2013 08:14:56 GMT"}],"update_date":"2013-10-14"}
{"id":"1303.7056","submitter":"Hiroshi Okada","authors":"Yasuhiro Daikoku, Hiroshi Okada","title":"Phenomenology of S_4 Flavor Symmetric extra U(1) model","comments":"33 pages, 7 tables, no figures; version accepted for publication in\n  Physical Review D","journal-ref":null,"doi":"10.1103/PhysRevD.88.015034","report-no":"KIAS-P13019","categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study several phenomenologies of an E_6 inspired extra U(1) model with S_4\nflavor symmetry. With the assignment of left-handed quarks and leptons to\nS_4-doublet, SUSY flavor problem is softened. As the extra Higgs bosons are\nneutrinophilic, baryon number asymmetry in the universe is realized by\nleptogenesis without causing gravitino overproduction. We find that the allowed\nregion for the lightest chargino mass is given by 100-140 GeV, if the dark\nmatter is a singlino dominated neutralino whose mass is about 36 GeV.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:22:05 GMT"},{"version":"v2","created":"Wed, 26 Jun 2013 16:50:27 GMT"}],"update_date":"2013-08-09"}
{"id":"1303.7057","submitter":"Vasant Natarajan","authors":"K. D. Rathod, Alok K. Singh, and Vasant Natarajan","title":"Continuous beam of laser-cooled Yb atoms","comments":"5 pages, 4 figures","journal-ref":"Europhysics Letters 102, 43001 (2013)","doi":"10.1209/0295-5075/102/43001","report-no":null,"categories":"physics.atom-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We demonstrate launching of laser-cooled Yb atoms in a continuous atomic\nbeam. The continuous cold beam has significant advantages over the more-common\npulsed fountain, which was also demonstrated by us recently. The cold beam is\nformed in the following steps---(i) Atoms from a thermal beam are first Zeeman\nslowed to a small final velocity, (ii) the slowed atoms are captured in a\ntwo-dimensional magneto-optic trap (2D-MOT), and (iii) atoms are launched {\\em\ncontinuously} in the vertical direction using two sets of moving-molasses\nbeams, inclined at $\\pm 15^\\circ$ to the vertical. The cooling transition used\nis the strongly-allowed ${^1S}_0 \\rightarrow {^1P}_1$ transition at 399 nm. We\ncapture about $7 \\times 10^6$ atoms in the 2D-MOT, and then launch them with a\nvertical velocity of 13 m/s at a longitudinal temperature of 125(6) mK.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:30:19 GMT"},{"version":"v2","created":"Tue, 18 Jun 2013 11:48:14 GMT"}],"update_date":"2013-06-19"}
{"id":"1303.7058","submitter":"Anushree Roy","authors":"Jaya Kumar Panda, Anushree Roy, Mauro Gemmi, Elena Husanu, Ang Li,\n  Daniele Ercolani, and Lucia Sorba","title":"Electronic Band Structure of Wurtzite GaP Nanowires via Resonance Raman\n  Spectroscopy","comments":"24 pages, 6 figures","journal-ref":null,"doi":"10.1063/1.4813625","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Raman measurements are performed on defect-free wurzite GaP nanowires.\nResonance Raman measurements are carried out over the excitation energy range\nbetween 2.19 and 2.71 eV. Resonances at 2.38 eV and 2.67 eV of the E1(LO) mode\nand at 2.67 eV of the A1(LO) are observed. The presence of these intensity\nresonances clearly demonstrates the existence of energy states with Gamma_9hh\nand Gamma_7V (Gamma_7C) symmetries of the valence (conduction) band and allows\nto measure WZ phase GaP band energies at the Gamma point. In addition, we have\ninvestigated temperature dependent resonant Raman measurements, which allowed\nus to extrapolate the zero temperature values of Gamma point energies, along\nwith the crystal field and spin-orbit splitting energies. Above results provide\na feedback for refining available theoretical calculations to derive the\ncorrect wurtzite III-V semiconductor band structure.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:34:30 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7059","submitter":"Masaki Takayama","authors":"Masaki Takayama, Hideyuki Saio, Yoshifusa Ita","title":"On the pulsation modes of OGLE small amplitude red giant variables in\n  the LMC","comments":"8 pages, 13 figures, accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stt398","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss the properties of pulsations in the OGLE Small Amplitude Red\nGiants (OSARGs) in the Large Magellanic Cloud (LMC). We consider stars below\nthe red-giant tip in this paper. They are multi-periodic and form three\nsequences in the period-luminosity plane. Comparing the periods and period\nratios with our theoretical models, we have found that these sequences\ncorrespond to radial first to third overtones, and nonradial dipole p$_4$ and\nquadrupole p$_2$ modes. The red-giant branch stars of OSARGs consist of stars\nhave initial masses of $\\sim0.9 - 1.4M_\\odot$ which corresponds to a luminosity\nrange of $\\log L/L_\\odot \\simeq 2.8 - 3.4$. With these parameters, the scaled\noptimal frequency $\\nu_{\\rm max}$ for solar-like oscillations goes through\nroughly the middle of the three sequences in the period-luminosity plane,\nsuggesting the stochastic excitation is likely the cause of the pulsations in\nOSARGs.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:52:34 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7060","submitter":"Chung-Pin  Chou","authors":"Chung-Pin Chou","title":"Low-lying quasiparticle excitations in strongly-correlated\n  superconductors: An ansatz from BCS quasiparticle excitations?","comments":"4 pages, 2 figures","journal-ref":null,"doi":"10.1016/j.jpcs.2013.05.027","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The question about the existence of Bogoliubov's quasiparticles in the BCS\nwave functions underneath Gutzwiller's projection is of importance to strongly\ncorrelated systems. We develop a method to examine the two-particle excitations\nof Gutzwiller-projected BCS wave functions by using the variational Monte Carlo\napproach. We find that the exact Gutzwiller-projected quasiparticle (GQP)\ndispersions are quantitatively reproduced by the Gutzwiller-projected\nBogoliubov quasiparticles (GBQP) except the regions where d-wave Cooper pairing\nis strong. Since GQP still shows higher energy than GBQP near the antinodes, we\nbelieve GBQP provides a reasonable description to the low-energy excitations in\nstrongly correlated superconducting systems. In addition, the intimate\nconnection between Gutzwiller's projection and d-wave Cooper pairing may also\nimply that strong correlations play a significant role in the nodal-antinodal\ndichotomy seen by photoemission experiments in cuprates.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 07:57:40 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7061","submitter":"Hans C. Eggers","authors":"H. C. Eggers and B. Buschbeck","title":"Internal cumulants for femtoscopy with fixed charged multiplicity","comments":"33 pages, 3 figures, 79 references","journal-ref":"Advances in High Energy Physics Vol 2013, Article ID 230515","doi":"10.1155/2013/230515","report-no":null,"categories":"hep-ex nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A detailed understanding of all effects and influences on higher-order\ncorrelations is essential. At low charged multiplicity, the effect of a\nnonpoissonian multiplicity distribution can significantly distort correlations.\nEvidently, the reference samples with respect to which correlations are\nmeasured should yield a null result in the absence of correlations. We show how\nthe careful specification of desired properties necessarily leads to an\naverage-of-multinomials reference sample. The resulting internal cumulants and\ntheir averaging over several multiplicities fulfil all requirements of\ncorrectly taking into account nonpoissonian multiplicity distributions as well\nas yielding a null result for uncorrelated fixed-N samples. Various correction\nfactors are shown to be approximations at best. Careful rederivation of\nstatistical variances and covariances within the frequentist approach yields\nerrors for cumulants that differ from those used so far. We finally briefly\ndiscuss the implementation of the analysis through a multiple event buffer\nalgorithm.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:06:53 GMT"},{"version":"v2","created":"Fri, 28 Jun 2013 15:34:38 GMT"}],"update_date":"2013-08-22"}
{"id":"1303.7062","submitter":"Boris E. Meierovich","authors":"Boris E. Meierovich","title":"Galaxy rotation curves. The theory","comments":"17 pages, 13 figures","journal-ref":"Physical Review D 87, D 87, 103510 (2013)","doi":"10.1103/PhysRevD.87.103510","report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The non-gauge vector field with as simple as possible Lagrangian\n(\\ref{Lagrangian}) turned out an adequate tool for macroscopic description of\nthe main properties of dark matter. The dependence of the velocity of a star on\nthe radius of the orbit $V\\left(r\\right) $ -- galaxy rotation curve -- is\nderived analytically from the first principles\\ completely within the\nEinstein's general relativity. The Milgrom's empirical modification of\nNewtonian dynamics in nonrelativistic limit (MOND) gets justified and specified\nin detail. In particular, the transition to a plateau is accompanied by damping\noscillations. In the scale of a galaxy, and in the scale of the whole universe,\nthe dark matter is described by a vector field with the same energy-momentum\ntensor. It is the evidence of the common physical nature. Now, when we have the\ngeneral expression (\\ref{Tik b=c=0}) for the energy-momentum tensor of dark\nmatter, it is possible to analyze its influence on the structure and evolution\nof super heavy stars and black holes.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:13:51 GMT"}],"update_date":"2016-05-24"}
{"id":"1303.7063","submitter":"Dr. Georgios M. Nikolopoulos","authors":"Georgios M. Nikolopoulos","title":"Statistics of a quantum-state-transfer Hamiltonian in the presence of\n  disorder","comments":null,"journal-ref":"Phys. Rev. A 87, 042311 (2013)","doi":"10.1103/PhysRevA.87.042311","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a statistical analysis on the performance of a protocol for the\nfaithful transfer of a quantum state in finite qubit or spin chains, in the\npresence of diagonal and off-diagonal disorder. It is shown that the\naverage-state fidelity, typically employed in the literature for the\nquantification of the transfer, may overestimate considerably the performance\nof the protocol in a single realization, leading to faulty conclusions about\nthe success of the transfer.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:14:35 GMT"}],"update_date":"2013-04-10"}
{"id":"1303.7064","submitter":"Yuriy Sydorenko","authors":"Oleksandr Chvartatskyi and Yuriy Sydorenko","title":"A new (1+1)-dimensional matrix k-constrained KP hierarchy","comments":"20 pages. arXiv admin note: substantial text overlap with\n  arXiv:1303.6510","journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a new generalization of matrix (1+1)-dimensional k-constrained\nKP hierarchy. The new hierarchy contains matrix generalizations of stationary\nDS systems, (2+1)-dimensional modified Korteweg-de Vries equation and the\nNizhnik equation. A binary Darboux transformation method is proposed for\nintegration of systems from this hierarchy.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:15:58 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7065","submitter":"Chen Li","authors":"Chen Li, Tingnan Zhang, and Daniel I. Goldman","title":"A Terradynamics of Legged Locomotion on Granular Media","comments":null,"journal-ref":"Science 339, 1408-1411 (2013)","doi":"10.1126/science.1229163","report-no":null,"categories":"physics.bio-ph cond-mat.soft physics.flu-dyn q-bio.QM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The theories of aero- and hydrodynamics predict animal movement and device\ndesign in air and water through the computation of lift, drag, and thrust\nforces. Although models of terrestrial legged locomotion have focused on\ninteractions with solid ground, many animals move on substrates that flow in\nresponse to intrusion. However, locomotor-ground interaction models on such\nflowable ground are often unavailable. We developed a force model for\narbitrarily-shaped legs and bodies moving freely in granular media, and used\nthis \"terradynamics\" to predict a small legged robot's locomotion on granular\nmedia using various leg shapes and stride frequencies. Our study reveals a\ncomplex but generic dependence of stresses in granular media on intruder depth,\norientation, and movement direction and gives insight into the effects of leg\nmorphology and kinematics on movement.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:20:28 GMT"}],"update_date":"2019-11-04"}
{"id":"1303.7066","submitter":"Kazuhiko Seki","authors":"Kazuhiko Seki, Shigeyuki Komura and Sanoop Ramachandran","title":"Growth kinetics of circular liquid domains on vesicles by\n  diffusion-controlled coalescence","comments":"16pages, 3 figures","journal-ref":"J. Phys.: Condens. Matter 25 (2013) 195105","doi":"10.1088/0953-8984/25/19/195105","report-no":null,"categories":"cond-mat.soft physics.chem-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Motivated by recent experiments on multi-component membranes, the growth\nkinetics of domains on vesicles is theoretically studied. It is known that the\nsteady-state rate of coalescence cannot be obtained by taking the long-time\nlimit of the coalescence rate when the membrane is regarded as an infinite\ntwo-dimensional (2D) system. The steady-state rate of coalescence is obtained\nby explicitly taking into account the spherical vesicle shape. Using the\nexpression of the 2D diffusion coefficient obtained in the limit of small\ndomain size, an analytical expression for the domain growth kinetics is\nobtained when the circular shape is always maintained. For large domains, the\ngrowth kinetics is discussed by investigating the size dependence of the\ncoalescence rate using the expression for the diffusion coefficient of\narbitrary domain size.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:24:04 GMT"}],"update_date":"2013-04-26"}
{"id":"1303.7067","submitter":"Yishai Shperber","authors":"Yishai Shperber, Omer Sinwani, Netanel Naftalis, Daniel Bedau, James\n  W. Reiner, and Lior Klein","title":"Thermally assisted current-induced magnetization reversal in SrRuO3","comments":null,"journal-ref":"Phys. Rev. B 87, 115118 (2013)","doi":"10.1103/PhysRevB.87.115118","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We inject a sequence of 1 ms current pulses into uniformly magnetized\npatterns of the itinerant ferromagnet SrRuO3 until a magnetization reversal is\ndetected. We detect the effective temperature during the pulse and find that\nthe cumulative pulse time required to induce magnetization reversal depends\nexponentially on 1/T. In addition, we find that the cumulative pulse time also\ndepends exponentially on the current amplitude. These observations indicate\ncurrent-induced magnetization reversal assisted by thermal fluctuations.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:30:26 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7068","submitter":"Daniel Huber","authors":"W.D. Apel, J.C. Arteaga, L. B\\\"ahren, K. Bekk, M. Bertaina, P.L.\n  Biermann, J. Bl\\\"umer, H. Bozdog, I.M. Brancus, P. Buchholz, S. Buitink, E.\n  Cantoni, A. Chiavassa, K. Daumiller, V. de Souza, P. Doll, M. Ender, R.\n  Engel, H. Falcke, M. Finger, D. Fuhrmann, H. Gemmeke, C. Grupen, A. Haungs,\n  D. Heck, J.R. H\\\"orandel, A. Horneffer, D. Huber, T. Huege, P.G. Isar, K.-H.\n  Kampert, D. Kang, O. Kr\\\"omer, J. Kuijpers, K. Link, P. Luczak, M. Ludwig,\n  H.J. Mathes, M. Melissas, C. Morello, S. Nehls, J. Oehlschl\\\"ager, N.\n  Palmieri, T. Pierog, J. Rautenberg, H. Rebel, M. Roth, C. R\\\"uhle, A.\n  Saftoiu, H. Schieler, A. Schmidt, F.G. Schr\\\"oder, O. Sima, G. Toma, G.C.\n  Trinchero, A. Weindl, J. Wochele, M. Wommer, J. Zabierowski, J.A. Zensus","title":"Thunderstorm Observations by Air-Shower Radio Antenna Arrays","comments":null,"journal-ref":"Advances in Space Research, Volume 48, Issue 7, 1 October 2011,\n  Pages 1295-1303, ISSN 0273-1177, 10.1016/j.asr.2011.06.003.\n  (http://www.sciencedirect.com/science/article/pii/S0273117711004297)","doi":"10.1016/j.asr.2011.06.003","report-no":null,"categories":"astro-ph.HE astro-ph.IM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Relativistic, charged particles present in extensive air showers lead to a\ncoherent emission of radio pulses which are measured to identify the shower\ninitiating high-energy cosmic rays. Especially during thunderstorms, there are\nadditional strong electric fields in the atmosphere, which can lead to further\nmultiplication and acceleration of the charged particles and thus have\ninfluence on the form and strength of the radio emission. For a reliable energy\nreconstruction of the primary cosmic ray by means of the measured radio signal\nit is very important to understand how electric fields affect the radio\nemission. In addition, lightning strikes are a prominent source of broadband\nradio emissions that are visible over very long distances. This, on the one\nhand, causes difficulties in the detection of the much lower signal of the air\nshower. On the other hand the recorded signals can be used to study features of\nthe lightning development. The detection of cosmic rays via the radio emission\nand the influence of strong electric fields on this detection technique is\ninvestigated with the LOPES experiment in Karlsruhe, Germany. The important\nquestion if a lightning is initiated by the high electron density given at the\nmaximum of a high-energy cosmic-ray air shower is also investigated, but could\nnot be answered by LOPES. But, these investigations exhibit the capabilities of\nEAS radio antenna arrays for lightning studies. We report about the studies of\nLOPES measured radio signals of air showers taken during thunderstorms and give\na short outlook to new measurements dedicated to search for correlations of\nlightning and cosmic rays.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:38:46 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7069","submitter":"Johannes Hoppenau","authors":"Johannes Hoppenau, Andreas Engel","title":"On the work distribution in quasi-static processes","comments":"11 pages, 1 figure","journal-ref":null,"doi":"10.1088/1742-5468/2013/06/P06004","report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We derive a systematic, multiple time-scale perturbation expansion for the\nwork distribution in isothermal quasi-static Langevin processes. To first order\nwe find a Gaussian distribution reproducing the result of Speck and Seifert\n[Phys. Rev. E 70, 066112 (2004)]. Scrutinizing the applicability of\nperturbation theory we then show that, irrespective of time-scale separation,\nthe expansion breaks down when applied to untypical work values from the tails\nof the distribution. We thus reconcile the result of Speck and Seifert with\napparently conflicting exact expressions for the asymptotics of work\ndistributions in special systems and with an intuitive argument building on the\ncentral limit theorem.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:47:17 GMT"},{"version":"v2","created":"Fri, 3 May 2013 08:53:57 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7070","submitter":"Daniel Huber","authors":"D. Huber, W.D. Apel, J.C. Arteaga, L. B\\\"ahren, K. Bekk, M. Bertaina,\n  P.L. Biermann, J. Bl\\\"umer, H. Bozdog, I.M. Brancus, P. Buchholz, E. Cantoni,\n  A. Chiavassa, K. Daumiller, V. de Souza, F. Di Pierro, P. Doll, R. Engel, H.\n  Falcke, M. Finger, B. Fuchs, D. Fuhrmann, H. Gemmeke, C. Grupen, A. Haungs,\n  D. Heck, J.R. H\\\"orandel, A. Horneffer, T. Huege, P.G. Isar, K.-H. Kampert,\n  D. Kang, O. Kr\\\"omer, J. Kuijpers, K. Link, P. Luczak, M. Ludwig, H.J.\n  Mathes, M. Melissas, C. Morello, J. Oehlschl\\\"ager, N. Palmieri, T. Pierog,\n  J. Rautenberg, H. Rebel, M. Roth, C. R\\\"uhle, A. Saftoiu, H. Schieler, A.\n  Schmidt, F.G. Schr\\\"oder, O. Sima, G. Toma, G.C. Trinchero, A. Weindl, J.\n  Wochele, M. Wommer, J. Zabierowski, J.A. Zensus","title":"LOPES 3D reconfiguration and first measurements","comments":"Proceedings","journal-ref":"Proceedings of the 32nd International Cosmic Ray Conference\n  (ICRC2011), held 11-18 August, 2011 in Beijing, China. Vol. 3 HE1.4:\n  Extensive Air Showers and HE Cosmic Rays., p.72","doi":null,"report-no":null,"categories":"astro-ph.IM astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Radio detection technique of high-energy cosmic rays is based on the\nradio signal emitted by the charged particles in an air shower due to their\ndeflection in the Earth's magnetic field. The LOPES experiment at Karlsruhe\nInstitute of Technology, Germany with its simple dipoles made major\ncontributions to the revival of this technique. LOPES is working in the\nfrequency range from 40 to 80 MHz and was reconfigured several times to improve\nand further develop the radio detection technique. In the current setup LOPES\nconsists of 10 tripole antennas which measure the complete electric field\nvector of the radio emission from cosmic rays. LOPES is the first experiment\nmeasuring all three vectorial components at once and thereby gaining the full\ninformation about the electric field vector and not only a two-dimensional\nprojection. Such a setup including also measurements of the vertical electric\nfield component is expected to increase the sensitivity to inclined showers and\nhelp to advance the understanding of the emission mechanism. We present the\nreconfiguration and calibration procedure of LOPES 3D and discuss first\nmeasurements.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:54:35 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7071","submitter":"Sascha Trippe","authors":"Sascha Trippe (SNU, Seoul)","title":"A Derivation of Modified Newtonian Dynamics","comments":"4 pages, 1 figure; to appear in JKAS (received 2013 February 14;\n  revised 2013 March 22; accepted 2013 March 28)","journal-ref":null,"doi":"10.5303/JKAS.2013.46.2.093","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modified Newtonian Dynamics (MOND) is a possible solution for the missing\nmass problem in galactic dynamics; its predictions are in good agreement with\nobservations in the limit of weak accelerations. However, MOND does not derive\nfrom a physical mechanism and does not make predictions on the transitional\nregime from Newtonian to modified dynamics; rather, empirical transition\nfunctions have to be constructed from the boundary conditions and comparison to\nobservations. I compare the formalism of classical MOND to the scaling law\nderived from a toy model of gravity based on virtual massive gravitons (the\n\"graviton picture\") which I proposed recently. I conclude that MOND naturally\nderives from the \"graviton picture\" at least for the case of non-relativistic,\nhighly symmetric dynamical systems. This suggests that - to first order - the\n\"graviton picture\" indeed provides a valid candidate for the physical mechanism\nbehind MOND and gravity on galactic scales in general.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:55:28 GMT"}],"update_date":"2017-01-18"}
{"id":"1303.7072","submitter":"Jian-Hua Zheng","authors":"Jian-Hua Zheng","title":"Transfer operator and conformal measures for a class of maps having\n  covering property","comments":"27 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $(X,d)$ be a metric space and $X_0$ be an open and dense subset of $X$.\nWe develop the Walters' theory and discuss the existence of conformal measures\nin terms of the Perron-Frobenius-Ruelle operator for a continuous map\n$T:X_0\\rightarrow X$ and the Bowen formula about Hausdorff dimension and\nPoincar\\'e exponent of some invariant subsests for $T$ with some expanding\nproperty.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:56:20 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7073","submitter":"Franz X. Bronold","authors":"Rafael L. Heinisch, Franz X. Bronold, and Holger Fehske","title":"Surface electrons at plasma walls","comments":"To appear in Complex Plasmas: Scientific Challenges and Technological\n  Opportunities, Editors: M. Bonitz, K. Becker, J. Lopez and H. Thomsen","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this chapter we introduce a microscopic modelling of the surplus electrons\non the plasma wall which complements the classical description of the plasma\nsheath. First we introduce a model for the electron surface layer to study the\nquasistationary electron distribution and the potential at an unbiased plasma\nwall. Then we calculate sticking coefficients and desorption times for electron\ntrapping in the image states. Finally we study how surplus electrons affect\nlight scattering and how charge signatures offer the possibility of a novel\ncharge measurement for dust grains.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 08:59:51 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7074","submitter":"Livio Flaminio","authors":"Livio Flaminio, Giovanni Forni, Federico Rodriguez Hertz","title":"Invariant Distributions for homogeneous flows","comments":"43 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that every homogeneous flow on a finite-volume homogeneous manifold\nhas countably many independent invariant distributions unless it is conjugate\nto a linear flow on a torus. We also prove that the same conclusion holds for\nevery affine transformation of a homogenous space which is not conjugate to a\ntoral translation. As a part of the proof, we have that any smooth partially\nhyperbolic flow on any compact manifold has countably many distinct minimal\nsets, hence countably many distinct ergodic probability measures. As a\nconsequence, the Katok and Greenfield-Wallach conjectures hold in all of the\nabove cases.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:12:30 GMT"},{"version":"v2","created":"Wed, 22 Jul 2015 17:00:44 GMT"}],"update_date":"2015-07-23"}
{"id":"1303.7075","submitter":"Debajyoti Mukhopadhyay Prof.","authors":"Debajyoti Mukhopadhyay, Gitesh Sonawane, Parth Sarthi Gupta, Sagar\n  Bhavsar, Vibha Mittal","title":"Enhanced Security for Cloud Storage using File Encryption","comments":"6 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Cloud computing is a term coined to a network that offers incredible\nprocessing power, a wide array of storage space and unbelievable speed of\ncomputation. Social media channels, corporate structures and individual\nconsumers are all switching to the magnificent world of cloud computing. The\nflip side to this coin is that with cloud storage emerges the security issues\nof confidentiality, data integrity and data availability. Since the cloud is a\nmere collection of tangible super computers spread across the world,\nauthentication and authorization for data access is more than a necessity. Our\nwork attempts to overcome these security threats. The proposed methodology\nsuggests the encryption of the files to be uploaded on the cloud. The integrity\nand confidentiality of the data uploaded by the user is ensured doubly by not\nonly encrypting it but also providing access to the data only on successful\nauthentication.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:20:54 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7076","submitter":"Hans Havlicek","authors":"Andrea Blunck, Hans Havlicek","title":"Projective lines over Jordan systems and geometry of Hermitian matrices","comments":null,"journal-ref":"Linear Algebra and its Applications 433 (2010) 672-680","doi":"10.1016/j.laa.2010.03.037","report-no":null,"categories":"math.AG math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Any set of $\\sigma$-Hermitian matrices of size $n \\times n$ over a field with\ninvolution $\\sigma$ gives rise to a projective line in the sense of ring\ngeometry and a projective space in the sense of matrix geometry. It is shown\nthat the two concepts are based upon the same set of points, up to some\nnotational differences.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:32:36 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7077","submitter":"Oleg Verbitsky","authors":"Christoph Berkholz and Oleg Verbitsky","title":"On the speed of constraint propagation and the time complexity of arc\n  consistency testing","comments":"19 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Establishing arc consistency on two relational structures is one of the most\npopular heuristics for the constraint satisfaction problem. We aim at\ndetermining the time complexity of arc consistency testing. The input\nstructures $G$ and $H$ can be supposed to be connected colored graphs, as the\ngeneral problem reduces to this particular case. We first observe the upper\nbound $O(e(G)v(H)+v(G)e(H))$, which implies the bound $O(e(G)e(H))$ in terms of\nthe number of edges and the bound $O((v(G)+v(H))^3)$ in terms of the number of\nvertices. We then show that both bounds are tight up to a constant factor as\nlong as an arc consistency algorithm is based on constraint propagation (like\nany algorithm currently known).\n  Our argument for the lower bounds is based on examples of slow constraint\npropagation. We measure the speed of constraint propagation observed on a pair\n$G,H$ by the size of a proof, in a natural combinatorial proof system, that\nSpoiler wins the existential 2-pebble game on $G,H$. The proof size is bounded\nfrom below by the game length $D(G,H)$, and a crucial ingredient of our\nanalysis is the existence of $G,H$ with $D(G,H)=\\Omega(v(G)v(H))$. We find one\nsuch example among old benchmark instances for the arc consistency problem and\nalso suggest a new, different construction.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:39:53 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7078","submitter":"Stephane  Coen","authors":"Stephane Coen and Miro Erkintalo","title":"Universal scaling laws of Kerr frequency combs","comments":"3 pages, 3 figures. Submitted to Optics Letters on 28 March 2013","journal-ref":"Optics Letters 38 (2013) 1790-1792","doi":"10.1364/OL.38.001790","report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using the known solutions of the Lugiato-Lefever equation, we derive\nuniversal trends of Kerr frequency combs. In particular, normalized properties\nof temporal cavity soliton solutions lead us to a simple analytic estimate of\nthe maximum attainable bandwidth for given pump-resonator parameters. The\nresult is validated via comparison with past experiments encompassing a diverse\nrange of resonator configurations and parameters.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:40:32 GMT"}],"update_date":"2013-10-22"}
{"id":"1303.7079","submitter":"Jeremy Leconte","authors":"J\\'er\\'emy Leconte, Francois Forget, Benjamin Charnay, Robin\n  Wordsworth, Franck Selsis, Ehouarn Millour","title":"3D climate modeling of close-in land planets: Circulation patterns,\n  climate moist bistability and habitability","comments":"Accepted for publication in Astronomy and Astrophysics, complete\n  abstract in the pdf, 18 pages, 18 figures","journal-ref":null,"doi":"10.1051/0004-6361/201321042","report-no":null,"categories":"astro-ph.EP physics.ao-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The inner edge of the classical habitable zone is often defined by the\ncritical flux needed to trigger the runaway greenhouse instability. This 1D\nnotion of a critical flux, however, may not be so relevant for inhomogeneously\nirradiated planets, or when the water content is limited (land planets).\n  Here, based on results from our 3D global climate model, we find that the\ncirculation pattern can shift from super-rotation to stellar/anti stellar\ncirculation when the equatorial Rossby deformation radius significantly exceeds\nthe planetary radius. Using analytical and numerical arguments, we also\ndemonstrate the presence of systematic biases between mean surface temperatures\nor temperature profiles predicted from either 1D or 3D simulations.\n  Including a complete modeling of the water cycle, we further demonstrate that\nfor land planets closer than the inner edge of the classical habitable zone,\ntwo stable climate regimes can exist. One is the classical runaway state, and\nthe other is a collapsed state where water is captured in permanent cold traps.\nWe identify this \"moist\" bistability as the result of a competition between the\ngreenhouse effect of water vapor and its condensation. We also present\nsynthetic spectra showing the observable signature of these two states.\n  Taking the example of two prototype planets in this regime, namely Gl581c and\nHD85512b, we argue that they could accumulate a significant amount of water ice\nat their surface. If such a thick ice cap is present, gravity driven ice flows\nand geothermal flux should come into play to produce long-lived liquid water at\nthe edge and/or bottom of the ice cap. Consequently, the habitability of\nplanets at smaller orbital distance than the inner edge of the classical\nhabitable zone cannot be ruled out. Transiting planets in this regime represent\npromising targets for upcoming observatories like EChO and JWST.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:44:27 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7080","submitter":"Daniel Huber","authors":"W.D. Apel, J.C. Arteaga, L. B\\\"ahren, K. Bekk, M. Bertaina, P.L.\n  Biermann, J. Bl\\\"umer, H. Bozdog, I.M. Brancus, A. Chiavassa, K. Daumiller,\n  V. de Souza, F. Di Pierro, P. Doll, R. Engel, H. Falcke, B. Fuchs, D.\n  Fuhrmann, H. Gemmeke, C. Grupen, A. Haungs, D. Heck, J.R. H\\\"orandel, A.\n  Horneffer, D. Huber, T. Huege, P.G. Isar, K.-H. Kampert, D. Kang, O.\n  Kr\\\"omer, J. Kuijpers, K. Link, P. Luczak, M. Ludwig, H.J. Mathes, M.\n  Melissas, C. Morello, J. Oehlschl\\\"ager, N. Palmieri, T. Pierog, J.\n  Rautenberg, H. Rebel, M. Roth, C. R\\\"uhle, A. Saftoiu, H. Schieler, A.\n  Schmidt, F.G. Schr\\\"oder, O. Sima, G. Toma, G.C. Trinchero, A. Weindl, J.\n  Wochele, J. Zabierowski, J.A. Zensus","title":"LOPES 3D - vectorial measurements of radio emission from cosmic ray\n  induced air showers","comments":"Proceedings ARENA 2012","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  LOPES 3D is able to measure all three components of the electric field vector\nof the radio emission from air showers. This allows a better comparison with\nemission models. The measurement of the vertical component increases the\nsensitivity to inclined showers. By measuring all three components of the\nelectric field vector LOPES 3D demonstrates by how much the reconstruction\naccuracy of primary cosmic ray parameters increases. Thus LOPES 3D evaluates\nthe usefulness of vectorial measurements for large scale applications.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:04:38 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7081","submitter":"Bastien Marmet","authors":"Bastien Marmet","title":"Quasi-Stationary Distributions for Stochastic Approximation Algorithms\n  with constant step size","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we investigate quasi-stationary distributions {\\mu}_N of\nstochastic approximation algorithms with constant step size which can be viewed\nas random perturbations of a time-continuous dynamical system. Inspired by\necological models these processes have a closed absorbing set corresponding to\nextinction. Under some large deviation assumptions and the existence of an\ninterior attractor for the ODE, we show that the weak* limit points of the QSD\n{\\mu}_N are invariant measures for the ODE with support in the interior\nattractors.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:16:58 GMT"},{"version":"v2","created":"Thu, 2 May 2013 12:57:46 GMT"}],"update_date":"2013-05-03"}
{"id":"1303.7082","submitter":"Tukumuli Mila","authors":"St\\'ephane Ballet, Alexis Bonnecaze and Mila Tukumuli","title":"On the construction of elliptic Chudnovsky-type algorithms for\n  multiplication in large extensions of finite fields","comments":"arXiv admin note: text overlap with arXiv:1107.0336 by other authors","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We indicate a strategy in order to construct bilinear multiplication\nalgorithms of type Chudnovsky in large extensions of any finite field. In\nparticular, by using the symmetric version of the generalization of\nRandriambololona specialized on the elliptic curves, we show that it is\npossible to construct such algorithms with low bilinear complexity. More\nprecisely, if we only consider the Chudnovsky-type algorithms of type symmetric\nelliptic, we show that the symmetric bilinear complexity of these algorithms is\nin $O(n(2q)^{\\log_q^*(n)})$ where $n$ corresponds to the extension degree, and\n$\\log_q^*(n)$ is the iterated logarithm. Moreover, we show that the\nconstruction of such algorithms can be done in time polynomial in $n$. Finally,\napplying this method we present the effective construction, step by step, of\nsuch an algorithm of multiplication in the finite field $\\F_{3^{57}}$.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:24:30 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7083","submitter":"Ziv Goldfeld","authors":"Ziv Goldfeld, Haim H. Permuter and Benjamin M. Zaidel","title":"The Finite State MAC with Cooperative Encoders and Delayed CSI","comments":null,"journal-ref":"IEEE Transactions on Information Theory, Vol. 60, No. 10, October\n  2014","doi":"10.1109/TIT.2014.2346494","report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we consider the finite-state multiple access channel (MAC)\nwith partially cooperative encoders and delayed channel state information\n(CSI). Here partial cooperation refers to the communication between the\nencoders via finite-capacity links. The channel states are assumed to be\ngoverned by a Markov process. Full CSI is assumed at the receiver, while at the\ntransmitters, only delayed CSI is available. The capacity region of this\nchannel model is derived by first solving the case of the finite-state MAC with\na common message. Achievability for the latter case is established using the\nnotion of strategies, however, we show that optimal codes can be constructed\ndirectly over the input alphabet. This results in a single codebook\nconstruction that is then leveraged to apply simultaneous joint decoding.\nSimultaneous decoding is crucial here because it circumvents the need to rely\non the capacity region's corner points, a task that becomes increasingly\ncumbersome with the growth in the number of messages to be sent. The common\nmessage result is then used to derive the capacity region for the case with\npartially cooperating encoders. Next, we apply this general result to the\nspecial case of the Gaussian vector MAC with diagonal channel transfer\nmatrices, which is suitable for modeling, e.g., orthogonal frequency division\nmultiplexing (OFDM)-based communication systems. The capacity region of the\nGaussian channel is presented in terms of a convex optimization problem that\ncan be solved efficiently using numerical tools. The region is derived by first\npresenting an outer bound on the general capacity region and then suggesting a\nspecific input distribution that achieves this bound. Finally, numerical\nresults are provided that give valuable insight into the practical implications\nof optimally using conferencing to maximize the transmission rates.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:30:39 GMT"},{"version":"v2","created":"Mon, 20 Jan 2014 13:51:56 GMT"},{"version":"v3","created":"Thu, 29 Jan 2015 12:11:30 GMT"}],"update_date":"2016-11-17"}
{"id":"1303.7084","submitter":"Imre Ferenc Barna Dr.","authors":"I. F. Barna","title":"Self-similar shock wave solutions of the non-linear Maxwell equations","comments":"6 pages, 2 figures published in Laser Phys. 24 (2014) 086002","journal-ref":"Laser Phys. 24 086002 (2014)","doi":"10.1088/1054-660X/24/8/086002","report-no":null,"categories":"physics.class-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In our study we consider nonlinear, power-law field-dependent electrical\npermitivity and magnetic permeability and investigate the time-dependent\nMaxwell equations with the self-similar Ansatz. This is a first-order\nhyperbolic PDE system which can conserve non-continuous initial conditions\ndescribing electromagnetic shock-waves. Besides shock-waves other interesting\nsolutions (e.g. with localized compact support) can be found with delicate\nphysical properties. Such phenomena may happen in complex materials induced by\nthe planned powerful Extreme Light Infrastructure(ELI) laser pulses.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:31:22 GMT"},{"version":"v2","created":"Tue, 9 Sep 2014 14:04:51 GMT"}],"update_date":"2014-09-10"}
{"id":"1303.7085","submitter":"Othman Benammar","authors":"Othman Benammar, Hicham Elasri, Abderrahim Sekkaki","title":"Semantic Matching of Security Policies to Support Security Experts","comments":"SECURWARE 2012 : The Sixth International Conference on Emerging\n  Security Information, Systems and Technologies","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/3.0/","abstract":"  Management of security policies has become increasingly difficult given the\nnumber of domains to manage, taken into consideration their extent and their\ncomplexity. Security experts has to deal with a variety of frameworks and\nspecification languages used in different domains that may belong to any Cloud\nComputing or Distributed Systems. This wealth of frameworks and languages make\nthe management task and the interpretation of the security policies so\ndifficult. Each approach provides its own conflict management method or tool,\nthe security expert will be forced to manage all these tools, which makes the\nfield maintenance and time consuming expensive. In order to hide this\ncomplexity and to facilitate some security experts tasks and automate the\nothers, we propose a security policies aligning based on ontologies process;\nthis process enables to detect and resolve security policies conflicts and to\nsupport security experts in managing tasks.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:40:23 GMT"}],"update_date":"2013-04-02"}
{"id":"1303.7086","submitter":"Jeremy Shears","authors":"Jeremy Shears and Theresa Hull","title":"Dr. Harold Whichello: medicine and astronomy in Cheshire","comments":"Accepted for publication in the Journal of the British Astronomical\n  Association. 20 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.hist-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dr. Harold Whichello (1870-1945) was a Cheshire General Practitioner and an\nenthusiastic amateur astronomer. He joined the British Astronomical Association\nin 1898 and undertook observations for its Lunar, Solar and Variable Star\nSections using a 6-inch Wray refractor. He also contributed lunar occultation\npredictions and comet ephemerides to its Computing Section.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:47:33 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7087","submitter":"Carlo Ferrigno","authors":"C. Ferrigno, R. Farinelli, E. Bozzo, K. Pottschmidt, D. Klochkov, P.\n  Kretschmar","title":"RX J0440.9+4431: a persistent Be/X-ray binary in outburst","comments":"Accepted for publication by A&A","journal-ref":null,"doi":"10.1051/0004-6361/201321053","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The persistent Be/X-ray binary RX J0440.9+4431 flared in 2010 and 2011 and\nhas been followed by various X-ray facilities Swift, RXTE, XMM-Newton, and\nINTEGRAL. We studied the source timing and spectral properties as a function of\nits X-ray luminosity to investigate the transition from normal to flaring\nactivity and the dynamical properties of the system. We have determined the\norbital period from the long-term Swift/BAT light curve, but our determinations\nof the spin period are not precise enough to constrain any orbital solution.\nThe source spectrum can always be described by a bulk-motion Comptonization\nmodel of black body seed photons attenuated by a moderate photoelectric\nabsorption. At the highest luminosity, we measured a curvature of the spectrum,\nwhich we attribute to a significant contribution of the radiation pressure in\nthe accretion process. This allows us to estimate that the transition from a\nbulk-motion-dominated flow to a radiatively dominated one happens at a\nluminosity of ~2e36 erg/s. The luminosity dependency of the size of the black\nbody emission region is found to be $r_{BB} \\propto L_X^{0.39\\pm0.02}$. This\nsuggests that either matter accreting onto the neutron star hosted in RX\nJ0440.9+4431 penetrates through closed magnetic field lines at the border of\nthe compact object magnetosphere or that the structure of the neutron star\nmagnetic field is more complicated than a simple dipole close to the surface\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:49:57 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7088","submitter":"Jeremy Shears","authors":"Jeremy Shears, Ian Miller, Roger Pickard, Richard Sabo","title":"Superoutbursts and grazing eclipses in the dwarf nova V1227 Herculis","comments":"Accepted for publication in the Journal of the British Astronomical\n  Association. 17 pages, 6 figures. The target star of this paper, SDSS\n  J165359.06+201010.4, has now received the official name of V1227 Her in the\n  General Catalogue of Variable Stars. This version contains the new name","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present photometry obtained during the 2012 May and September outbursts of\nthe frequently outbursting dwarf nova, V1227 Her. Superhumps were present in\nboth cases with a peak-to peak amplitude of up to 0.28 mag, showing these\nevents to be superoutbursts. We show for the first time that the system\nundergoes small eclipses with a depth of up to 0.08 mag, lasting 11 to 14 min,\nwhich are likely to be grazing eclipses of the accretion disc. The September\noutburst was the better observed of the two and lasted at least 14 days with an\noutburst amplitude of approximately 4 magnitudes. The mean superhump period was\nPsh = 0.065103(20) d. Analysis of eclipse times of minimum gave an orbital\nperiod Porb = 0.064419(26) d, although there is some ambiguity due to the\nrelatively short time over which the eclipses were observed. The fractional\nsuperhump period excess, epsilon, was 0.0106(7).\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:54:45 GMT"},{"version":"v2","created":"Wed, 10 Apr 2013 13:50:55 GMT"}],"update_date":"2013-04-11"}
{"id":"1303.7089","submitter":"Thomas Hausberger","authors":"Thomas Hausberger (I3M)","title":"On the concept of (homo)morphism : a key notion in the learning of\n  abstract algebra","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.HO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This article is dedicated to the investigation of difficulties involved in\nthe understanding of the homomorphism concept. It doesn't restrict to\ngroup-theory but on the contrary raises the issue of developing teaching\nstrategies aiming at gaining access to structuralist thinking. Emphasis is put\non epistemological analysis and its interaction with didactics in an attempt to\nmake Abstract Algebra more accessible.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:56:39 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7090","submitter":"Nicolas Durrande","authors":"Nicolas Durrande (Mines Saint-\\'Etienne MSE, LIMOS), James Hensman,\n  Magnus Rattray, Neil D. Lawrence","title":"Gaussian process models for periodicity detection","comments":"in PeerJ Computer Science, 2016","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of detecting and quantifying the periodic component\nof a function given noise-corrupted observations of a limited number of\ninput/output tuples. Our approach is based on Gaussian process regression which\nprovides a flexible non-parametric framework for modelling periodic data. We\nintroduce a novel decomposition of the covariance function as the sum of\nperiodic and aperiodic kernels. This decomposition allows for the creation of\nsub-models which capture the periodic nature of the signal and its complement.\nTo quantify the periodicity of the signal, we derive a periodicity ratio which\nreflects the uncertainty in the fitted sub-models. Although the method can be\napplied to many kernels, we give a special emphasis to the Mat\\'ern family,\nfrom the expression of the reproducing kernel Hilbert space inner product to\nthe implementation of the associated periodic kernels in a Gaussian process\ntoolkit. The proposed method is illustrated by considering the detection of\nperiodically expressed genes in the arabidopsis genome.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:59:18 GMT"},{"version":"v2","created":"Wed, 17 Feb 2016 19:39:24 GMT"},{"version":"v3","created":"Fri, 19 Aug 2016 15:59:55 GMT"}],"update_date":"2016-08-22"}
{"id":"1303.7091","submitter":"Colin Mrozinski","authors":"Colin Mrozinski","title":"Quantum automorphism groups and SO(3)-deformations","comments":"Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.QA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that any compact quantum group having the same fusion rules as the\nones of $SO(3)$ is the quantum automorphism group of a pair $(A, \\varphi)$,\nwhere $A$ is a finite dimensional $C^*$-algebra endowed with a homogeneous\nfaithful state. We also study the representation category of the quantum\nautomorphism group of $(A, \\varphi)$ when $\\varphi$ is not necessarily\npositive, generalizing some known results, and we discuss the possibility of\nclassifying the cosemisimple (not necessarily compact) Hopf algebras whose\ncorepresentation semi-ring is isomorphic to that of $SO(3)$.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:01:16 GMT"},{"version":"v2","created":"Mon, 6 Jan 2014 19:58:30 GMT"}],"update_date":"2014-01-07"}
{"id":"1303.7092","submitter":"Eric Gautier","authors":"Eric Gautier (CREST, ENSAE), Alexandre Tsybakov (CREST, ENSAE)","title":"Pivotal estimation in high-dimensional regression via linear programming","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST q-fin.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a new method of estimation in high-dimensional linear regression\nmodel. It allows for very weak distributional assumptions including\nheteroscedasticity, and does not require the knowledge of the variance of\nrandom errors. The method is based on linear programming only, so that its\nnumerical implementation is faster than for previously known techniques using\nconic programs, and it allows one to deal with higher dimensional models. We\nprovide upper bounds for estimation and prediction errors of the proposed\nestimator showing that it achieves the same rate as in the more restrictive\nsituation of fixed design and i.i.d. Gaussian errors with known variance.\nFollowing Gautier and Tsybakov (2011), we obtain the results under weaker\nsensitivity assumptions than the restricted eigenvalue or assimilated\nconditions.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:01:46 GMT"},{"version":"v2","created":"Mon, 15 Apr 2013 09:45:31 GMT"}],"update_date":"2013-04-16"}
{"id":"1303.7093","submitter":"Aravind Kota Gopalakrishna","authors":"Aravind Kota Gopalakrishna, Tanir Ozcelebi, Antonio Liotta, Johan J.\n  Lukkien","title":"Relevance As a Metric for Evaluating Machine Learning Algorithms","comments":"To Appear at International Conference on Machine Learning and Data\n  Mining (MLDM 2013), 14 pages, 6 figures","journal-ref":null,"doi":"10.1007/978-3-642-39712-7_15","report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In machine learning, the choice of a learning algorithm that is suitable for\nthe application domain is critical. The performance metric used to compare\ndifferent algorithms must also reflect the concerns of users in the application\ndomain under consideration. In this work, we propose a novel probability-based\nperformance metric called Relevance Score for evaluating supervised learning\nalgorithms. We evaluate the proposed metric through empirical analysis on a\ndataset gathered from an intelligent lighting pilot installation. In comparison\nto the commonly used Classification Accuracy metric, the Relevance Score proves\nto be more appropriate for a certain class of applications.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:01:53 GMT"},{"version":"v2","created":"Fri, 5 Apr 2013 19:12:06 GMT"},{"version":"v3","created":"Mon, 8 Apr 2013 14:26:49 GMT"}],"update_date":"2013-07-19"}
{"id":"1303.7094","submitter":"Kevin Wildrick","authors":"Zolt\\'an M. Balogh, Jeremy T. Tyson, Kevin Wildrick","title":"Frequency of Sobolev dimension distortion of horizontal subgroups of\n  Heisenberg groups","comments":"22 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the behavior of Sobolev mappings defined on the Heisenberg groups\nwith respect to a foliation by left cosets of a horizontal homogeneous\nsubgroup. We quantitatively estimate, in terms of Euclidean Hausdorff\ndimension, the size of the set of cosets that are mapped onto sets of high\ndimension. The proof of our main result combines ideas of Gehring and Mostow\nabout the absolute continuity of quasiconformal mappings with Mattila's\nprojection and slicing machinery.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:02:54 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7095","submitter":"Annalisa Fasolino","authors":"L.W. van Heeringen, G. A. de Wijs, A. McCollam, J.C. Maan, and A.\n  Fasolino","title":"k.p subband structure of the LaAlO3/SrTiO3 interface","comments":"8 pages, 7 figures","journal-ref":"Phys. Rev. B 88,205140 (2013)","doi":"10.1103/PhysRevB.88.205140","report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Heterostructures made of transition metal oxides are new tailor-made\nmaterials which are attracting much attention. We have constructed a 6-band k.p\nHamiltonian and used it within the envelope function method to calculate the\nsubband structure of a variety of LaAlO3/SrTiO3 heterostructures. By use of\ndensity functional calculations, we determine the k.p parameters describing the\nconduction band edge of SrTiO3: the three effective mass parameters, L=0.6104\neV AA^2, M=9.73 eV AA^2, N=-1.616 eV AA^2, the spin orbit splitting\nDelta_SO=28.5 meV and the low temperature tetragonal distortion energy\nsplitting Delta_T=2.1 meV. For confined systems we find strongly anisotropic\nnon-parabolic subbands. As an application we calculate bands, density of states\nand magnetic energy levels and compare the results to Shubnikov-de Haas quantum\noscillations observed in high magnetic fields. For typical heterostructures we\nfind that electric field strength at the interface of F = 0.1 meV/AA for a\ncarrier density of 7.2 10^{12} cm^-2 results in a subband structure that is\nsimilar to experimental results.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:04:01 GMT"},{"version":"v2","created":"Wed, 8 Jan 2014 15:28:37 GMT"}],"update_date":"2014-01-09"}
{"id":"1303.7096","submitter":"Martin Deraux","authors":"Martin Deraux (IF), Elisha Falbel (IMJ, INRIA Paris-Rocquencourt)","title":"Complex hyperbolic geometry of the figure eight knot","comments":null,"journal-ref":"Geom. Topol. 19 (2015) 237-293","doi":"10.2140/gt.2015.19.237","report-no":null,"categories":"math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the figure eight knot complement admits a uniformizable\nspherical CR structure, i.e. it occurs as the manifold at infinity of a complex\nhyperbolic orbifold. The uniformization is unique provided we require the\nperipheral subgroups to have unipotent holonomy.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:06:39 GMT"},{"version":"v2","created":"Tue, 11 Feb 2014 10:51:44 GMT"}],"update_date":"2015-05-27"}
{"id":"1303.7097","submitter":"Andrea Cavagna","authors":"Alessandro Attanasi, Andrea Cavagna, Lorenzo Del Castello, Irene\n  Giardina, Tomas S. Grigera, Asja Jeli\\'c, Stefania Melillo, Leonardo Parisi,\n  Oliver Pohl, Edward Shen, Massimiliano Viale","title":"Superfluid transport of information in turning flocks of starlings","comments":null,"journal-ref":"Nature Physics 10 (9), 691-696 (2014)","doi":"10.1038/nphys3035","report-no":null,"categories":"cond-mat.stat-mech physics.bio-ph q-bio.PE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Collective decision-making in biological systems requires all individuals in\nthe group to go through a behavioural change of state. During this transition,\nthe efficiency of information transport is a key factor to prevent cohesion\nloss and preserve robustness. The precise mechanism by which natural groups\nachieve such efficiency, though, is currently not fully understood. Here, we\npresent an experimental study of starling flocks performing collective turns in\nthe field. We find that the information to change direction propagates across\nthe flock linearly in time with negligible attenuation, hence keeping group\ndecoherence to a minimum. This result contrasts with current theories of\ncollective motion, which predict a slower and dissipative transport of\ndirectional information. We propose a novel theory whose cornerstone is the\nexistence of a conserved spin current generated by the gauge symmetry of the\nsystem. The theory turns out to be mathematically identical to that of\nsuperfluid transport in liquid helium and it explains the dissipationless\npropagating mode observed in turning flocks. Superfluidity also provides a\nquantitative expression for the speed of propagation of the information,\naccording to which transport must be swifter the stronger the group's\norientational order. This prediction is verified by the data. We argue that the\nlink between strong order and efficient decision-making required by\nsuperfluidity may be the adaptive drive for the high degree of behavioural\npolarization observed in many living groups. The mathematical equivalence\nbetween superfluid liquids and turning flocks is a compelling demonstration of\nthe far-reaching consequences of symmetry and conservation laws across\ndifferent natural systems.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:14:09 GMT"}],"update_date":"2014-10-10"}
{"id":"1303.7098","submitter":"Oscar Lorente-Esp\\'in","authors":"Oscar Lorente-Esp\\'in","title":"Emission of fermions in little string theory","comments":"17 pages, no figures, minor corrections","journal-ref":"Phys. Rev. D. 87, 064016 (2013)","doi":"10.1103/PhysRevD.87.064016","report-no":null,"categories":"hep-th gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is well-known that little string theory (LST) black holes radiate a purely\nthermal spectrum of scalar particles. This theory lives in a Hagedorn phase\nwith a fixed Hagedorn temperature that does not depend on its mass. Therefore,\nthe theory keeps a thermal profile even taking into account self-gravitating\neffects and the back-reaction of the metric. This has implications concerning\nthe information loss paradox; one would not be able to recover any information\nfrom the LST black hole since the emission of scalar particles is totally\nuncorrelated. Several studies of the emission spectrum in LST concern scalar\nfields; it is our aim in this work to extend the study to the emission of\nfermions in order to verify that the most relevant conclusion for the scalar\nfield remains valid for the fermions fields. Thus, we have calculated the\nemission probability, the flux, and also the greybody factor corresponding to a\nfermion field in LST background.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:15:31 GMT"},{"version":"v2","created":"Mon, 1 Apr 2013 20:12:19 GMT"}],"update_date":"2013-04-03"}
{"id":"1303.7099","submitter":"Ludovic Marquis","authors":"Ludovic Marquis (IRMAR)","title":"Around groups in Hilbert Geometry","comments":"~60 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT math.GR math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This is survey about action of group on Hilbert geometry. It will be a\nchapter of the \"Handbook of Hilbert geometry\" edited by G. Besson, M. Troyanov\nand A. Papadopoulos.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:16:57 GMT"},{"version":"v2","created":"Tue, 22 Apr 2014 13:16:26 GMT"}],"update_date":"2014-04-23"}
{"id":"1303.7100","submitter":"Bertrand Lods","authors":"Luisa Arlotti, Bertrand Lods, Mustapha Mokhtar-Kharroubi\n  (LM-Besan\\c{c}on)","title":"Non-autonomous Honesty theory in abstract state spaces with applications\n  to linear kinetic equations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We provide a honesty theory of substochastic evolution families in real\nabstract state space, extending to an non-autonomous setting the result\nobtained for $C_0$-semigroups in our recent contribution \\textit{[On perturbed\nsubstochastic semigroups in abstract state spaces, \\textit{Z. Anal. Anwend.}\n\\textbf{30}, 457--495, 2011]}. The link with the honesty theory of perturbed\nsubstochastic semigroups is established. Several applications to non-autonomous\nlinear kinetic equations (linear Boltzmann equation and fragmentation equation)\nare provided.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:19:43 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7101","submitter":"Paul Busch","authors":"J.C.G. Biniok and P. Busch","title":"Multi-slit interferometry and commuting functions of position and\n  momentum","comments":"Version 2 contains minor corrections and improvements and a new\n  reference to to relevant work on modular variables by Y. Aharonov et al","journal-ref":"Physical Review A 87 (2013) 062116 (7 pp.)","doi":"10.1103/PhysRevA.87.062116","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a recent, modified double-pinhole diffraction experiment the existence of\nan interference pattern was established indirectly along with a near-perfect\nimaging of the double pinhole. Our theoretical analysis shows that the\nexperiment constitutes a preparation of a quantum state that is, to a good\napproximation, a joint eigenstate of commuting functions of position and\nmomentum. Gaining information about the momentum distribution by means of the\nparticular experimental setup is thus possible with negligible impact on the\nposition distribution. Furthermore, we construct explicitly a class of states\nsimultaneously localised on periodic sets in position and momentum space, which\nare therefore eigenstates of the observables being measured jointly (to a good\napproximation) in multi-slit interferometry. Finally, we show that with an\nappropriate change of settings the experiment demonstrates the mutual\ndisturbance of position and momentum measurements.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:22:08 GMT"},{"version":"v2","created":"Sun, 16 Jun 2013 10:18:06 GMT"}],"update_date":"2013-06-27"}
{"id":"1303.7102","submitter":"Bogumi{\\l}a \\'Swie\\.zewska","authors":"Maria Krawczyk, Dorota Sokolowska, Bogumila Swiezewska","title":"2HDM with Z_2 symmetry in light of new LHC data","comments":"To appear in Proc. of Discrete 2012 (talk by M. Krawczyk), 7 pages, 4\n  figures, v2: corrected Fig. 1b","journal-ref":"2013 J. Phys.: Conf. Ser. 447 012050","doi":"10.1088/1742-6596/447/1/012050","report-no":"IFT-1/2013","categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Properties of the Z_2-symmetric Two Higgs Doublet Models (2HDM) are discussed\nand confronted with new LHC data for a 125 GeV Higgs particle. The particle\ndiscovered at LHC in 2012 has properties expected for it in the Standard Model\n(SM), with a possible enhancement in the two-photon channel. SM-like Higgs\nscenarios can be realized in the Two Higgs Doublet Models with Z_2 (D) symmetry\nwithin the normal Mixed Model (with scalar sector as in MSSM) and the Inert\nDoublet Model (IDM), where a good Dark Matter (DM) candidate is present. Here\nwe discuss both of the models.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:35:08 GMT"},{"version":"v2","created":"Sat, 13 Jul 2013 14:00:05 GMT"}],"update_date":"2013-09-13"}
{"id":"1303.7103","submitter":"Federico Penna","authors":"Federico Penna, Slawomir Stanczak","title":"Decentralized Eigenvalue Algorithms for Distributed Signal Detection in\n  Cognitive Networks","comments":"Submitted to IEEE JSAC Cognitive Radio Series","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we derive and analyze two algorithms -- referred to as\ndecentralized power method (DPM) and decentralized Lanczos algorithm (DLA) --\nfor distributed computation of one (the largest) or multiple eigenvalues of a\nsample covariance matrix over a wireless network. The proposed algorithms,\nbased on sequential average consensus steps for computations of matrix-vector\nproducts and inner vector products, are first shown to be equivalent to their\ncentralized counterparts in the case of exact distributed consensus. Then,\nclosed-form expressions of the error introduced by non-ideal consensus are\nderived for both algorithms. The error of the DPM is shown to vanish\nasymptotically under given conditions on the sequence of consensus errors.\nFinally, we consider applications to spectrum sensing in cognitive radio\nnetworks, and we show that virtually all eigenvalue-based tests proposed in the\nliterature can be implemented in a distributed setting using either the DPM or\nthe DLA. Simulation results are presented that validate the effectiveness of\nthe proposed algorithms in conditions of practical interest (large-scale\nnetworks, small number of samples, and limited number of iterations).\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:42:28 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7104","submitter":"Denis Khomitsky","authors":"D.V. Khomitsky, A.A. Chubanov","title":"Edge states and topological properties of electrons on the bismuth on\n  silicon surface with giant spin-orbit coupling","comments":"9 pages, 3 figures, published version","journal-ref":"Journal of Experimental and Theoretical Physics, 2014, vol. 118,\n  No. 3, pp. 457-466","doi":"10.1134/S1063776114020101","report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We derive a model of localized edge states in the finite width strip for\ntwo-dimensional electron gas formed in the hybrid system of bismuth monolayer\ndeposited on the silicon interface and described by the nearly-free electron\nmodel with giant spin-orbit splitting. The edge states have the energy\ndispersion in the bulk energy gap with the Dirac-like linear dependence on the\nquasimomentum and the spin polarization coupled to the direction of\npropagation, demonstrating the properties of topological insulator. The\ntopological stability of edge states is confirmed by the calculations of the\n$Z_2$ invariant taken from the structure of the Pfaffian for the time reversal\noperator for the filled bulk bands in the surface Brillouin zone which is shown\nto have a stable number of zeros with the variations of material parameters.\nThe proposed properties of the edge states may support future advances in\nexperimental and technological applications of this new material in\nnanoelectronics and spintronics.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:45:11 GMT"},{"version":"v2","created":"Tue, 2 Apr 2013 20:59:11 GMT"},{"version":"v3","created":"Tue, 4 Feb 2014 15:26:48 GMT"}],"update_date":"2014-04-09"}
{"id":"1303.7105","submitter":"Robert van Leeuwen","authors":"Robert van Leeuwen and Gianluca Stefanucci","title":"Equilibrium and nonequilibrium many-body perturbation theory: a unified\n  framework based on the Martin-Schwinger hierarchy","comments":"17 pages, 6 figures","journal-ref":"Journal of Physics: Conference Series 427, 012001 (2013)","doi":"10.1088/1742-6596/427/1/012001","report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a unified framework for equilibrium and nonequilibrium many-body\nperturbation theory. The most general nonequilibrium many-body theory valid for\ngeneral initial states is based on a time-contour originally introduced by\nKonstantinov and Perel'. The various other well-known formalisms of Keldysh,\nMatsubara and the zero-temperature formalism are then derived as special cases\nthat arise under different assumptions. We further present a single simple\nproof of Wick's theorem that is at the same time valid in all these flavors of\nmany-body theory. It arises simply as a solution of the equations of the\nMartin-Schwinger hierarchy for the noninteracting many-particle Green's\nfunction with appropriate boundary conditions. We further discuss a generalized\nWick theorem for general initial states on the Keldysh contour and derive how\nthe formalisms based on the Keldysh and Konstantinov-Perel'-contours are\nrelated for the case of general initial states.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:47:43 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7106","submitter":"Enrique Herrero","authors":"E. Herrero, A. F. Lanza, I. Ribas, C. Jordi, J. C. Morales","title":"Photospheric activity, rotation and magnetic interaction in LHS 6343 A","comments":"14 pages, 16 figures","journal-ref":null,"doi":"10.1051/0004-6361/201220518","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Context. The Kepler mission has recently discovered a brown dwarf companion\ntransiting one member of the M4V+M5V visual binary system LHS 6343 AB with an\norbital period of 12.71 days. Aims. The particular interest of this transiting\nsystem lies in the synchronicity between the transits of the brown dwarf C\ncomponent and the main modulation observed in the light curve, which is assumed\nto be caused by rotating starspots on the A component. We model the activity of\nthis star by deriving maps of the active regions that allow us to study stellar\nrotation and the possible interaction with the brown dwarf companion. Methods.\nAn average transit profile was derived, and the photometric perturbations due\nto spots occulted during transits are removed to derive more precise transit\nparameters. We applied a maximum entropy spot model to fit the out-of-transit\noptical modulation as observed by Kepler during an uninterrupted interval of\n500 days. It assumes that stellar active regions consist of cool spots and\nbright faculae whose visibility is modulated by stellar rotation. Results.\nThanks to the extended photometric time series, we refine the determination of\nthe transit parameters and find evidence of spots that are occulted by the\nbrown dwarf during its transits. The modelling of the out-of-transit light\ncurve of LHS 6343 A reveals several starspots rotating with a slightly longer\nperiod than the orbital period of the brown dwarf, i.e., 13.13 +- 0.02 days. No\nsignature attributable to differential rotation is observed. We find evidence\nof a persistent active longitude on the M dwarf preceding the sub- companion\npoint by 100 deg and lasting for at least 500 days. This can be relevant for\nunderstanding how magnetic interaction works in low-mass binary and star-planet\nsystems.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:54:04 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7107","submitter":"Yuriy Bunkov","authors":"Yury Bunkov","title":"Direct Majorana quasiparticles heat capacity observation by $^3$He Dark\n  Matter detector","comments":"6 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det astro-ph.CO hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Majorana fermion: fermion that is its own antiparticle, was predicted by\nMajorana in 1937. No fundamental particles are known to be Majorana fermions,\nalthough there are speculations that the neutrino is one. Many proposed\ntheories assumes that the mysterious 'dark matter', which forms the greatest\npart of the universe, is composed of Majorana fermions. Even Majorana does not\nyet observed as a stable particle, its can be also exist as a quasiparticle in\nthe edge of topological isolators. Here we reports the Dark Matter bolometer\ntime constant deviation which is the result of additional Majorana heat\ncapacity.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:56:49 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7108","submitter":"Boris Chorny","authors":"Boris Chorny","title":"A classification of small homotopy functors from spectra to spectra","comments":"Final version, to appear in Fund. Math","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT math.CT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that every small homotopy functor from spectra to spectra is weakly\nequivalent to a filtered colimit of representable functors represented in\ncofibrant spectra. Moreover, we present this classification as a Quillen\nequivalence of the category of small functors from spectra to spectra equipped\nwith the homotopy model structure and the opposite of the pro-category of\nspectra with the strict model structure.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:58:38 GMT"},{"version":"v2","created":"Tue, 3 Nov 2015 16:14:18 GMT"}],"update_date":"2015-11-04"}
{"id":"1303.7109","submitter":"Tomomi Kouzu","authors":"Tomomi Kouzu, Makoto S. Tashiro, Yukikatsu Terada, Shin'ya Yamada, Aya\n  Bamba, Teruaki Enoto, Koji Mori, Yasushi Fukazawa, Kazuo Makishima","title":"Spectral Variation of the Hard X-ray Emission from the Crab Nebula with\n  the Suzaku Hard X-ray Detector","comments":"18 pages, 10 figures, PASJ accepted","journal-ref":null,"doi":"10.1093/pasj/65.4.74","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Crab Nebula is one of the brightest and most stable sources in the X-ray\nsky. Year-scale flux variation from the object was recently revealed in the\nhard X-ray band by four satellites. This marked the first detection of\nyear-scale variability from pulsar wind nebulae in the hard X-ray band. The\nCrab Nebula has been observed at least once a year for calibration purposes\nwith the Suzaku Hard X-ray Detector (HXD) since its launch in 2005. In order to\ninvestigate possible spectral changes as well as flux variation, the archival\ndata of the HXD were analyzed. The flux variation reported by other instruments\nwas confirmed in the 25 -- 100 keV band by the HXD in a few percent level, but\nflux above 100 keV did not follow the trend in variation below 100 keV. The\nhardness ratios produced utilizing the PIN and GSO sensors installed in the HXD\nexhibit significant scattering, thereby indicating spectral variations in the\nhard X-ray. The spectral changes are quantified by spectral fitting with a\nbroken power-law model. The difference between the two photon indexes of the\nbroken power-law model in harder and softer energy bands is in the range of <\n2.54. Taking into account flux variation of 6.3% and spectral variation\ntime-scale of a few days, multi components of the broken power-law-shaped\nsynchrotron emission with different cooling times are suggested.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:09:22 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7110","submitter":"Tuvi Etzion","authors":"Tuvi Etzion","title":"The q-Analog of the Middle Levels Problem","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The well-known middle levels problem is to find a Hammiltonian cycle in the\ngraph induced from the binary Hamming graph $\\cH_2(2k+1)$ by the words of\nweight $k$ or $k+1$. In this paper we define the $q$-analog of the middle\nlevels problem. Let $n=2k+1$ and let $q$ be a power of a prime number. Consider\nthe set of $(k+1)$-dimensional subspaces and the set of $k$-dimensional\nsubspaces of $\\F_q^n$. Can these subspaces be ordered in a way that for any two\nadjacent subspaces $X$ and $Y$, either $X \\subset Y$ or $Y \\subset X$? A\nconstruction method which yields many Hamiltonian cycles for any given $q$ and\n$k=2$ is presented.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:21:24 GMT"},{"version":"v2","created":"Fri, 27 Sep 2013 04:59:04 GMT"},{"version":"v3","created":"Mon, 10 Mar 2014 09:17:35 GMT"},{"version":"v4","created":"Wed, 12 Mar 2014 14:51:36 GMT"}],"update_date":"2014-03-13"}
{"id":"1303.7111","submitter":"Tobias Baier","authors":"Gowrishankar Seshadri and Tobias Baier","title":"Effect of Electro-Osmotic Flow on Energy Conversion on Superhydrophobic\n  Surfaces","comments":null,"journal-ref":null,"doi":"10.1063/1.4802044","report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It has been suggested that superhydrophobic surfaces, due to the presence of\na no-shear zone, can greatly enhance transport of surface charges, leading to a\nconsiderable increase in the streaming potential. This could find potential use\nin micro-energy harvesting devices. In this paper, we show using analytical and\nnumerical methods, that when a streaming potential is generated in such\nsuperhydrophobic geometries, the reverse electro-osmotic flow and hence current\ngenerated by this, is significant. A decrease in streaming potential compared\nto what was earlier predicted is expected. We also show that, due to the\nelectro-osmotic streaming-current, a saturation in both the power extracted and\nefficiency of energy conversion is achieved in such systems for large values of\nthe free surface charge densities. Nevertheless, under realistic conditions,\nsuch microstructured devices with superhydrophobic surfaces have the potential\nto even reach energy conversion efficiencies only achieved in nanostructured\ndevices so far.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:37:25 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7112","submitter":"Marvin Rose","authors":"Marvin Rose, Clive Tadhunter, Joanna Holt, Javier Rodr\\'iguez Zaur\\'in","title":"On the nature of the red, 2MASS selected AGN in the local Universe I: an\n  optical spectroscopic study","comments":"30 pages, 22 figures; accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stt564","report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present optical spectra for a representative sample of 27 nearby (z < 0.2)\n2MASS-selected AGN with red near-IR colours (J-K 2.0). The spectra were taken\nwith the ISIS spectrograph on the WHT with the aim of determining the nature of\nthe red 2MASS AGN, in particular whether they are young quasars obscured by\ntheir natal cocoon of gas and dust. We compare our findings with those obtained\nfor comparison samples of PG quasars and unobscured type 1 AGN.\n  The spectra show a remarkable variety, including moderately reddened type 1\nobjects (45%), type 1 objects that appear similar to traditional UV/optical\nselected AGN (11%), narrow-line Seyfert 1 AGN (15%), type 2 AGN (22%) and\nHII/composite objects (7%). The high Balmer decrements that we measure in many\nof the type 1 objects are consistent with their red J-KS colours being due to\nmoderate levels of dust extinction (0.2 < E(B-V) < 1.2). However, we measure\nonly modest velocity shifts and widths for the broader [OIII]{\\lambda}5007\nemission line components that are similar to those measured in the comparison\nsamples. This suggests that the outflows in the red 2MASS objects are not\nunusual compared with those of optical/UV selected AGN of similar luminosity.\nIn addition, the Eddington ratios for the 2MASS sample are relatively modest.\n  Overall, based on their optical spectra, we find no clear evidence that the\npopulation of red, 2MASS selected AGN at low redshifts represents young\nquasars. Most plausibly, these objects are normal type 1 AGN that are\nmoderately obscured by material in the outer layers of the circum-nuclear tori\nor in the disks of the host galaxies.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:40:22 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7113","submitter":"Suman Sinha Dr.","authors":"Pradipta Kumar Mandal and Suman Sinha","title":"Characterization of kinetic coarsening in a random-field Ising model","comments":"Double-column, 4 pages, 6 figures","journal-ref":"Phys. Rev. E 89, 042144 (2014)","doi":"10.1103/PhysRevE.89.042144","report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report a study of nonequilibrium relaxation in a two-dimensional random\nfield Ising model at a nonzero temperature. We attempt to observe the\ncoarsening from a different perspective with a particular focus on three\ndynamical quantities that characterize the kinetic coarsening. We provide a\nsimple generalized scaling relation of coarsening supported by numerical\nresults. The excellent data collapse of the dynamical quantities justifies our\nproposition. The scaling relation corroborates the recent observation that the\naverage linear domain size satisfies different scaling behavior in different\ntime regimes.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:42:24 GMT"},{"version":"v2","created":"Mon, 7 Jul 2014 12:56:56 GMT"}],"update_date":"2014-07-08"}
{"id":"1303.7114","submitter":"Andreas Steenpass","authors":"Magdaleen S. Marais and Andreas Steenpass","title":"The Classification of Real Singularities Using SINGULAR. Part I:\n  Splitting Lemma and Simple Singularities","comments":"12 pages, 1 table","journal-ref":"J. Symb. Comput. 68 (2015), 61-71","doi":"10.1016/j.jsc.2014.08.007","report-no":null,"categories":"math.AG math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present algorithms to classify isolated hypersurface singularities over\nthe real numbers according to the classification by V.I. Arnold (Arnold et al.,\n1985). This first part covers the splitting lemma and the simple singularities;\na second and a third part will be devoted to the unimodal singularities up to\ncorank 2. All algorithms are implemented in the SINGULAR library\nrealclassify.lib (Marais and Steenpass, 2012).\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:48:25 GMT"},{"version":"v2","created":"Tue, 5 Nov 2013 11:26:32 GMT"},{"version":"v3","created":"Fri, 13 Feb 2015 10:04:27 GMT"}],"update_date":"2016-01-15"}
{"id":"1303.7115","submitter":"Dmitry Namiot","authors":"Dmitry Namiot, Manfred Schneps-Schneppe","title":"Smart Cities Software from the developer's point of view","comments":"8 pages, submitted to 6-th Conference Applied Information and\n  Communication Technology AICT2013","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The paper discusses the current state and development proposals for Smart\nCities and Future Internet projects. Definitions of a Smart City can vary but\nusually tend to suggest the use of innovative Info-Communication technologies\nsuch as the Internet of Things and Web 2.0 to deliver more effective and\nefficient public services that improve living and working conditions and create\nmore sustainable urban environments. Our goal is to analyze the current\nproposals from the developer's point of view, highlight the really new\nelements, the positions borrowed from the existing tools as well as propose\nsome new extensions. We would like to discuss the possible extensions for the\nexisting proposals and describe add-ons that, by our opinion, let keep the\nfuture research inline with the modern approaches in the web development\ndomain.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:53:22 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7116","submitter":"Johannes Knebel","authors":"Johannes Knebel, Torben Kr\\\"uger, Markus F. Weber, Erwin Frey","title":"Coexistence and Survival in Conservative Lotka-Volterra Networks","comments":"5 pages, 3 figures","journal-ref":"Phys. Rev. Lett. 110, 168106 (2013)","doi":"10.1103/PhysRevLett.110.168106","report-no":"LMU-ASC 63/12","categories":"q-bio.PE cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Analyzing coexistence and survival scenarios of Lotka-Volterra (LV) networks\nin which the total biomass is conserved is of vital importance for the\ncharacterization of long-term dynamics of ecological communities. Here, we\nintroduce a classification scheme for coexistence scenarios in these\nconservative LV models and quantify the extinction process by employing the\nPfaffian of the network's interaction matrix. We illustrate our findings on\nglobal stability properties for general systems of four and five species and\nfind a generalized scaling law for the extinction time.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:57:46 GMT"}],"update_date":"2013-04-26"}
{"id":"1303.7117","submitter":"Brittany Terese Fasy","authors":"Brittany Terese Fasy, Fabrizio Lecci, Alessandro Rinaldo, Larry\n  Wasserman, Sivaraman Balakrishnan, Aarti Singh","title":"Confidence sets for persistence diagrams","comments":"Published in at http://dx.doi.org/10.1214/14-AOS1252 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)","journal-ref":"Annals of Statistics 2014, Vol. 42, No. 6, 2301-2339","doi":"10.1214/14-AOS1252","report-no":"IMS-AOS-AOS1252","categories":"math.ST cs.CG cs.LG stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Persistent homology is a method for probing topological properties of point\nclouds and functions. The method involves tracking the birth and death of\ntopological features (2000) as one varies a tuning parameter. Features with\nshort lifetimes are informally considered to be \"topological noise,\" and those\nwith a long lifetime are considered to be \"topological signal.\" In this paper,\nwe bring some statistical ideas to persistent homology. In particular, we\nderive confidence sets that allow us to separate topological signal from\ntopological noise.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:59:00 GMT"},{"version":"v2","created":"Fri, 7 Feb 2014 16:36:57 GMT"},{"version":"v3","created":"Thu, 20 Nov 2014 08:16:51 GMT"}],"update_date":"2014-11-21"}
{"id":"1303.7118","submitter":"Karen Masters","authors":"Karen L. Masters (ICG Portsmouth)","title":"A Zoo of Galaxies","comments":"15 pages, 8 figures. Proceedings of Invited Discourse at the 27th IAU\n  General Assembly, in Beijing, China, August 2012. To appear in Highlights of\n  Astronomy, Volume 16","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We live in a universe filled with galaxies with an amazing variety of sizes\nand shapes. One of the biggest challenges for astronomers working in this field\nis to understand how all these types relate to each other in the background of\nan expanding universe. Modern astronomical surveys (like the Sloan Digital Sky\nSurvey) have revolutionised this field of astronomy, by providing vast numbers\nof galaxies to study. The sheer size of the these databases made traditional\nvisual classification of the types galaxies impossible and in 2007 inspired the\nGalaxy Zoo project (www.galaxyzoo.org); starting the largest ever scientific\ncollaboration by asking members of the public to help classify galaxies by type\nand shape. Galaxy Zoo has since shown itself, in a series of now more than 30\nscientific papers, to be a fantastic database for the study of galaxy\nevolution. In this Invited Discourse I spoke a little about the historical\nbackground of our understanding of what galaxies are, of galaxy classification,\nabout our modern view of galaxies in the era of large surveys. I finish with\nshowcasing some of the contributions galaxy classifications from the Galaxy Zoo\nproject are making to our understanding of galaxy evolution.\n  This publication has been made possible by the participation of more than\n200,000 volunteers in the Galaxy Zoo project. Their contributions are\nindividually acknowledged at http://www.galaxyzoo.org/volunteers. KLM\nacknowledges funding from the Peter and Patricia Gruber Foundation as the 2008\nPeter and Patricia Gruber Foundation IAU Fellow, and from a 2010 Leverhulme\nTrust Early Career Fellowship, as well as support from the Royal Astronomical\nSociety to attend the 28th GA of the IAU.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:14:26 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7119","submitter":"Marta Galicka","authors":"S. Safaei, P. Kacman, and R. Buczko","title":"The topological-crystalline-insulator (Pb,Sn)Te - surface states and\n  their spin-polarization","comments":"8 pages, 7 figures, submitted to Phys. Rev. B","journal-ref":null,"doi":"10.1103/PhysRevB.88.045305","report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using a tight-binding approach we study theoretically the nature of surface\nstates in Pb0.4Sn0.6Te - the newly discovered\ntopological-crystalline-insulator. Apart from the studied before (001) surface\nstates, two other surface families, {011} and {111}, in which the mirror\nsymmetry of the crystal's rock-salt structure plays the same role in\ntopological protection, are considered. Our calculations show that while in\n(111) surface states of (Pb,Sn)Te four single topologically protected\nDirac-cones should appear, for the (110) surface states the protection is\nlifted for two L points. In this case, instead of the Dirac points energy gaps\noccur in the surface states, due to the interaction between the two L valleys.\nIn all studied cases a chiral spin texture is obtained.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:16:47 GMT"}],"update_date":"2013-12-05"}
{"id":"1303.7120","submitter":"Sen Zhang","authors":"Sen Zhang","title":"Pre-acceleration from Landau-Lifshitz Series","comments":"16 pages","journal-ref":null,"doi":"10.1093/ptep/ptt099","report-no":"OIQP-13-05","categories":"hep-th math-ph math.MP physics.class-ph physics.plasm-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Landau-Lifshitz equation is considered as an approximation of the\nAbraham-Lorentz-Dirac equation. It is derived from the Abraham-Lorentz-Dirac\nequation by treating radiation reaction terms as a perturbation. However, while\nthe Abraham-Lorentz-Dirac equation has pathological solutions of\npre-acceleration and runaway, the Landau-Lifshitz equation and its finite\nhigher order extensions are free of these problems. So it seems mysterious that\nthe property of solutions of these two equations is so different. In this paper\nwe show that the problems of pre-acceleration and runaway appear when one\nconsider a series of all-order perturbation which we call it the\nLandau-Lifshitz series. We show that the Landau-Lifshitz series diverges in\ngeneral. Hence a resummation is necessary to obtain a well-defined solution\nfrom the Landau-Lifshitz series. This resummation leads the pre-accelerating\nand the runaway solutions. The analysis is focusing on the non-relativistic\ncase, but we can extend the results obtained here to relativistic case at least\nin one dimension.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:39:08 GMT"}],"update_date":"2014-05-07"}
{"id":"1303.7121","submitter":"Andrii Neronov","authors":"R.Durrer, A.Neronov","title":"Cosmological Magnetic Fields: Their Generation, Evolution and\n  Observation","comments":"to appear in Astronomy & Astrophysics Review","journal-ref":null,"doi":"10.1007/s00159-013-0062-7","report-no":null,"categories":"astro-ph.CO astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We review the possible mechanisms for the generation of cosmological magnetic\nfields, discuss their evolution in an expanding Universe filled with the cosmic\nplasma and provide a critical review of the literature on the subject. We put\nspecial emphasis on the prospects for observational tests of the proposed\ncosmological magnetogenesis scenarios using radio and gamma-ray astronomy and\nultra high energy cosmic rays. We argue that primordial magnetic fields are\nobservationally testable. They lead to magnetic fields in the intergalactic\nmedium with magnetic field strength and correlation length in a well defined\nrange. We also state the unsolved questions in this fascinating open problem of\ncosmology and propose future observations to address them.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:42:03 GMT"},{"version":"v2","created":"Tue, 7 May 2013 09:57:37 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7122","submitter":"Fabi\\'an Riquelme","authors":"Andreas Polym\\'eris and Fabi\\'an Riquelme","title":"On the Complexity of the Decisive Problem in Simple, Regular and\n  Weighted Games","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.CC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the computational complexity of an important property of simple,\nregular and weighted games, which is decisiveness. We show that this concept\ncan naturally be represented in the context of hypergraph theory, and that\ndecisiveness can be decided for simple games in quasi-polynomial time, and for\nregular and weighted games in polynomial time. The strongness condition poses\nthe main difficulties, while properness reduces the complexity of the problem,\nespecially if it is amplified by regularity. On the other hand, regularity also\nallows to specify the problem instances much more economically, implying a\nreconsideration of the corresponding complexity measure that, as we prove, has\nimportant structural as well as algorithmic consequences.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:51:25 GMT"},{"version":"v2","created":"Tue, 9 Jul 2013 11:44:39 GMT"}],"update_date":"2013-07-10"}
{"id":"1303.7123","submitter":"Wladimir  Neves","authors":"Xavier Carvajal, Wladimir Neves","title":"Persistence property in weighted Sobolev spaces for nonlinear dispersive\n  equations","comments":"25 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We generalize the Abstract Interpolation Lemma proved by the authors in [2].\nUsing this extension, we show in a more general context, the persistence\nproperty for the generalized Korteweg-de Vries equation, see (1.2), in the\nweighted Sobolev space with low regularity in the weight. The method used can\nbe applied for other nonlinear dispersive models, for instance the\nmultidimensional nonlinear Schrodinger equation.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:52:05 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7124","submitter":"Daniel Mazin","authors":"Daniel Mazin, Martin Raue, Bagmeet Behera, Susumu Inoue, Yoshiyuki\n  Inoue, Takeshi Nakamori, Tomonori Totani (for the CTA Consortium)","title":"Potential of EBL and cosmology studies with the Cherenkov Telescope\n  Array","comments":"12 pages, 9 figures, to appear in Astroparticle Physics. arXiv admin\n  note: text overlap with arXiv:1005.1196","journal-ref":"Astroparticle Physics Volume 43, Pages 241-251 (March 2013)","doi":"10.1016/j.astropartphys.2012.09.002","report-no":"MPP-2013-98","categories":"astro-ph.CO astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Very high energy (VHE, E >100 GeV) gamma-rays are absorbed via interaction\nwith low-energy photons from the extragalactic background light (EBL) if the\ninvolved photon energies are above the threshold for electron-positron pair\ncreation. The VHE gamma-ray absorption, which is energy dependent and increases\nstrongly with redshift, distorts the VHE spectra observed from distant objects.\nThe observed energy spectra of the AGNs carry, therefore, an imprint of the\nEBL. The detection of VHE gamma-ray spectra of distant sources (z = 0.11 -\n0.54) by current generation Imaging Atmospheric Cherenkov Telescopes (IACTs)\nenabled to set strong upper limits on the EBL density, using certain basic\nassumptions about blazar physics. In this paper it is studied how the improved\nsensitivity of the Cherenkov Telescope Array (CTA) and its enlarged energy\ncoverage will enlarge our knowledge about the EBL and its sources. CTA will\ndeliver a large sample of AGN at different redshifts with detailed measured\nspectra. In addition, it will provide the exciting opportunity to use gamma ray\nbursts (GRBs) as probes for the EBL density at high redshifts.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:52:06 GMT"}],"update_date":"2019-08-14"}
{"id":"1303.7125","submitter":"Sean Benson","authors":"The LHCb collaboration: R. Aaij, C. Abellan Beteta, B. Adeva, M.\n  Adinolfi, C. Adrover, A. Affolder, Z. Ajaltouni, J. Albrecht, F. Alessio, M.\n  Alexander, S. Ali, G. Alkhazov, P. Alvarez Cartelle, A.A. Alves Jr, S. Amato,\n  S. Amerio, Y. Amhis, L. Anderlini, J. Anderson, R. Andreassen, R.B. Appleby,\n  O. Aquines Gutierrez, F. Archilli, A. Artamonov, M. Artuso, E. Aslanides, G.\n  Auriemma, S. Bachmann, J.J. Back, C. Baesso, V. Balagura, W. Baldini, R.J.\n  Barlow, C. Barschel, S. Barsuk, W. Barter, Th. Bauer, A. Bay, J. Beddow, F.\n  Bedeschi, I. Bediaga, S. Belogurov, K. Belous, I. Belyaev, E. Ben-Haim, M.\n  Benayoun, G. Bencivenni, S. Benson, J. Benton, A. Berezhnoy, R. Bernet, M.-O.\n  Bettler, M. van Beuzekom, A. Bien, S. Bifani, T. Bird, A. Bizzeti, P.M.\n  Bj{\\o}rnstad, T. Blake, F. Blanc, J. Blouw, S. Blusk, V. Bocci, A. Bondar, N.\n  Bondar, W. Bonivento, S. Borghi, A. Borgia, T.J.V. Bowcock, E. Bowen, C.\n  Bozzi, T. Brambach, J. van den Brand, J. Bressieux, D. Brett, M. Britsch, T.\n  Britton, N.H. Brook, H. Brown, I. Burducea, A. Bursche, G. Busetto, J.\n  Buytaert, S. Cadeddu, O. Callot, M. Calvi, M. Calvo Gomez, A. Camboni, P.\n  Campana, D. Campora Perez, A. Carbone, G. Carboni, R. Cardinale, A. Cardini,\n  H. Carranza-Mejia, L. Carson, K. Carvalho Akiba, G. Casse, M. Cattaneo, Ch.\n  Cauet, M. Charles, Ph. Charpentier, P. Chen, N. Chiapolini, M. Chrzaszcz, K.\n  Ciba, X. Cid Vidal, G. Ciezarek, P.E.L. Clarke, M. Clemencic, H.V. Cliff, J.\n  Closier, C. Coca, V. Coco, J. Cogan, E. Cogneras, P. Collins, A.\n  Comerma-Montells, A. Contu, A. Cook, M. Coombes, S. Coquereau, G. Corti, B.\n  Couturier, G.A. Cowan, D. Craik, S. Cunliffe, R. Currie, C. D'Ambrosio, P.\n  David, P.N.Y. David, A. Davis, I. De Bonis, K. De Bruyn, S. De Capua, M. De\n  Cian, J.M. De Miranda, L. De Paula, W. De Silva, P. De Simone, D. Decamp, M.\n  Deckenhoff, L. Del Buono, D. Derkach, O. Deschamps, F. Dettori, A. Di Canto,\n  H. Dijkstra, M. Dogaru, S. Donleavy, F. Dordei, A. Dosil Su\\'arez, D.\n  Dossett, A. Dovbnya, F. Dupertuis, R. Dzhelyadin, A. Dziurda, A. Dzyuba, S.\n  Easo, U. Egede, V. Egorychev, S. Eidelman, D. van Eijk, S. Eisenhardt, U.\n  Eitschberger, R. Ekelhof, L. Eklund, I. El Rifai, Ch. Elsasser, D. Elsby, A.\n  Falabella, C. F\\\"arber, G. Fardell, C. Farinelli, S. Farry, V. Fave, D.\n  Ferguson, V. Fernandez Albor, F. Ferreira Rodrigues, M. Ferro-Luzzi, S.\n  Filippov, C. Fitzpatrick, M. Fontana, F. Fontanelli, R. Forty, O. Francisco,\n  M. Frank, C. Frei, M. Frosini, S. Furcas, E. Furfaro, A. Gallas Torreira, D.\n  Galli, M. Gandelman, P. Gandini, Y. Gao, J. Garofoli, P. Garosi, J. Garra\n  Tico, L. Garrido, C. Gaspar, R. Gauld, E. Gersabeck, M. Gersabeck, T.\n  Gershon, Ph. Ghez, V. Gibson, V.V. Gligorov, C. G\\\"obel, D. Golubkov, A.\n  Golutvin, A. Gomes, H. Gordon, M. Grabalosa G\\'andara, R. Graciani Diaz, L.A.\n  Granado Cardoso, E. Graug\\'es, G. Graziani, A. Grecu, E. Greening, S.\n  Gregson, O. Gr\\\"unberg, B. Gui, E. Gushchin, Yu. Guz, T. Gys, C.\n  Hadjivasiliou, G. Haefeli, C. Haen, S.C. Haines, S. Hall, T. Hampson, S.\n  Hansmann-Menzemer, N. Harnew, S.T. Harnew, J. Harrison, T. Hartmann, J. He,\n  V. Heijne, K. Hennessy, P. Henrard, J.A. Hernando Morata, E. van Herwijnen,\n  E. Hicks, D. Hill, M. Hoballah, C. Hombach, P. Hopchev, W. Hulsbergen, P.\n  Hunt, T. Huse, N. Hussain, D. Hutchcroft, D. Hynds, V. Iakovenko, M. Idzik,\n  P. Ilten, R. Jacobsson, A. Jaeger, E. Jans, P. Jaton, F. Jing, M. John, D.\n  Johnson, C.R. Jones, B. Jost, M. Kaballo, S. Kandybei, M. Karacson, T.M.\n  Karbach, I.R. Kenyon, U. Kerzel, T. Ketel, A. Keune, B. Khanji, O. Kochebina,\n  I. Komarov, R.F. Koopman, P. Koppenburg, M. Korolev, A. Kozlinskiy, L.\n  Kravchuk, K. Kreplin, M. Kreps, G. Krocker, P. Krokovny, F. Kruse, M.\n  Kucharczyk, V. Kudryavtsev, T. Kvaratskheliya, V.N. La Thi, D. Lacarrere, G.\n  Lafferty, A. Lai, D. Lambert, R.W. Lambert, E. Lanciotti, G. Lanfranchi, C.\n  Langenbruch, T. Latham, C. Lazzeroni, R. Le Gac, J. van Leerdam, J.-P. Lees,\n  R. Lef\\`evre, A. Leflat, J. Lefran\\c{c}ois, S. Leo, O. Leroy, B. Leverington,\n  Y. Li, L. Li Gioi, M. Liles, R. Lindner, C. Linn, B. Liu, G. Liu, S. Lohn, I.\n  Longstaff, J.H. Lopes, E. Lopez Asamar, N. Lopez-March, H. Lu, D. Lucchesi,\n  J. Luisier, H. Luo, F. Machefert, I.V. Machikhiliyan, F. Maciuc, O. Maev, S.\n  Malde, G. Manca, G. Mancinelli, U. Marconi, R. M\\\"arki, J. Marks, G.\n  Martellotti, A. Martens, L. Martin, A. Mart\\'in S\\'anchez, M. Martinelli, D.\n  Martinez Santos, D. Martins Tostes, A. Massafferri, R. Matev, Z. Mathe, C.\n  Matteuzzi, E. Maurice, A. Mazurov, J. McCarthy, R. McNulty, A. Mcnab, B.\n  Meadows, F. Meier, M. Meissner, M. Merk, D.A. Milanes, M.-N. Minard, J.\n  Molina Rodriguez, S. Monteil, D. Moran, P. Morawski, M.J. Morello, R.\n  Mountain, I. Mous, F. Muheim, K. M\\\"uller, R. Muresan, B. Muryn, B. Muster,\n  P. Naik, T. Nakada, R. Nandakumar, I. Nasteva, M. Needham, N. Neufeld, A.D.\n  Nguyen, T.D. Nguyen, C. Nguyen-Mau, M. Nicol, V. Niess, R. Niet, N. Nikitin,\n  T. Nikodem, A. Nomerotski, A. Novoselov, A. Oblakowska-Mucha, V. Obraztsov,\n  S. Oggero, S. Ogilvy, O. Okhrimenko, R. Oldeman, M. Orlandea, J.M. Otalora\n  Goicochea, P. Owen, A. Oyanguren, B.K. Pal, A. Palano, M. Palutan, J. Panman,\n  A. Papanestis, M. Pappagallo, C. Parkes, C.J. Parkinson, G. Passaleva, G.D.\n  Patel, M. Patel, G.N. Patrick, C. Patrignani, C. Pavel-Nicorescu, A. Pazos\n  Alvarez, A. Pellegrino, G. Penso, M. Pepe Altarelli, S. Perazzini, D.L.\n  Perego, E. Perez Trigo, A. P\\'erez-Calero Yzquierdo, P. Perret, M.\n  Perrin-Terrin, G. Pessina, K. Petridis, A. Petrolini, A. Phan, E. Picatoste\n  Olloqui, B. Pietrzyk, T. Pila\\v{r}, D. Pinci, S. Playfer, M. Plo Casasus, F.\n  Polci, G. Polok, A. Poluektov, E. Polycarpo, D. Popov, B. Popovici, C.\n  Potterat, A. Powell, J. Prisciandaro, V. Pugatch, A. Puig Navarro, G. Punzi,\n  W. Qian, J.H. Rademacker, B. Rakotomiaramanana, M.S. Rangel, I. Raniuk, N.\n  Rauschmayr, G. Raven, S. Redford, M.M. Reid, A.C. dos Reis, S. Ricciardi, A.\n  Richards, K. Rinnert, V. Rives Molina, D.A. Roa Romero, P. Robbe, E.\n  Rodrigues, P. Rodriguez Perez, S. Roiser, V. Romanovsky, A. Romero Vidal, J.\n  Rouvinet, T. Ruf, F. Ruffini, H. Ruiz, P. Ruiz Valls, G. Sabatino, J.J.\n  Saborido Silva, N. Sagidova, P. Sail, B. Saitta, C. Salzmann, B. Sanmartin\n  Sedes, M. Sannino, R. Santacesaria, C. Santamarina Rios, E. Santovetti, M.\n  Sapunov, A. Sarti, C. Satriano, A. Satta, M. Savrie, D. Savrina, P. Schaack,\n  M. Schiller, H. Schindler, M. Schlupp, M. Schmelling, B. Schmidt, O.\n  Schneider, A. Schopper, M.-H. Schune, R. Schwemmer, B. Sciascia, A. Sciubba,\n  M. Seco, A. Semennikov, K. Senderowska, I. Sepp, N. Serra, J. Serrano, P.\n  Seyfert, M. Shapkin, I. Shapoval, P. Shatalov, Y. Shcheglov, T. Shears, L.\n  Shekhtman, O. Shevchenko, V. Shevchenko, A. Shires, R. Silva Coutinho, T.\n  Skwarnicki, N.A. Smith, E. Smith, M. Smith, M.D. Sokoloff, F.J.P. Soler, F.\n  Soomro, D. Souza, B. Souza De Paula, B. Spaan, A. Sparkes, P. Spradlin, F.\n  Stagni, S. Stahl, O. Steinkamp, S. Stoica, S. Stone, B. Storaci, M.\n  Straticiuc, U. Straumann, V.K. Subbiah, S. Swientek, V. Syropoulos, M.\n  Szczekowski, P. Szczypka, T. Szumlak, S. T'Jampens, M. Teklishyn, E.\n  Teodorescu, F. Teubert, C. Thomas, E. Thomas, J. van Tilburg, V. Tisserand,\n  M. Tobin, S. Tolk, D. Tonelli, S. Topp-Joergensen, N. Torr, E. Tournefier, S.\n  Tourneur, M.T. Tran, M. Tresch, A. Tsaregorodtsev, P. Tsopelas, N. Tuning, M.\n  Ubeda Garcia, A. Ukleja, D. Urner, U. Uwer, V. Vagnoni, G. Valenti, R.\n  Vazquez Gomez, P. Vazquez Regueiro, S. Vecchi, J.J. Velthuis, M. Veltri, G.\n  Veneziano, M. Vesterinen, B. Viaud, D. Vieira, X. Vilasis-Cardona, A.\n  Vollhardt, D. Volyanskyy, D. Voong, A. Vorobyev, V. Vorobyev, C. Vo{\\ss}, H.\n  Voss, R. Waldi, R. Wallace, S. Wandernoth, J. Wang, D.R. Ward, N.K. Watson,\n  A.D. Webber, D. Websdale, M. Whitehead, J. Wicht, J. Wiechczynski, D.\n  Wiedner, L. Wiggers, G. Wilkinson, M.P. Williams, M. Williams, F.F. Wilson,\n  J. Wishahi, M. Witek, S.A. Wotton, S. Wright, S. Wu, K. Wyllie, Y. Xie, F.\n  Xing, Z. Xing, Z. Yang, R. Young, X. Yuan, O. Yushchenko, M. Zangoli, M.\n  Zavertyaev, F. Zhang, L. Zhang, W.C. Zhang, Y. Zhang, A. Zhelezov, A.\n  Zhokhov, L. Zhong, A. Zvyagin","title":"First measurement of the CP-violating phase in $B_s^0 \\to \\phi \\phi$\n  decays","comments":"9 pages, 3 figures","journal-ref":"Phys. Rev. Lett. 110, 241802 (2013)","doi":"10.1103/PhysRevLett.110.241802","report-no":"LHCb-PAPER-2013-007, CERN-PH-EP-2013-046","categories":"hep-ex","license":"http://creativecommons.org/licenses/by/3.0/","abstract":"  A first flavour-tagged measurement of the time-dependent CP-violating\nasymmetry in $B_s^0 \\to \\phi\\phi$ decays is presented. In this decay channel,\nthe CP-violating weak phase arises due to CP violation in the interference\nbetween $B_s^0$-$\\bar{B}_s^0$ mixing and the $b \\to s \\bar{s} s $ gluonic\npenguin decay amplitude. Using a sample of $pp$ collision data corresponding to\nan integrated luminosity of $1.0\\; fb^{-1}$ and collected at a centre-of-mass\nenergy of $7 \\rm TeV$ with the LHCb detector, $880\\ \\B_s^0 \\to \\phi\\phi$ signal\ndecays are obtained. The CP-violating phase is measured to be in the interval\n[-2.46, -0.76] \\rm rad$ at 68% confidence level. The p-value of the Standard\nModel prediction is 16%.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:56:55 GMT"},{"version":"v2","created":"Fri, 14 Jun 2013 11:04:34 GMT"}],"update_date":"2013-06-17"}
{"id":"1303.7126","submitter":"Huai-liang Chang","authors":"Huai-Liang Chang, Jun Li, Wei-Ping Li","title":"Witten's top Chern class via cosection localization","comments":"35 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For a Landau Ginzburg space ([C^n/G],W), we construct the Witten's top Chern\nclasses as algebraic cycles via cosection localized virtual cycles in case all\nsectors are narrow. We verify all axioms of such classes. We derive an explicit\nformula of such classes in the free case. We prove that this construction is\nequivalent to the prior constructions of Polishchuk-Vaintrob, of Chiodo and of\nFan-Jarvis-Ruan.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:00:01 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7127","submitter":"Alexios Balatsoukas-Stimming","authors":"A. Balatsoukas-Stimming, A. J. Raymond, W. J. Gross, and A. Burg","title":"Hardware Architecture for List SC Decoding of Polar Codes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.AR math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a hardware architecture and algorithmic improvements for list SC\ndecoding of polar codes. More specifically, we show how to completely avoid\ncopying of the likelihoods, which is algorithmically the most cumbersome part\nof list SC decoding. The hardware architecture was synthesized for a\nblocklength of N = 1024 bits and list sizes L = 2, 4 using a UMC 90nm VLSI\ntechnology. The resulting decoder can achieve a coded throughput of 181 Mbps at\na frequency of 459 MHz.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:04:54 GMT"},{"version":"v2","created":"Fri, 14 Jun 2013 14:51:17 GMT"},{"version":"v3","created":"Thu, 27 Feb 2014 15:53:10 GMT"}],"update_date":"2014-02-28"}
{"id":"1303.7128","submitter":"Robert Stencel","authors":"Robert E. Stencel","title":"Results of the Recent \\epsilon Aurigae Eclipse Campaign","comments":"15 pages. See also Journal AAVSO vol. 40 #2 pp.618-632","journal-ref":"Central European Astrophys. Bulletin Vol. 37, 2013","doi":null,"report-no":"University of Denver Observatories Report 2013-1","categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Results of the 2010 eclipse campaign are described, and preliminary\ninterpretations proposed. These include photometric, interferometric,\nspectroscopic, astrometric and polarimetric observational results. Next steps,\nalong with continued monitoring, include simulations and other future work.\nNumerous acknowledgements are appropriate for the many participants in making\nthis international effort a success.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:12:10 GMT"},{"version":"v2","created":"Fri, 29 Mar 2013 02:37:10 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7129","submitter":"Anna Hasenfratz","authors":"Anna Hasenfratz, Anqi Cheng, Gregory Petropoulos and David Schaich","title":"Reaching the chiral limit in many flavor systems","comments":"7 pages, 5 figures; Contribution to SCGT12 \"KMI-GCOE Workshop on\n  Strong Coupling Gauge Theories in the LHC Perspective\", 4-7 Dec. 2012, Nagoya\n  University","journal-ref":null,"doi":"10.1142/9789814566254_0004","report-no":null,"categories":"hep-lat","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a brief overview of our recent lattice studies of SU(3) gauge\ntheory with N_f = 8 and 12 fundamental fermions, including some new and\nyet-unpublished results.\n  To explore relatively unfamiliar systems beyond lattice QCD, we carry out a\nwide variety of investigations with the goal of synthesizing the results to\nbetter understand the non-perturbative dynamics of these systems.\n  All our findings are consistent with conformal infrared dynamics in the\n12-flavor system, but with 8 flavors we observe puzzling behavior that requires\nfurther investigation.\n  Our new Monte Carlo renormalization group technique exploits the Wilson flow\nto obtain more direct predictions of a 12-flavor IR fixed point.\n  Studies of N_f = 12 bulk and finite-temperature transitions also indicate IR\nconformality, while our current results for the 8-flavor phase diagram do not\nyet provide clear signs of spontaneous chiral symmetry breaking.\n  From the Dirac eigenvalue spectrum we extract the mass anomalous dimension\ngamma_m, and predict gamma*_m = 0.32(3) at the 12-flavor fixed point.\n  The N_f = 8 system again shows interesting behavior, with a large anomalous\ndimension across a wide range of energy scales.\n  We use the eigenvalue density to predict the chiral condensate, and compare\nthis approach with direct and partially-quenched measurements.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:12:12 GMT"}],"update_date":"2017-08-23"}
{"id":"1303.7130","submitter":"Hyundae Lee","authors":"Hyeonbae Kang and Hyundae Lee","title":"Coated inclusions of finite conductivity neutral to multiple fields in\n  two dimensional conductivity or anti-plane elasticity","comments":null,"journal-ref":"Eur. J. Appl. Math 25 (2014) 329-338","doi":"10.1017/S0956792514000060","report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of neutral inclusions for two-dimensional\nconductivity and anti-plane elasticity. The neutral inclusion, when inserted in\na matrix having a uniform field, does not disturb the field outside the\ninclusion. The inclusion consists of a core and a shell. We show that if the\ninclusion is neutral to two linearly independent fields, then the core and the\nshell are confocal ellipses.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:15:01 GMT"}],"update_date":"2019-02-20"}
{"id":"1303.7131","submitter":"Nicolas Regnault","authors":"E. Dobardzic, M.V. Milovanovic, N. Regnault","title":"On the geometrical description of fractional Chern insulators based on\n  static structure factor calculations","comments":"13 pages, 7 figures, published version","journal-ref":"Phys. Rev. B 88, 115117 (2013)","doi":"10.1103/PhysRevB.88.115117","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the static structure factor of the fractional Chern insulator\nLaughlin-like state and provide analytical forms for this quantity in the\nlong-distance limit. In the course of this we identify averaged over Brillouin\nzone Fubini Study metric as the relevant metric in the long-distance limit. We\ndiscuss under which conditions the static structure factor will assume the\nusual behavior of Laughlin-like fractional quantum Hall system i.e. the\nscenario of Girvin, MacDonald, and Platzman [Phys. Rev. B 33, 2481 (1986)]. We\nstudy the influence of the departure of the averaged over Brillouin zone Fubini\nStudy metric from its fractional quantum Hall value which appears in the\nlong-distance analysis as an effective change of the filling factor. According\nto our exact diagonalization results on the Haldane model and analytical\nconsiderations we find persistence of fractional Chern insulator state even in\nthis region of the parameter space.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:17:11 GMT"},{"version":"v2","created":"Fri, 25 Oct 2013 01:43:03 GMT"}],"update_date":"2013-10-28"}
{"id":"1303.7132","submitter":"Davide Mandelli","authors":"Davide Mandelli and Andrea Vanossi and Erio Tosatti","title":"Stick-Slip Nanofriction in Trapped Cold Ion Chains","comments":"9 pages, 13 figures","journal-ref":null,"doi":"10.1103/PhysRevB.87.195418","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stick-slip -- the sequence of mechanical instabilities through which a slider\nadvances on a solid substrate -- is pervasive throughout sliding friction, from\nnano to geological scales. Here we suggest that trapped cold ions in an optical\nlattice can also be of help in understanding stick-slip friction, and also the\nway friction changes when one of the sliders undergoes structural transitions.\nFor that scope, we simulated the dynamical properties of a 101-ions chain,\ndriven to slide back and forth by a slowly oscillating electric field in an\nincommensurate periodic \"corrugation\" potential of increasing magnitude U0. We\nfound the chain sliding to switch, as U0 increases and before the Aubry\ntransition, from a smooth-sliding regime with low dissipation to a stick-slip\nregime with high dissipation. In the stick-slip regime the onset of overall\nsliding is preceded by precursor events consisting of partial slips of few ions\nonly, leading to partial depinning of the chain, a nutshell remnant of\nprecursor events at the onset of motion also observed in macroscopic sliders.\nSeeking to identify the possible effects on friction of a structural\ntransition, we reduced the trapping potential aspect ratio until the ion chain\nshape turned from linear to zigzag. Dynamic friction was found to rise at the\ntransition, reflecting the opening of newer dissipation channels.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:21:44 GMT"},{"version":"v2","created":"Thu, 2 May 2013 12:53:35 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7133","submitter":"Roberta Cardinale","authors":"LHCb collaboration: R. Aaij, C. Abellan Beteta, A. Adametz, B. Adeva,\n  M. Adinolfi, C. Adrover, A. Affolder, Z. Ajaltouni, J. Albrecht, F. Alessio,\n  M. Alexander, S. Ali, G. Alkhazov, P. Alvarez Cartelle, A.A. Alves Jr, S.\n  Amato, Y. Amhis, L. Anderlini, J. Anderson, R. Andreassen, R.B. Appleby, O.\n  Aquines Gutierrez, F. Archilli, A. Artamonov, M. Artuso, E. Aslanides, G.\n  Auriemma, S. Bachmann, J.J. Back, C. Baesso, V. Balagura, W. Baldini, R.J.\n  Barlow, C. Barschel, S. Barsuk, W. Barter, Th. Bauer, A. Bay, J. Beddow, I.\n  Bediaga, S. Belogurov, K. Belous, I. Belyaev, E. Ben-Haim, M. Benayoun, G.\n  Bencivenni, S. Benson, J. Benton, A. Berezhnoy, R. Bernet, M.-O. Bettler, M.\n  van Beuzekom, A. Bien, S. Bifani, T. Bird, A. Bizzeti, P.M. Bj{\\o}rnstad, T.\n  Blake, F. Blanc, C. Blanks, J. Blouw, S. Blusk, A. Bobrov, V. Bocci, A.\n  Bondar, N. Bondar, W. Bonivento, S. Borghi, A. Borgia, T.J.V. Bowcock, E.\n  Bowen, C. Bozzi, T. Brambach, J. van den Brand, J. Bressieux, D. Brett, M.\n  Britsch, T. Britton, N.H. Brook, H. Brown, I. Burducea, A. Bursche, J.\n  Buytaert, S. Cadeddu, O. Callot, M. Calvi, M. Calvo Gomez, A. Camboni, P.\n  Campana, A. Carbone, G. Carboni, R. Cardinale, A. Cardini, H. Carranza-Mejia,\n  L. Carson, K. Carvalho Akiba, G. Casse, M. Cattaneo, Ch. Cauet, M. Charles,\n  Ph. Charpentier, P. Chen, N. Chiapolini, M. Chrzaszcz, K. Ciba, X. Cid Vidal,\n  G. Ciezarek, P.E.L. Clarke, M. Clemencic, H.V. Cliff, J. Closier, C. Coca, V.\n  Coco, J. Cogan, E. Cogneras, P. Collins, A. Comerma-Montells, A. Contu, A.\n  Cook, M. Coombes, S. Coquereau, G. Corti, B. Couturier, G.A. Cowan, D. Craik,\n  S. Cunliffe, R. Currie, C. D'Ambrosio, P. David, P.N.Y. David, I. De Bonis,\n  K. De Bruyn, S. De Capua, M. De Cian, J.M. De Miranda, L. De Paula, W. De\n  Silva, P. De Simone, D. Decamp, M. Deckenhoff, H. Degaudenzi, L. Del Buono,\n  C. Deplano, D. Derkach, O. Deschamps, F. Dettori, A. Di Canto, J. Dickens, H.\n  Dijkstra, M. Dogaru, F. Domingo Bonal, S. Donleavy, F. Dordei, A. Dosil\n  Su\\'arez, D. Dossett, A. Dovbnya, F. Dupertuis, R. Dzhelyadin, A. Dziurda, A.\n  Dzyuba, S. Easo, U. Egede, V. Egorychev, S. Eidelman, D. van Eijk, S.\n  Eisenhardt, U. Eitschberger, R. Ekelhof, L. Eklund, I. El Rifai, Ch.\n  Elsasser, D. Elsby, A. Falabella, C. F\\\"arber, G. Fardell, C. Farinelli, S.\n  Farry, V. Fave, D. Ferguson, V. Fernandez Albor, F. Ferreira Rodrigues, M.\n  Ferro-Luzzi, S. Filippov, C. Fitzpatrick, M. Fontana, F. Fontanelli, R.\n  Forty, O. Francisco, M. Frank, C. Frei, M. Frosini, S. Furcas, E. Furfaro, A.\n  Gallas Torreira, D. Galli, M. Gandelman, P. Gandini, Y. Gao, J. Garofoli, P.\n  Garosi, J. Garra Tico, L. Garrido, C. Gaspar, R. Gauld, E. Gersabeck, M.\n  Gersabeck, T. Gershon, Ph. Ghez, V. Gibson, V.V. Gligorov, C. G\\\"obel, D.\n  Golubkov, A. Golutvin, A. Gomes, H. Gordon, M. Grabalosa G\\'andara, R.\n  Graciani Diaz, L.A. Granado Cardoso, E. Graug\\'es, G. Graziani, A. Grecu, E.\n  Greening, S. Gregson, O. Gr\\\"unberg, B. Gui, E. Gushchin, Yu. Guz, T. Gys, C.\n  Hadjivasiliou, G. Haefeli, C. Haen, S.C. Haines, S. Hall, T. Hampson, S.\n  Hansmann-Menzemer, N. Harnew, S.T. Harnew, J. Harrison, P.F. Harrison, T.\n  Hartmann, J. He, V. Heijne, K. Hennessy, P. Henrard, J.A. Hernando Morata, E.\n  van Herwijnen, E. Hicks, D. Hill, M. Hoballah, C. Hombach, P. Hopchev, W.\n  Hulsbergen, P. Hunt, T. Huse, N. Hussain, D. Hutchcroft, D. Hynds, V.\n  Iakovenko, P. Ilten, R. Jacobsson, A. Jaeger, E. Jans, F. Jansen, P. Jaton,\n  F. Jing, M. John, D. Johnson, C.R. Jones, B. Jost, M. Kaballo, S. Kandybei,\n  M. Karacson, T.M. Karbach, I.R. Kenyon, U. Kerzel, T. Ketel, A. Keune, B.\n  Khanji, O. Kochebina, I. Komarov, R.F. Koopman, P. Koppenburg, M. Korolev, A.\n  Kozlinskiy, L. Kravchuk, K. Kreplin, M. Kreps, G. Krocker, P. Krokovny, F.\n  Kruse, M. Kucharczyk, V. Kudryavtsev, T. Kvaratskheliya, V.N. La Thi, D.\n  Lacarrere, G. Lafferty, A. Lai, D. Lambert, R.W. Lambert, E. Lanciotti, G.\n  Lanfranchi, C. Langenbruch, T. Latham, C. Lazzeroni, R. Le Gac, J. van\n  Leerdam, J.-P. Lees, R. Lef\\`evre, A. Leflat, J. Lefran\\c{c}ois, O. Leroy, Y.\n  Li, L. Li Gioi, M. Liles, R. Lindner, C. Linn, B. Liu, G. Liu, J. von Loeben,\n  J.H. Lopes, E. Lopez Asamar, N. Lopez-March, H. Lu, J. Luisier, H. Luo, F.\n  Machefert, I.V. Machikhiliyan, F. Maciuc, O. Maev, S. Malde, G. Manca, G.\n  Mancinelli, N. Mangiafave, U. Marconi, R. M\\\"arki, J. Marks, G. Martellotti,\n  A. Martens, L. Martin, A. Mart\\'in S\\'anchez, M. Martinelli, D. Martinez\n  Santos, D. Martins Tostes, A. Massafferri, R. Matev, Z. Mathe, C. Matteuzzi,\n  M. Matveev, E. Maurice, A. Mazurov, J. McCarthy, R. McNulty, B. Meadows, F.\n  Meier, M. Meissner, M. Merk, D.A. Milanes, M.-N. Minard, J. Molina Rodriguez,\n  S. Monteil, D. Moran, P. Morawski, R. Mountain, I. Mous, F. Muheim, K.\n  M\\\"uller, R. Muresan, B. Muryn, B. Muster, P. Naik, T. Nakada, R. Nandakumar,\n  I. Nasteva, M. Needham, N. Neufeld, A.D. Nguyen, T.D. Nguyen, C. Nguyen-Mau,\n  M. Nicol, V. Niess, R. Niet, N. Nikitin, T. Nikodem, S. Nisar, A. Nomerotski,\n  A. Novoselov, A. Oblakowska-Mucha, V. Obraztsov, S. Oggero, S. Ogilvy, O.\n  Okhrimenko, R. Oldeman, M. Orlandea, J.M. Otalora Goicochea, P. Owen, B.K.\n  Pal, A. Palano, M. Palutan, J. Panman, A. Papanestis, M. Pappagallo, C.\n  Parkes, C.J. Parkinson, G. Passaleva, G.D. Patel, M. Patel, G.N. Patrick, C.\n  Patrignani, C. Pavel-Nicorescu, A. Pazos Alvarez, A. Pellegrino, G. Penso, M.\n  Pepe Altarelli, S. Perazzini, D.L. Perego, E. Perez Trigo, A. P\\'erez-Calero\n  Yzquierdo, P. Perret, M. Perrin-Terrin, G. Pessina, K. Petridis, A.\n  Petrolini, A. Phan, E. Picatoste Olloqui, B. Pietrzyk, T. Pila\\v{r}, D.\n  Pinci, S. Playfer, M. Plo Casasus, F. Polci, G. Polok, A. Poluektov, E.\n  Polycarpo, D. Popov, B. Popovici, C. Potterat, A. Powell, J. Prisciandaro, V.\n  Pugatch, A. Puig Navarro, W. Qian, J.H. Rademacker, B. Rakotomiaramanana,\n  M.S. Rangel, I. Raniuk, N. Rauschmayr, G. Raven, S. Redford, M.M. Reid, A.C.\n  dos Reis, S. Ricciardi, A. Richards, K. Rinnert, V. Rives Molina, D.A. Roa\n  Romero, P. Robbe, E. Rodrigues, P. Rodriguez Perez, G.J. Rogers, S. Roiser,\n  V. Romanovsky, A. Romero Vidal, J. Rouvinet, T. Ruf, H. Ruiz, G. Sabatino,\n  J.J. Saborido Silva, N. Sagidova, P. Sail, B. Saitta, C. Salzmann, B.\n  Sanmartin Sedes, M. Sannino, R. Santacesaria, C. Santamarina Rios, E.\n  Santovetti, M. Sapunov, A. Sarti, C. Satriano, A. Satta, M. Savrie, D.\n  Savrina, P. Schaack, M. Schiller, H. Schindler, S. Schleich, M. Schlupp, M.\n  Schmelling, B. Schmidt, O. Schneider, A. Schopper, M.-H. Schune, R.\n  Schwemmer, B. Sciascia, A. Sciubba, M. Seco, A. Semennikov, K. Senderowska,\n  I. Sepp, N. Serra, J. Serrano, P. Seyfert, M. Shapkin, I. Shapoval, P.\n  Shatalov, Y. Shcheglov, T. Shears, L. Shekhtman, O. Shevchenko, V.\n  Shevchenko, A. Shires, R. Silva Coutinho, T. Skwarnicki, N.A. Smith, E.\n  Smith, M. Smith, K. Sobczak, M.D. Sokoloff, F.J.P. Soler, F. Soomro, D.\n  Souza, B. Souza De Paula, B. Spaan, A. Sparkes, P. Spradlin, F. Stagni, S.\n  Stahl, O. Steinkamp, S. Stoica, S. Stone, B. Storaci, M. Straticiuc, U.\n  Straumann, V.K. Subbiah, S. Swientek, V. Syropoulos, M. Szczekowski, P.\n  Szczypka, T. Szumlak, S. T'Jampens, M. Teklishyn, E. Teodorescu, F. Teubert,\n  C. Thomas, E. Thomas, J. van Tilburg, V. Tisserand, M. Tobin, S. Tolk, D.\n  Tonelli, S. Topp-Joergensen, N. Torr, E. Tournefier, S. Tourneur, M.T. Tran,\n  M. Tresch, A. Tsaregorodtsev, P. Tsopelas, N. Tuning, M. Ubeda Garcia, A.\n  Ukleja, D. Urner, U. Uwer, V. Vagnoni, G. Valenti, R. Vazquez Gomez, P.\n  Vazquez Regueiro, S. Vecchi, J.J. Velthuis, M. Veltri, G. Veneziano, M.\n  Vesterinen, B. Viaud, D. Vieira, X. Vilasis-Cardona, A. Vollhardt, D.\n  Volyanskyy, D. Voong, A. Vorobyev, V. Vorobyev, C. Vo\\ss, H. Voss, R. Waldi,\n  R. Wallace, S. Wandernoth, J. Wang, D.R. Ward, N.K. Watson, A.D. Webber, D.\n  Websdale, M. Whitehead, J. Wicht, J. Wiechczynski, D. Wiedner, L. Wiggers, G.\n  Wilkinson, M.P. Williams, M. Williams, F.F. Wilson, J. Wishahi, M. Witek,\n  S.A. Wotton, S. Wright, S. Wu, K. Wyllie, Y. Xie, F. Xing, Z. Xing, Z. Yang,\n  R. Young, X. Yuan, O. Yushchenko, M. Zangoli, M. Zavertyaev, F. Zhang, L.\n  Zhang, W.C. Zhang, Y. Zhang, A. Zhelezov, L. Zhong, A. Zvyagin","title":"Measurements of the branching fractions of $B^{+} \\to p \\bar p K^{+}$\n  decays","comments":"14 pages, 5 figures","journal-ref":"Eur.Phys.J. C73 (2013) 2462","doi":"10.1140/epjc/s10052-013-2462-2","report-no":"LHCb-PAPER-2012-047, CERN-PH-EP-2013-040","categories":"hep-ex","license":"http://creativecommons.org/licenses/by/3.0/","abstract":"  The branching fractions of the decay $B^{+} \\to p \\bar p K^{+}$ for different\nintermediate states are measured using data, corresponding to an integrated\nluminosity of $1.0 fb^{-1}$, collected by the LHCb experiment. The total\nbranching fraction, its charmless component $(M_{p\\bar p} <2.85 {GeV/}c^{2})$\nand the branching fractions via the resonant $c\\bar c$ states $\\eta_{c}(1S)$\nand $\\psi(2S)$ relative to the decay via a $J/\\psi$ intermediate state are\n{align*} \\frac{{\\mathcal B}(B^{+} \\to p \\bar p K^{+})_{total}}{{\\mathcal\nB}(B^{+} \\to J/\\psi K^{+} \\to p \\bar p K^{+})}=& \\, 4.91 \\pm 0.19 \\, {(\\rm\nstat)} \\pm 0.14 \\, {(\\rm syst)}, \\frac{{\\mathcal B}(B^{+} \\to p \\bar p\nK^{+})_{M_{p\\bar p} <2.85 {GeV/}c^{2}}}{{\\mathcal B}(B^{+} \\to J/\\psi K^{+} \\to\np \\bar p K^{+})}=& \\, 2.02 \\pm 0.10 \\, {(\\rm stat)}\\pm 0.08 \\, {(\\rm syst)},\n\\frac{{\\mathcal B} (B^{+} \\to \\eta_{c}(1S) K^{+} \\to p \\bar p K^{+})}{{\\mathcal\nB}(B^{+} \\to J/\\psi K^{+} \\to p \\bar p K^{+})} = & \\, 0.578 \\pm 0.035 \\, {(\\rm\nstat)} \\pm 0.027 \\, {(\\rm syst)}, \\frac{{\\mathcal B} (B^{+} \\to \\psi(2S) K^{+}\n\\to p \\bar p K^{+})}{{\\mathcal B}(B^{+} \\to J/\\psi K^{+} \\to p \\bar p K^{+})}=&\n\\, 0.080 \\pm 0.012 \\, {(\\rm stat)} \\pm 0.009 \\, {(\\rm syst)}. {align*} Upper\nlimits on the $B^{+}$ branching fractions into the $\\eta_{c}(2S)$ meson and\ninto the charmonium-like states X(3872) and X(3915) are also obtained.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:24:56 GMT"},{"version":"v2","created":"Tue, 16 Jul 2013 12:51:41 GMT"}],"update_date":"2016-08-11"}
{"id":"1303.7134","submitter":"David Dudal","authors":"D. Dudal, M. S. Guimaraes, L. F. Palhares, S. P. Sorella","title":"Confinement and dynamical chiral symmetry breaking in a non-perturbative\n  renormalizable quark model","comments":"10 pages, 3 figures. v2: extended version; added intermediate\n  computations + extra references. v3: partially rewritten version, new title,\n  extra background material (21 pages). v4: version accepted for publication in\n  Ann.Phys. (23 pages)","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-lat hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Inspired by the construction of the Gribov-Zwanziger action in the Landau\ngauge, we introduce a quark model exhibiting both confinement and chiral\nsymmetry aspects. An important feature is the incorporation of spontaneous\nchiral symmetry breaking in a renormalizable fashion. The quark propagator in\nthe condensed vacuum turns out to be of a confining type. Besides a real pole,\nit exhibits complex conjugate poles. The resulting spectral form is explicitly\nshown to violate positivity, indicative of its unphysical character. Moreover,\nthe ensuing quark mass function fits well to existing lattice data. To further\nvalidate the physical nature of the model, we identify a massless pseudoscalar\n(i.e. a pion) in the chiral limit and present estimates for the rho meson mass\nand decay constant.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:26:12 GMT"},{"version":"v2","created":"Thu, 17 Oct 2013 13:54:44 GMT"},{"version":"v3","created":"Tue, 18 Aug 2015 13:12:29 GMT"},{"version":"v4","created":"Wed, 6 Jan 2016 10:23:28 GMT"}],"update_date":"2016-01-07"}
{"id":"1303.7135","submitter":"Bernard Derrida","authors":"B. Derrida and M. Retaux","title":"Finite size corrections to the large deviation function of the density\n  in the one dimensional symmetric simple exclusion process","comments":null,"journal-ref":null,"doi":"10.1007/s10955-013-0797-6","report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The symmetric simple exclusion process is one of the simplest\nout-of-equilibrium systems for which the steady state is known. Its large\ndeviation functional of the density has been computed in the past both by\nmicroscopic and macroscopic approaches. Here we obtain the leading finite size\ncorrection to this large deviation functional. The result is compared to the\nsimilar corrections for equilibrium systems.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:31:38 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7136","submitter":"EPTCS","authors":"Delia Kesner (Universit\\'e Paris-Diderot), Petrucio Viana\n  (Universidade Federal Fluminense)","title":"Proceedings Seventh Workshop on Logical and Semantic Frameworks, with\n  Applications","comments":null,"journal-ref":"EPTCS 113, 2013","doi":"10.4204/EPTCS.113","report-no":null,"categories":"cs.LO cs.PL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This document contains the proceedings of the Seventh International Workshop\non Logical and Semantic Frameworks, with Applications, which was held on\nSeptember 29 and 30, 2012, in Rio de Janeiro, Brazil. It contains 11 regular\npapers (9 long and 2 short) accepted for presentation at the meeting, as well\nas extended abstracts of invited talks by Torben Bra\\\"uner (Roskilde\nUniversity, Denmark), Maribel Fern\\'andez (King's College London, United\nKingdom), Edward Hermann Haeusler (PUC-Rio, Brazil) and Alexandre Miquel\n(\\'Ecole Normale Sup\\'erieure de Lyon, France).\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:45:17 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7137","submitter":"Maksims Fiosins","authors":"A. Andronov and M. Fioshin","title":"Discrete Optimization of Statistical Sample Sizes in Simulation by Using\n  the Hierarchical Bootstrap Method","comments":"9 pages","journal-ref":"proceedings of the 6th Tartu Conference, 1999","doi":null,"report-no":null,"categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Bootstrap method application in simulation supposes that value of random\nvariables are not generated during the simulation process but extracted from\navailable sample populations. In the case of Hierarchical Bootstrap the\nfunction of interest is calculated recurrently using the calculation tree. In\nthe present paper we consider the optimization of sample sizes in each vertex\nof the calculation tree. The dynamic programming method is used for this aim.\nProposed method allows to decrease a variance of system characteristic\nestimators.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:48:44 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7138","submitter":"Isabelle Robert-Philip","authors":"Armand Lebreton, Izo Abram, R\\'emy Braive, Isabelle Sagnes, Isabelle\n  Robert-Philip and Alexios Beveratos","title":"Unequivocal differentiation of coherent and chaotic light through\n  interferometric photon correlation measurements","comments":"5 pages, 3 figures","journal-ref":null,"doi":"10.1103/PhysRevLett.110.163603","report-no":null,"categories":"quant-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a novel experimental technique that can differentiate\nunequivocally between chaotic light and coherent light with amplitude\nfluctuations, and thus permits to characterize unambiguously the output of a\nlaser. This technique consists of measuring the second-order intensity\ncross-correlation at the outputs of an unbalanced Michelson interferometer. It\nis applied to a chaotic light source and to the output of a semiconductor\nnanolaser whose \"standard\" intensity correlation function above-threshold\ndisplays values compatible with a mixture of coherent and chaotic light. Our\nexperimental results demonstrate that the output of such lasers is not\npartially chaotic but is indeed a coherent state with amplitude fluctuations.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:49:35 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7139","submitter":"Sean Gryb B","authors":"Sean Gryb and Karim Thebault","title":"Symmetry and Evolution in Quantum Gravity","comments":"29 pages. 1 table (version accepted to Foundations of Physics)","journal-ref":"Found. Phys., Vol 44, Issue 3 (2014), Page 305-34","doi":"10.1007/s10701-014-9789-x","report-no":null,"categories":"gr-qc hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose an operator constraint equation for the wavefunction of the\nUniverse that admits genuine evolution. While the corresponding classical\ntheory is equivalent to the canonical decomposition of General Relativity, the\nquantum theory makes predictions that are distinct from Wheeler-DeWitt\ncosmology. Furthermore, the local symmetry principle - and corresponding\nobservables - of the theory have a direct interpretation in terms of a\nconventional gauge theory, where the gauge symmetry group is that of spatial\nconformal diffeomorphisms (that preserve the spatial volume of the Universe).\nThe global evolution is in terms of an arbitrary parameter that serves only as\nan unobservable label for successive states of the Universe. Our proposal\nfollows unambiguously from a suggestion of York whereby the independently\nspecifiable initial data in the action principle of General Relativity is given\nby a conformal geometry and the spatial average of the York time on the\nspacelike hypersurfaces that bound the variation. Remarkably, such a\nvariational principle uniquely selects the form of the constraints of the\ntheory so that we can establish a precise notion of both symmetry and evolution\nin quantum gravity.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:50:07 GMT"},{"version":"v2","created":"Tue, 25 Mar 2014 11:21:22 GMT"}],"update_date":"2014-04-03"}
{"id":"1303.7140","submitter":"Alexander Stibor","authors":"Georg Sch\\\"utz, Alexander Rembold, Andreas Pooch, Henrike Prochel and\n  Alexander Stibor","title":"Effective beam separation schemes for the measurement of the electric\n  Aharonov-Bohm effect in an ion interferometer","comments":null,"journal-ref":"Ultramicroscopy 158, 65 (2015)","doi":"10.1016/j.ultramic.2015.06.016","report-no":null,"categories":"physics.optics physics.ins-det quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose an experiment for the first proof of the type I electric\nAharonov-Bohm effect in an ion interferometer for hydrogen. The performances of\nthree different beam separation schemes are simulated and compared. The\ncoherent ion beam is generated by a single atom tip (SAT) source and separated\nby either two biprisms with a quadrupole lens, two biprisms with an einzel-lens\nor three biprisms. The beam path separation is necessary to introduce two metal\ntubes that can be pulsed with different electric potentials. The high time\nresolution of a delay line detector allows to work with a continuous ion beam\nand circumvents the pulsed beam operation as originally suggested by Aharonov\nand Bohm. We demonstrate, that the higher mass and therefore lower velocity of\nions compared to electrons combined with the high expected SAT ion emission\nputs the direct proof of this quantum effect for the first time into reach of\ncurrent technical possibilities. Thereby a high coherent ion detection rate is\ncrucial to avoid long integration times that allow the influence of dephasing\nnoise from the environment. We can determine the period of the expected matter\nwave interference pattern and the signal on the detector by determining the\nsuperposition angle of the coherent partial beams. Our simulations were tested\nwith an electron interferometer setup and agree with the experimental results.\nWe determine the separation scheme with three biprisms to be most efficient and\npredict a total signal acquisition time of only 80 s to measure a phase shift\nfrom 0 to 2$\\pi$ due to the electric Aharonov-Bohm effect.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:51:03 GMT"},{"version":"v2","created":"Sun, 20 Oct 2013 15:41:47 GMT"},{"version":"v3","created":"Tue, 19 Nov 2013 19:21:08 GMT"},{"version":"v4","created":"Fri, 19 Dec 2014 21:35:08 GMT"},{"version":"v5","created":"Tue, 28 Jul 2015 18:32:55 GMT"}],"update_date":"2017-03-24"}
{"id":"1303.7141","submitter":"Andrey Palnichenko","authors":"N.S. Sidorov, A.V. Palnichenko, D. V. Shakhrai, V. V. Avdonin, O. M.\n  Vyaselev, S.S. Khasanov","title":"Superconductivity of Mg/MgO interface formed by shock-wave pressure","comments":null,"journal-ref":"Physica C 488 (2013) 18-24","doi":"10.1016/j.physc.2013.02.012","report-no":null,"categories":"cond-mat.supr-con","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A mixture of Mg and MgO has been subjected to a shock-wave pressure of 170\nkbar. The ac susceptibility measurements of the product has revealed a\nmetastable superconductivity with Tc=30 K, characterized by glassy dynamics of\nthe shielding currents below Tc. Comparison of the ac susceptibility and the dc\nmagnetization measurements infers that the superconductivity arises within the\ninterfacial layer formed between metallic Mg and its oxide due to the\nshock-wave treatment.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:52:35 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7142","submitter":"Sarah C. Gallagher","authors":"S. C. Gallagher, M. M. Abado (U. of Western Ontario), J. E. Everett\n  (Northwestern U.), S. Keating (U. Toronto), R. P. Deo","title":"Why a Windy Torus?","comments":"8 pages. Proceedings article for the Torus Workshop 2012 held at U.\n  Texas at San Antonio Dec 5-7, 2012. C. Packham. R. Mason, A. Alonson-Herrero\n  (eds.)","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mass ejection in the form of winds or jets appears to be as fundamental to\nquasar activity as accretion, and can be directly observed in many objects with\nbroadened and blue-shifted UV absorption features. A convincing argument for\nradiation pressure driving this ionized outflow can be made within the dust\nsublimation radius. Beyond, radiation pressure is even more important, as high\nenergy photons from the central engine can now push on dust grains. This\nphysics underlies the dusty-wind model for the putative obscuring torus.\nSpecifically, the dusty wind in our model is first launched from the outer\naccretion disk as a magneto-centrifugal wind and then accelerated and shaped by\nradiation pressure from the central continuum. Such a wind can plausibly\naccount for both the necessary obscuring medium to explain the ratio of\nbroad-to-narrow-line objects and the mid-infrared emission commonly seen in\nquasar spectral energy distributions. A convincing demonstration that\nlarge-scale, organized magnetic fields are present in radio-quiet active\ngalactic nuclei is now required to bolster the case for this paradigm.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:54:52 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7143","submitter":"Fred Espen Benth","authors":"Fred Espen Benth, Andr\\'e S\\\"u{\\ss}","title":"Integration theory for infinite dimensional volatility modulated\n  Volterra processes","comments":"Published at http://dx.doi.org/10.3150/15-BEJ696 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)","journal-ref":"Bernoulli 2016, Vol. 22, No. 3, 1383-1430","doi":"10.3150/15-BEJ696","report-no":"IMS-BEJ-BEJ696","categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We treat a stochastic integration theory for a class of Hilbert-valued,\nvolatility-modulated, conditionally Gaussian Volterra processes. We apply\ntechniques from Malliavin calculus to define this stochastic integration as a\nsum of a Skorohod integral, where the integrand is obtained by applying an\noperator to the original integrand, and a correction term involving the\nMalliavin derivative of the same altered integrand, integrated against the\nLebesgue measure. The resulting integral satisfies many of the expected\nproperties of a stochastic integral, including an It\\^{o} formula. Moreover, we\nderive an alternative definition using a random-field approach and relate both\nconcepts. We present examples related to fundamental solutions to partial\ndifferential equations.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:55:59 GMT"},{"version":"v2","created":"Thu, 17 Mar 2016 14:22:02 GMT"}],"update_date":"2016-03-18"}
{"id":"1303.7144","submitter":"Yu-Ru Lin Yu-Ru Lin","authors":"Yu-Ru Lin, Drew Margolin, Brian Keegan, Andrea Baronchelli, David\n  Lazer","title":"#Bigbirds Never Die: Understanding Social Dynamics of Emergent Hashtag","comments":"Proceedings of the 7th International AAAI Conference on Weblogs and\n  Social Media (ICWSM 2013)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI physics.data-an physics.soc-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We examine the growth, survival, and context of 256 novel hashtags during the\n2012 U.S. presidential debates. Our analysis reveals the trajectories of\nhashtag use fall into two distinct classes: \"winners\" that emerge more quickly\nand are sustained for longer periods of time than other \"also-rans\" hashtags.\nWe propose a \"conversational vibrancy\" framework to capture dynamics of\nhashtags based on their topicality, interactivity, diversity, and prominence.\nStatistical analyses of the growth and persistence of hashtags reveal novel\nrelationships between features of this framework and the relative success of\nhashtags. Specifically, retweets always contribute to faster hashtag adoption,\nreplies extend the life of \"winners\" while having no effect on \"also-rans.\"\nThis is the first study on the lifecycle of hashtag adoption and use in\nresponse to purely exogenous shocks. We draw on theories of uses and\ngratification, organizational ecology, and language evolution to discuss these\nfindings and their implications for understanding social influence and\ncollective action in social media more generally.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:58:45 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7145","submitter":"Sangbum Cho","authors":"Sangbum Cho and Yuya Koda","title":"The genus two Goeritz group of $S^2 \\times S^1$","comments":"minor changes; to appear in Mathematical Research Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The genus-g Goeritz group is the group of isotopy classes of\norientation-preserving homeomorphisms of a closed orientable 3-manifold that\npreserve a given genus-g Heegaard splitting of the manifold. In this work, we\nshow that the genus-2 Goeritz group of $S^2 \\times S^1$ is finitely presented,\nand give its explicit presentation.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:01:09 GMT"},{"version":"v2","created":"Sat, 18 Jan 2014 09:17:04 GMT"}],"update_date":"2014-01-21"}
{"id":"1303.7146","submitter":"Bozena Piatek","authors":"Bozena Piatek and Rafa Espinola","title":"Diversities, hyperconvexity and fixed points","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diversities have been recently introduced as a generalization of metrics for\nwhich a rich tight span theory could be stated. In this work we take up a\nnumber of questions about hyperconvexity, diversities and fixed points of\nnonexpansive mappings. Most of these questions are motivated by the study of\nthe connection between a hyperconvex diversity and its induced metric space for\nwhich we provide some answers. Examples are given, for instance, showing that\nsuch a metric space need not be hyperconvex but still we prove, as our main\nresult, that they enjoy the fixed point property for nonexpansive mappings\nprovided the diversity is bounded and that this boundedness condition cannot be\ntransferred from the diversity to the induced metric space.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:07:10 GMT"}],"update_date":"2016-10-05"}
{"id":"1303.7147","submitter":"Semen Gorfman","authors":"Semen Gorfman, Oleg Schmidt, Vladimir Tsirelson, Michael Ziolkowski,\n  Ullrich Pietsch","title":"Crystallography under external electric field","comments":"10 pages, 10 figures","journal-ref":null,"doi":"10.1002/zaac.201200497","report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Structural response of crystals to an applied external perturbation is\nimportant as a key for understanding microscopic origin of physical properties.\nExperimental investigation of structural response is a great challenge for\nmodern structure analysis. We demonstrate how advanced X-ray diffraction\ntechniques facilitate probing tiny (10-4 {\\AA}) distortions of bond lengths\nunder a permanent electric field. We also discuss details of the experimental\nprocedure essential for reaching such precision. We ask whether the experiment\ncan be used to evaluate chemical bonds in crystals by their sensitivity to an\nexternal electric field and discuss if the bond deformations can be predicted\nusing the bond-valence model or the Bader's theory of atoms in molecules and\ncrystals. Finally, we describe the new time-resolved studies of a structural\nresponse to a dynamical switch of applied electric field. These results give\naccess to the time-lining of piezoelectric effect on a microsecond time scale.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:23:13 GMT"}],"update_date":"2016-05-24"}
{"id":"1303.7148","submitter":"Randy Dumas","authors":"Randy K. Dumas, Ezio Iacocca, Stefano Bonetti, Sohrab Sani, Majid\n  Mohseni, Anders Eklund, Johan Persson, Olle Heinonen, and Johan {\\AA}kerman","title":"Spin wave mode coexistence on the nano-scale: A consequence of the\n  Oersted field induced asymmetric energy landscape","comments":"20 pages (including supplementary material), 6 figures","journal-ref":null,"doi":"10.1103/PhysRevLett.110.257202","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It has been argued that if multiple spin wave modes are competing for the\nsame centrally located energy source, as in a nanocontact spin torque\noscillator, that only one mode should survive in the steady state. Here, the\nexperimental conditions necessary for mode coexistence are explored. Mode\ncoexistence is facilitated by the local field asymmetries induced by the\nspatially inhomogeneous Oersted field, which leads to a physical separation of\nthe modes, and is further promoted by spin wave localization at reduced applied\nfield angles. Finally, both simulation and experiment reveal a low frequency\nsignal consistent with the intermodulation of two coexistent modes.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:26:30 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7149","submitter":"Andre Vellino","authors":"Andr\\'e Vellino","title":"Usage-based vs. Citation-based Methods for Recommending Scholarly\n  Research Articles","comments":"4 pages, 4 figures, ACM Recommender Systems Workshop 2012, Dublin\n  Ireland","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DL cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There are two principal data sources for collaborative filtering recommenders\nin scholarly digital libraries: usage data obtained from harvesting a large,\ndistributed collection of Open URL web logs and citation data obtained from the\njournal articles. This study explores the characteristics of recommendations\ngenerated by implementations of these two methods: the 'bX' system by ExLibris\nand an experimental citation-based recommender, Sarkanto. Recommendations from\neach system were compared according to their semantic similarity to the seed\narticle that was used to generate them. Since the full text of the articles was\nnot available for all the recommendations in both systems, the semantic\nsimilarity between the seed article and the recommended articles was deemed to\nbe the semantic distance between the journals in which the articles were\npublished. The semantic distance between journals was computed from the\n\"semantic vectors\" distance between all the terms in the full-text of the\navailable articles in that journal and this study shows that citation-based\nrecommendations are more semantically diverse than usage-based ones. These\nrecommenders are complementary since most of the time, when one recommender\nproduces recommendations the other does not.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:27:16 GMT"},{"version":"v2","created":"Fri, 29 Mar 2013 02:21:53 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7150","submitter":"Quesne Christiane","authors":"I. Marquette, C. Quesne","title":"New ladder operators for a rational extension of the harmonic oscillator\n  and superintegrability of some two-dimensional systems","comments":"22 pages, published version","journal-ref":"J. Math. Phys. 54 (2013) 102102, 12 pages","doi":"10.1063/1.4823771","report-no":"ULB/229/CQ/13/1","categories":"math-ph math.MP nlin.SI quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  New ladder operators are constructed for a rational extension of the harmonic\noscillator associated with type III Hermite exceptional orthogonal polynomials\nand characterized by an even integer $m$. The eigenstates of the Hamiltonian\nseparate into $m+1$ infinite-dimensional unitary irreducible representations of\nthe corresponding polynomial Heisenberg algebra. These ladder operators are\nused to construct a higher-order integral of motion for two superintegrable\ntwo-dimensional systems separable in cartesian coordinates. The polynomial\nalgebras of such systems provide for the first time an algebraic derivation of\nthe whole spectrum through their finite-dimensional unitary irreducible\nrepresentations.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:33:53 GMT"},{"version":"v2","created":"Wed, 3 Jul 2013 12:21:39 GMT"},{"version":"v3","created":"Fri, 11 Oct 2013 12:49:51 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7151","submitter":"Akira Endo","authors":"A. Endo, C. Sfiligoj, S. J. C. Yates, J. J. A. Baselmans, D. J. Thoen,\n  S. M. H. Javadzadeh, P. P. van der Werf, A. M. Baryshev, and T. M. Klapwijk","title":"On-chip filter bank spectroscopy at 600-700 GHz using NbTiN\n  superconducting resonators","comments":"4 pages, 3 figures, submitted to Applied Physics Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM cond-mat.supr-con","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We experimentally demonstrate the principle of an on-chip submillimeter wave\nfilter bank spectrometer, using superconducting microresonators as narrow\nband-separation filters. The filters are made of NbTiN/SiNx/NbTiN microstrip\nline resonators, which have a resonance frequency in the range of 614-685\nGHz---two orders of magnitude higher in frequency than what is currently\nstudied for use in circuit quantum electrodynamics and photodetectors. The\nfrequency resolution of the filters decreases from 350 to 140 with increasing\nfrequency, most likely limited by dissipation of the resonators.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:34:49 GMT"},{"version":"v2","created":"Fri, 21 Jun 2013 06:45:24 GMT"}],"update_date":"2013-06-24"}
{"id":"1303.7152","submitter":"Victor Chernozhukov","authors":"Victor Chernozhukov, Denis Chetverikov, Kengo Kato","title":"Anti-concentration and honest, adaptive confidence bands","comments":"Published in at http://dx.doi.org/10.1214/14-AOS1235 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)","journal-ref":"Annals of Statistics 2014, Vol. 42, No. 5, 1787-1818","doi":"10.1214/14-AOS1235","report-no":"IMS-AOS-AOS1235","categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modern construction of uniform confidence bands for nonparametric densities\n(and other functions) often relies on the classical Smirnov-Bickel-Rosenblatt\n(SBR) condition; see, for example, Gin\\'{e} and Nickl [Probab. Theory Related\nFields 143 (2009) 569-596]. This condition requires the existence of a limit\ndistribution of an extreme value type for the supremum of a studentized\nempirical process (equivalently, for the supremum of a Gaussian process with\nthe same covariance function as that of the studentized empirical process). The\nprincipal contribution of this paper is to remove the need for this classical\ncondition. We show that a considerably weaker sufficient condition is derived\nfrom an anti-concentration property of the supremum of the approximating\nGaussian process, and we derive an inequality leading to such a property for\nseparable Gaussian processes. We refer to the new condition as a generalized\nSBR condition. Our new result shows that the supremum does not concentrate too\nfast around any value. We then apply this result to derive a Gaussian\nmultiplier bootstrap procedure for constructing honest confidence bands for\nnonparametric density estimators (this result can be applied in other\nnonparametric problems as well). An essential advantage of our approach is that\nit applies generically even in those cases where the limit distribution of the\nsupremum of the studentized empirical process does not exist (or is unknown).\nThis is of particular importance in problems where resolution levels or other\ntuning parameters have been chosen in a data-driven fashion, which is needed\nfor adaptive constructions of the confidence bands. Finally, of independent\ninterest is our introduction of a new, practical version of Lepski's method,\nwhich computes the optimal, nonconservative resolution levels via a Gaussian\nmultiplier bootstrap method.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:39:44 GMT"},{"version":"v2","created":"Fri, 29 Mar 2013 23:07:46 GMT"},{"version":"v3","created":"Wed, 4 Dec 2013 19:28:36 GMT"},{"version":"v4","created":"Tue, 23 Sep 2014 12:56:01 GMT"}],"update_date":"2014-09-24"}
{"id":"1303.7153","submitter":"Lingfeng Zhang","authors":"L.-F. Zhang, L. Covaci, M. V. Milo\\v{s}evi\\'c, G.R. Berdiyorov, F.M.\n  Peeters","title":"Vortex states in nanoscale superconducting squares: the influence of\n  quantum confinement","comments":null,"journal-ref":"Phys. Rev. B 88, 144501 (2013)","doi":"10.1103/PhysRevB.88.144501","report-no":null,"categories":"cond-mat.supr-con","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bogoliubov-de Gennes theory is used to investigate the effect of the size of\na superconducting square on the vortex states in the quantum confinement\nregime. When the superconducting coherence length is comparable to the Fermi\nwavelength, the shape resonances of the superconducting order parameter have\nstrong influence on the vortex configuration. Several unconventional vortex\nstates, including asymmetric ones, giant multi-vortex combinations, and states\ncomprising giant antivortex, were found as ground states and their stability\nwas found to be very sensitive on the value of $k_F\\xi_0$, the size of the\nsample $W$, and the magnetic flux $\\Phi$. By increasing the temperature and/or\nenlarging the size of the sample, quantum confinement is suppressed and the\nconventional mesoscopic vortex states as predicted by the Ginzburg-Laudau (GL)\ntheory are recovered. However, contrary to the GL results we found that the\nstates containing symmetry-induced vortex-antivortex pairs are stable over the\nwhole temperature range. It turns out that the inhomogeneous order parameter\ninduced by quantum confinement favors vortex-antivortex molecules, as well as\ngiant vortices with a rich structure in the vortex core - unattainable in the\nGL domain.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:43:43 GMT"},{"version":"v2","created":"Fri, 29 Mar 2013 15:40:00 GMT"},{"version":"v3","created":"Wed, 2 Oct 2013 15:41:23 GMT"}],"update_date":"2014-01-20"}
{"id":"1303.7154","submitter":"Antonio Di Lorenzo","authors":"Antonio Di Lorenzo","title":"Quantum state tomography from sequential measurement of two variables in\n  a single setup","comments":"16 pages, 2 figures, revtex4-1. Comments welcome. v2: sacrificed\n  generality to clarity; v3: minor changes, references added","journal-ref":"Phys. Rev. A 88, 042114 (2013)","doi":"10.1103/PhysRevA.88.042114","report-no":null,"categories":"quant-ph cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We demonstrate that the task of determining an unknown quantum state can be\naccomplished efficiently by making a sequential measurement of two observables\n$\\hat{A}$ and $\\hat{B}$, provided that the two observables are chosen in such a\nway that their eigenstates may form bases connected by a discrete Fourier\ntransform. The state can be pure or mixed, the dimension of the Hilbert space\nand the coupling strength are arbitrary, and the experimental setup is fixed.\nThe concept of Moyal quasicharacteristic function is introduced for\nfinite-dimensional Hilbert spaces.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:50:06 GMT"},{"version":"v2","created":"Mon, 24 Jun 2013 12:32:15 GMT"},{"version":"v3","created":"Sat, 19 Oct 2013 11:18:51 GMT"}],"update_date":"2013-10-22"}
{"id":"1303.7155","submitter":"Kate Jones","authors":"Kate L. Jones","title":"Transfer reaction experiments with radioactive beams: from halos to the\n  r-process","comments":"From the proceedings of Nobel Symposium 152: Physics with Radioactive\n  Beams, Goteborg, Sweden, Spring 2012","journal-ref":"Phys. Scr. T152 (2013) 014020","doi":"10.1088/0031-8949/2013/T152/014020","report-no":null,"categories":"nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transfer reactions are a powerful probe of the properties of atomic nuclei.\nWhen used in inverse kinematics with radioactive ion beams they can provide\ndetailed information on the structure of exotic nuclei and can inform\nnucleosynthesis calculations. There are a number of groups around the world who\nuse these reactions, usually with particle detection in large silicon arrays.\nSometimes these arrays are coupled to gamma-ray detectors, and occasionally\nsmaller arrays of silicon detectors are mounted within a solenoid magnet.\nModern techniques using transfer reactions in inverse kinematics are covered,\nwith specific examples, many from measurements made with beams from the\nHolifield Radioactive Ion Beam Facility at Oak Ridge National Laboratory.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:55:02 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7156","submitter":"Angelo Felice Lopez","authors":"Salvatore Cacciola and Angelo Felice Lopez","title":"Nakamaye's theorem on log canonical pairs","comments":"v2: We removed, in the introduction, the phrase about Choi's papers,\n  as he uses Nakamaye's theorem in the semiample case. Updated references. v3:\n  added reference to Ambro's \"Quasi-log varieties\". v4: improved exposition in\n  sections 1, 2 and 4; slightly corrected the statement of Lemma 3.1","journal-ref":"Ann. Inst. Fourier 64 (2014), n. 6, 2283-2298","doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We generalize Nakamaye's description, via intersection theory, of the\naugmented base locus of a big and nef divisor on a normal pair with\nlog-canonical singularities or, more generally, on a normal variety with non-lc\nlocus of dimension at most 1. We also generalize\nEin-Lazarsfeld-Mustata-Nakamaye-Popa's description, in terms of valuations, of\nthe subvarieties of the restricted base locus of a big divisor on a normal pair\nwith klt singularities.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:55:16 GMT"},{"version":"v2","created":"Fri, 19 Apr 2013 18:39:10 GMT"},{"version":"v3","created":"Tue, 23 Apr 2013 18:29:21 GMT"},{"version":"v4","created":"Sun, 23 Mar 2014 19:46:35 GMT"}],"update_date":"2014-12-24"}
{"id":"1303.7157","submitter":"Changqing Jin","authors":"K. Zhao, Z. Deng, X. C. Wang, W. Han, J. L. Zhu, X. Li, Q.Q. Liu, R.C.\n  Yu, T. Goko, B. Frandsen, Lian Liu, Fanlong Ning, Y.J. Uemura, H. Dabkowska,\n  G.M. Luke, H. Luetkens, E. Morenzoni, S.R. Dunsiger, A. Senyshyn, P. B\\\"oni,\n  C.Q. Jin","title":"New Diluted Ferromagnetic Semiconductor isostructural to 122 type iron\n  pnictide superconductor with TC up to 180 K","comments":"12 pages, 3 Figures, 3 tables","journal-ref":"Nature Communications 4:1442 | DOI: 10.1038(2013)","doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.str-el quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diluted magnetic semiconductors (DMS) have received much attention due to its\npotential applications to spintronics devices. A prototypical system (Ga,Mn)As\nhas been widely studied since 1990s. The simultaneous spin and charge doping\nvia hetero-valence (Ga3+,Mn2+) substitution, however, resulted in severely\nlimited solubility without availability of bulk specimens. Previously we\nsynthesized a new diluted ferromagnetic semiconductor of bulk Li(Zn,Mn)As with\nTc up to 50K, where isovalent (Zn,Mn) spin doping was separated from charge\ncontrol via Li concentrations. Here we report the synthesis of a new diluted\nferromagnetic semiconductor (Ba1-xKx)(Zn1-yMny)2As2, isostructural to iron 122\nsystem, where holes are doped via (Ba2+, K1+), while spins via (Zn2+,Mn2+)\nsubstitutions. Bulk samples with x=0.1-0.3 and y=0.05-0.15 exhibit\nferromagnetic order with TC up to 180K, comparable to that of record high Tc\nfor Ga(MnAs), significantly enhanced than Li(Zn,Mn)As. Moreover the\n(Ba,K)(Zn,Mn)2As2 shares the same 122 crystal structure with semiconducting\nBaZn2As2, antiferromagnetic BaMn2As2, and superconducting (Ba,K)Fe2As2, which\nmakes them promising to the development of multilayer functional devices.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 15:55:29 GMT"}],"update_date":"2013-03-29"}
{"id":"1303.7227","submitter":"Monica Patriche","authors":"Monica Patriche","title":"New results on equilibria of fuzzy abstract economies","comments":"13 pages. arXiv admin note: substantial text overlap with\n  arXiv:1303.6979","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We obtain new equilibrium theorems for fuzzy abstract economies with\ncorrespondences being w-upper semicontinuous or having e-USS-property.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 21:10:48 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7228","submitter":"Peter Mitchell","authors":"P. D. Mitchell, C. G. Lacey, C. M. Baugh, S. Cole","title":"How well can we really estimate the stellar masses of galaxies from\n  broadband photometry?","comments":"29 pages, 16 Figures, changed to match published MNRAS version","journal-ref":null,"doi":"10.1093/mnras/stt1280","report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The estimated stellar masses of galaxies are widely used to characterize how\nthe galaxy population evolves over cosmic time. If stellar masses can be\nestimated in a robust manner, free from any bias, global diagnostics such as\nthe stellar mass function can be used to constrain the physics of galaxy\nformation. We explore how galaxy stellar masses, estimated by fitting\nbroad-band spectral energy distributions (SEDs) with stellar population models,\ncan be biased as a result of commonly adopted assumptions for the\nstar-formation and chemical enrichment histories, recycled fractions and dust\nattenuation curves of galaxies. We apply the observational technique of\nbroad-band SED fitting to model galaxy SEDs calculated by the theoretical\ngalaxy formation model GALFORM, isolating the effect of each of these\nassumptions. We find that, averaged over the entire galaxy population, the\ncommon assumption of exponentially declining star-formation histories does not\nadversely affect stellar mass estimation. We show that fixing the metallicity\nin SED fitting or using sparsely sampled metallicity grids can introduce mass\ndependent systematics into stellar mass estimates. We find that the common\nassumption of a star-dust geometry corresponding to a uniform foreground dust\nscreen can cause the stellar masses of dusty model galaxies to be significantly\nunderestimated. Finally, we show that stellar mass functions recovered by\napplying SED fitting to model galaxies at high redshift can differ\nsignificantly in both shape and normalization from the intrinsic mass functions\npredicted by a given model. Given these differences, our methodology of using\nstellar masses estimated from model galaxy SEDs offers a new, self-consistent\nway to compare model predictions with observations.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 22:30:07 GMT"},{"version":"v2","created":"Wed, 4 Sep 2013 17:29:22 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7229","submitter":"Qi-Ren Zhang","authors":"Qi-Ren Zhang","title":"Quantum electrodynamics in a laser and the electron laser collision","comments":"15 pages, 2 figures","journal-ref":"Chin. Phys. B Vol. 23, No. 1 (2014) 010306","doi":"10.1088/1674-1056/23/1/010306","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantum electrodynamics in a laser is formulated, in which the electron-laser\ninteraction is exactly considered, while the interaction of an electron and a\nsingle photon is considered by perturbation. The formulation is applied to the\nelectron-laser collisions. The effect of coherence between photons in the laser\nis therefore fully considered in these collisions. The possibility of\n$\\gamma-$ray laser generation by use of this kind of collision is discussed.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:40:07 GMT"},{"version":"v2","created":"Tue, 16 Jul 2013 08:54:28 GMT"},{"version":"v3","created":"Tue, 26 Nov 2013 08:47:50 GMT"},{"version":"v4","created":"Tue, 7 Jan 2014 02:31:37 GMT"},{"version":"v5","created":"Fri, 8 Aug 2014 09:02:10 GMT"}],"update_date":"2014-08-11"}
{"id":"1303.7230","submitter":"Oleg A. Vasilyev","authors":"Oleg A. Vasilyev, Boris A. Klumov, Alexei V. Tkachenko","title":"Precursors of order in aggregates of patchy particles","comments":"12 pages, 3 figures","journal-ref":null,"doi":"10.1103/PhysRevE.88.012302","report-no":null,"categories":"cond-mat.soft","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study computationally the local structure of aggregated systems of patchy\nparticles. By calculating the probability distribution functions of various\nrotational invariants we can identify the precursors of orientation order in\namorphous phase. Surprisingly, the strongest signature of local order is\nobserved for 4-patch particles with tetrahedral symmetry, not for 6-patch\nparticles with the cubic one. This trend is exactly opposite to their known\nability to crystallize. We relate this anomaly to the observation that a\ngeneric aggregate of patchy systems has coordination number close to 4. Our\nresults also suggest a significant correlation between rotational order in the\nstudied liquids with the corresponding crystalline phases, making this approach\npotentially useful for a broader range of patchy systems.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:28:14 GMT"}],"update_date":"2015-06-15"}
{"id":"1303.7400","submitter":"Bent Flyvbjerg","authors":"Bent Flyvbjerg","title":"Policy and Planning for Large Infrastructure Projects: Problems, Causes,\n  Cures","comments":"arXiv admin note: substantial text overlap with arXiv:1303.6571,\n  arXiv:1303.6654, arXiv:1303.6571, arXiv:1302.3642","journal-ref":null,"doi":null,"report-no":"Policy Research Working Paper, WPS 3781, World Bank, Washington, DC,\n  2005, 32 pp","categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper argues, first, that a major problem in the planning of large\ninfrastructure projects is the high level of misinformation about costs and\nbenefits that decision makers face in deciding whether to build, and the high\nrisks such misinformation generates. Second, it explores the causes of\nmisinformation and risk, mainly in the guise of optimism bias and strategic\nmisrepresentation. Finally, the paper presents a number of measures aimed at\nimproving planning and decision making for large infrastructure projects,\nincluding changed incentive structures and better planning methods. Thus the\npaper is organized as a simple triptych consisting in problems, causes, and\ncures.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:04:30 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7401","submitter":"Bent Flyvbjerg","authors":"Bent Flyvbjerg","title":"Measuring Inaccuracy in Travel Demand Forecasting: Methodological\n  Considerations Regarding Ramp Up and Sampling","comments":null,"journal-ref":"Transportation Research A, vol. 39, no. 6, July 2005, 522-530","doi":"10.1016/j.tra.2005.02.003","report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Project promoters, forecasters, and managers sometimes object to two things\nin measuring inaccuracy in travel demand forecasting: (1) using the forecast\nmade at the time of making the decision to build as the basis for measuring\ninaccuracy and (2) using traffic during the first year of operations as the\nbasis for measurement. This paper presents the case against both objections.\nFirst, if one is interested in learning whether decisions about building\ntransport infrastructure are based on reliable information, then it is exactly\nthe traffic forecasted at the time of making the decision to build that is of\ninterest. Second, although ideally studies should take into account so-called\ndemand \"ramp up\" over a period of years, the empirical evidence and practical\nconsiderations do not support this ideal requirement, at least not for large-N\nstudies. Finally, the paper argues that large samples of inaccuracy in travel\ndemand forecasts are likely to be conservatively biased, i.e., accuracy in\ntravel demand forecasts estimated from such samples would likely be higher than\naccuracy in travel demand forecasts in the project population. This bias must\nbe taken into account when interpreting the results from statistical analyses\nof inaccuracy in travel demand forecasting.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:41:50 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7402","submitter":"Bent Flyvbjerg","authors":"Bent Flyvbjerg","title":"Cost Overruns and Demand Shortfalls in Urban Rail and Other\n  Infrastructure","comments":null,"journal-ref":"Transportation Planning and Technology, vol. 30, no. 1, February\n  2007, 9-30","doi":"10.1080/03081060701207938","report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Risk, including economic risk, is increasingly a concern for public policy\nand management. The possibility of dealing effectively with risk is hampered,\nhowever, by lack of a sound empirical basis for risk assessment and management.\nThe paper demonstrates the general point for cost and demand risks in urban\nrail projects. The paper presents empirical evidence that allow valid economic\nrisk assessment and management of urban rail projects, including benchmarking\nof individual or groups of projects. Benchmarking of the Copenhagen Metro is\npresented as a case in point. The approach developed is proposed as a model for\nother types of policies and projects in order to improve economic and financial\nrisk assessment and management in policy and planning.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 12:14:47 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7403","submitter":"Bent Flyvbjerg","authors":"Bent Flyvbjerg, Massimo Garbuio, and Dan Lovallo","title":"Delusion and Deception in Large Infrastructure Projects: Two Models for\n  Explaining and Preventing Executive Disaster","comments":null,"journal-ref":"California Management Review, vol. 51, no. 2, Winter 2009, 170-193","doi":"10.1225/CMR423","report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Economist recently reported that infrastructure spending is the largest\nit is ever been as a share of world GDP. With $22 trillion in projected\ninvestments over the next ten years in emerging economies alone, the magazine\ncalls it the \"biggest investment boom in history.\" The efficiency of\ninfrastructure planning and execution is therefore particularly important at\npresent. Unfortunately, the private sector, the public sector and\nprivate/public sector partnerships have a dismal record of delivering on large\ninfrastructure cost and performance promises. This paper explains why and how\nto solve the problem.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:51:20 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7404","submitter":"Bent Flyvbjerg","authors":"Bent Flyvbjerg, Nils Bruzelius, and Werner Rothengatter","title":"Megaprojects and Risk: An Anatomy of Ambition","comments":"Cambridge University Press, 2003","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Back cover text: Megaprojects and Risk provides the first detailed\nexamination of the phenomenon of megaprojects. It is a fascinating account of\nhow the promoters of multibillion-dollar megaprojects systematically and\nself-servingly misinform parliaments, the public and the media in order to get\nprojects approved and built. It shows, in unusual depth, how the formula for\napproval is an unhealthy cocktail of underestimated costs, overestimated\nrevenues, undervalued environmental impacts and overvalued economic development\neffects. This results in projects that are extremely risky, but where the risk\nis concealed from MPs, taxpayers and investors. The authors not only explore\nthe problems but also suggest practical solutions drawing on theory and hard,\nscientific evidence from the several hundred projects in twenty nations that\nillustrate the book. Accessibly written, it will be essential reading in its\nfield for students, scholars, planners, economists, auditors, politicians,\njournalists and interested citizens.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 10:29:04 GMT"}],"update_date":"2013-04-01"}
{"id":"1303.7405","submitter":"Bent Flyvbjerg","authors":"Bent Flyvbjerg","title":"How Planners Deal with Uncomfortable Knowledge: The Dubious Ethics of\n  the American Planning Association","comments":"Flyvbjerg, Bent, 2013, \"How Planners Deal with Uncomfortable\n  Knowledge: The Dubious Ethics of the American Planning Association,\" Cities","journal-ref":null,"doi":"10.1016/J.CITIES.2012.10.016","report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With a point of departure in the concept \"uncomfortable knowledge,\" this\narticle presents a case study of how the American Planning Association (APA)\ndeals with such knowledge. APA was found to actively suppress publicity of\nmalpractice concerns and bad planning in order to sustain a boosterish image of\nplanning. In the process, APA appeared to disregard and violate APA's own Code\nof Ethics. APA justified its actions with a need to protect APA members'\ninterests, seen as preventing planning and planners from being presented in\npublic in a bad light. The current article argues that it is in members'\ninterest to have malpractice critiqued and reduced, and that this best happens\nby exposing malpractice, not by denying or diverting attention from it as APA\ndid in this case. Professions, organizations, and societies that stifle\ncritique tend to degenerate and become socially and politically irrelevant\n\"zombie institutions.\" The article asks whether such degeneration has set in\nfor APA and planning. Finally, it is concluded that more debate about APA's\nethics and actions is needed for improving planning practice. Nine key\nquestions are presented to constructively stimulate such debate.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:04:53 GMT"}],"update_date":"2013-04-01"}
{"id":"1304.0265","submitter":"Alexander Budzier","authors":"Bent Flyvbjerg and Alexander Budzier","title":"Why Your IT Project Might Be Riskier Than You Think","comments":null,"journal-ref":"Harvard Business Review, Vol. 89 (2011), No. 9, pp. 23-25","doi":null,"report-no":null,"categories":"q-fin.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Out-of-control information technology (IT) projects have ended the careers of\ntop managers, such as EADS CEO Noel Forgeard and Levi Strauss' CIO David\nBergen. Moreover, IT projects have brought down whole companies, like Kmart in\nthe US and Auto Windscreen in the UK. Software and other IT is now such an\nintegral part of most business processes and products that CEOs must know their\nIT risks, which are typically substantial and overlooked. The analysis of a\nsample of 1,471 IT projects showed that the average cost overrun was 27% - but\nthat figure masks a far more alarming 'fat tail' risk. Fully one in six of the\nprojects in the sample was a Black Swan, with a cost overrun of 200%, on\naverage, and a schedule overrun of almost 70%. This highlights the true pitfall\nof IT change initiatives: It's not that they're particularly prone to high cost\noverruns on average - it is that there are a disproportionate number of Black\nSwans. By focusing on averages instead of the more damaging outliers, most\nmanagers and consultants have been missing the real risk in doing IT. In\nconclusion, the article outlines ideas as to what can be done to avoid Black\nSwans.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 13:59:48 GMT"},{"version":"v2","created":"Tue, 16 Apr 2013 17:19:27 GMT"}],"update_date":"2013-04-17"}
{"id":"1304.1491","submitter":"Fahiem Bacchus","authors":"Fahiem Bacchus","title":"Lp : A Logic for Statistical Information","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-1-6","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This extended abstract presents a logic, called Lp, that is capable of\nrepresenting and reasoning with a wide variety of both qualitative and\nquantitative statistical information. The advantage of this logical formalism\nis that it offers a declarative representation of statistical knowledge;\nknowledge represented in this manner can be used for a variety of reasoning\ntasks. The logic differs from previous work in probability logics in that it\nuses a probability distribution over the domain of discourse, whereas most\nprevious work (e.g., Nilsson [2], Scott et al. [3], Gaifinan [4], Fagin et al.\n[5]) has investigated the attachment of probabilities to the sentences of the\nlogic (also, see Halpern [6] and Bacchus [7] for further discussion of the\ndifferences). The logic Lp possesses some further important features. First, Lp\nis a superset of first order logic, hence it can represent ordinary logical\nassertions. This means that Lp provides a mechanism for integrating statistical\ninformation and reasoning about uncertainty into systems based solely on logic.\nSecond, Lp possesses transparent semantics, based on sets and probabilities of\nthose sets. Hence, knowledge represented in Lp can be understood in terms of\nthe simple primative concepts of sets and probabilities. And finally, the there\nis a sound proof theory that has wide coverage (the proof theory is complete\nfor certain classes of models). The proof theory captures a sufficient range of\nvalid inferences to subsume most previous probabilistic uncertainty reasoning\nsystems. For example, the linear constraints like those generated by Nilsson's\nprobabilistic entailment [2] can be generated by the proof theory, and the\nBayesian inference underlying belief nets [8] can be performed. In addition,\nthe proof theory integrates quantitative and qualitative reasoning as well as\nstatistical and logical reasoning. In the next section we briefly examine\nprevious work in probability logics, comparing it to Lp. Then we present some\nof the varieties of statistical information that Lp is capable of expressing.\nAfter this we present, briefly, the syntax, semantics, and proof theory of the\nlogic. We conclude with a few examples of knowledge representation and\nreasoning in Lp, pointing out the advantages of the declarative representation\noffered by Lp. We close with a brief discussion of probabilities as degrees of\nbelief, indicating how such probabilities can be generated from statistical\nknowledge encoded in Lp. The reader who is interested in a more complete\ntreatment should consult Bacchus [7].\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:36:47 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1492","submitter":"Kenneth Basye","authors":"Kenneth Basye, Thomas L. Dean","title":"Map Learning with Indistinguishable Locations","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-7-13","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nearly all spatial reasoning problems involve uncertainty of one sort or\nanother. Uncertainty arises due to the inaccuracies of sensors used in\nmeasuring distances and angles. We refer to this as directional uncertainty.\nUncertainty also arises in combining spatial information when one location is\nmistakenly identified with another. We refer to this as recognition\nuncertainty. Most problems in constructing spatial representations (maps) for\nthe purpose of navigation involve both directional and recognition uncertainty.\nIn this paper, we show that a particular class of spatial reasoning problems\ninvolving the construction of representations of large-scale space can be\nsolved efficiently even in the presence of directional and recognition\nuncertainty. We pay particular attention to the problems that arise due to\nrecognition uncertainty.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:36:53 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1493","submitter":"Carlo Berzuini","authors":"Carlo Berzuini, Riccardo Bellazzi, Silvana Quaglini","title":"Temporal Reasoning with Probabilities","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-14-21","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we explore representations of temporal knowledge based upon the\nformalism of Causal Probabilistic Networks (CPNs). Two different\n?continuous-time? representations are proposed. In the first, the CPN includes\nvariables representing ?event-occurrence times?, possibly on different time\nscales, and variables representing the ?state? of the system at these times. In\nthe second, the CPN describes the influences between random variables with\nvalues in () representing dates, i.e. time-points associated with the\noccurrence of relevant events. However, structuring a system of inter-related\ndates as a network where all links commit to a single specific notion of cause\nand effect is in general far from trivial and leads to severe difficulties. We\nclaim that we should recognize explicitly different kinds of relation between\ndates, such as ?cause?, ?inhibition?, ?competition?, etc., and propose a method\nwhereby these relations are coherently embedded in a CPN using additional\nauxiliary nodes corresponding to \"instrumental\" variables. Also discussed,\nthough not covered in detail, is the topic concerning how the quantitative\nspecifications to be inserted in a temporal CPN can be learned from specific\ndata.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:36:59 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1494","submitter":"Piero P. Bonissone","authors":"Piero P. Bonissone","title":"Now that I Have a Good Theory of Uncertainty, What Else Do I Need?","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-22-33","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rather than discussing the isolated merits of a nominative theory of\nuncertainty, this paper focuses on a class of problems, referred to as Dynamic\nClassification Problem (DCP), which requires the integration of many theories,\nincluding a prescriptive theory of uncertainty. We start by analyzing the\nDynamic Classification Problem and by defining its induced requirements on a\nsupporting (plausible) reasoning system. We provide a summary of the underlying\ntheory (based on the semantics of many-valed logics) and illustrate the\nconstraints imposed upon it to ensure the modularity and computational\nperformance required by the applications. We describe the technologies used for\nknowledge engineering (such as object-based simulator to exercise requirements,\nand development tools to build the Knowledge Base and functionally validate\nit). We emphasize the difference between development environment and run-time\nsystem, describe the rule cross-compiler, and the real-time inference engine\nwith meta-reasoning capabilities. Finally, we illustrate how our proposed\ntechnology satisfies the pop's requirements and analyze some of the lessons\nreamed from its applications to situation assessment problems for Pilot's\nAssociate and Submarine Commander Associate.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:05 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1495","submitter":"Piero P. Bonissone","authors":"Piero P. Bonissone, David A. Cyrluk, James W. Goodwin, Jonathan\n  Stillman","title":"Uncertainty and Incompleteness","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-34-45","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Two major difficulties in using default logics are their intractability and\nthe problem of selecting among multiple extensions. We propose an approach to\nthese problems based on integrating nommonotonic reasoning with plausible\nreasoning based on triangular norms. A previously proposed system for reasoning\nwith uncertainty (RUM) performs uncertain monotonic inferences on an acyclic\ngraph. We have extended RUM to allow nommonotonic inferences and cycles within\nnonmonotonic rules. By restricting the size and complexity of the nommonotonic\ncycles we can still perform efficient inferences. Uncertainty measures provide\na basis for deciding among multiple defaults. Different algorithms and\nheuristics for finding the optimal defaults are discussed.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:11 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1496","submitter":"Lashon B. Booker","authors":"Lashon B. Booker, Naveen Hota, Connie Loggia Ramsey","title":"BaRT: A Bayesian Reasoning Tool for Knowledge Based Systems","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-46-53","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As the technology for building knowledge based systems has matured, important\nlessons have been learned about the relationship between the architecture of a\nsystem and the nature of the problems it is intended to solve. We are\nimplementing a knowledge engineering tool called BART that is designed with\nthese lessons in mind. BART is a Bayesian reasoning tool that makes belief\nnetworks and other probabilistic techniques available to knowledge engineers\nbuilding classificatory problem solvers. BART has already been used to develop\na decision aid for classifying ship images, and it is currently being used to\nmanage uncertainty in systems concerned with analyzing intelligence reports.\nThis paper discusses how state-of-the-art probabilistic methods fit naturally\ninto a knowledge based approach to classificatory problem solving, and\ndescribes the current capabilities of BART.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:17 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1497","submitter":"Eugene Charniak","authors":"Eugene Charniak, Robert P. Goldman","title":"Plan Recognition in Stories and in Life","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-54-59","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Plan recognition does not work the same way in stories and in \"real life\"\n(people tend to jump to conclusions more in stories). We present a theory of\nthis, for the particular case of how objects in stories (or in life) influence\nplan recognition decisions. We provide a Bayesian network formalization of a\nsimple first-order theory of plans, and show how a particular network parameter\nseems to govern the difference between \"life-like\" and \"story-like\" response.\nWe then show why this parameter would be influenced (in the desired way) by a\nmodel of speaker (or author) topic selection which assumes that facts in\nstories are typically \"relevant\".\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:23 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1498","submitter":"R. Martin Chavez","authors":"R. Martin Chavez, Gregory F. Cooper","title":"An Empirical Evaluation of a Randomized Algorithm for Probabilistic\n  Inference","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-60-70","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In recent years, researchers in decision analysis and artificial intelligence\n(Al) have used Bayesian belief networks to build models of expert opinion.\nUsing standard methods drawn from the theory of computational complexity,\nworkers in the field have shown that the problem of probabilistic inference in\nbelief networks is difficult and almost certainly intractable. K N ET, a\nsoftware environment for constructing knowledge-based systems within the\naxiomatic framework of decision theory, contains a randomized approximation\nscheme for probabilistic inference. The algorithm can, in many circumstances,\nperform efficient approximate inference in large and richly interconnected\nmodels of medical diagnosis. Unlike previously described stochastic algorithms\nfor probabilistic inference, the randomized approximation scheme computes a\npriori bounds on running time by analyzing the structure and contents of the\nbelief network. In this article, we describe a randomized algorithm for\nprobabilistic inference and analyze its performance mathematically. Then, we\ndevote the major portion of the paper to a discussion of the algorithm's\nempirical behavior. The results indicate that the generation of good trials\n(that is, trials whose distribution closely matches the true distribution),\nrather than the computation of numerous mediocre trials, dominates the\nperformance of stochastic simulation. Key words: probabilistic inference,\nbelief networks, stochastic simulation, computational complexity theory,\nrandomized algorithms.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:29 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1499","submitter":"Marvin S. Cohen","authors":"Marvin S. Cohen","title":"Decision Making \"Biases\" and Support for Assumption-Based Higher-Order\n  Reasoning","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-71-80","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Unaided human decision making appears to systematically violate consistency\nconstraints imposed by normative theories; these biases in turn appear to\njustify the application of formal decision-analytic models. It is argued that\nboth claims are wrong. In particular, we will argue that the \"confirmation\nbias\" is premised on an overly narrow view of how conflicting evidence is and\nought to be handled. Effective decision aiding should focus on supporting the\ncontral processes by means of which knowledge is extended into novel situations\nand in which assumptions are adopted, utilized, and revised. The Non- Monotonic\nProbabilist represents initial work toward such an aid.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:35 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1500","submitter":"Didier Dubois","authors":"Didier Dubois, Jerome Lang, Henri Prade","title":"Automated Reasoning Using Possibilistic Logic: Semantics, Belief\n  Revision and Variable Certainty Weights","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-81-87","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper an approach to automated deduction under uncertainty,based on\npossibilistic logic, is proposed ; for that purpose we deal with clauses\nweighted by a degree which is a lower bound of a necessity or a possibility\nmeasure, according to the nature of the uncertainty. Two resolution rules are\nused for coping with the different situations, and the refutation method can be\ngeneralized. Besides the lower bounds are allowed to be functions of variables\ninvolved in the clause, which gives hypothetical reasoning capabilities. The\nrelation between our approach and the idea of minimizing abnormality is briefly\ndiscussed. In case where only lower bounds of necessity measures are involved,\na semantics is proposed, in which the completeness of the extended resolution\nprinciple is proved. Moreover deduction from a partially inconsistent knowledge\nbase can be managed in this approach and displays some form of\nnon-monotonicity.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:41 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1501","submitter":"Christopher Elsaesser","authors":"Christopher Elsaesser, Max Henrion","title":"How Much More Probable is \"Much More Probable\"? Verbal Expressions for\n  Probability Updates","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-88-94","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bayesian inference systems should be able to explain their reasoning to\nusers, translating from numerical to natural language. Previous empirical work\nhas investigated the correspondence between absolute probabilities and\nlinguistic phrases. This study extends that work to the correspondence between\nchanges in probabilities (updates) and relative probability phrases, such as\n\"much more likely\" or \"a little less likely.\" Subjects selected such phrases to\nbest describe numerical probability updates. We examined three hypotheses about\nthe correspondence, and found the most descriptively accurate of these three to\nbe that each such phrase corresponds to a fixed difference in probability\n(rather than fixed ratio of probabilities or of odds). The empirically derived\nphrase selection function uses eight phrases and achieved a 72% accuracy in\ncorrespondence with the subjects' actual usage.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:47 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1502","submitter":"Henri Farrency","authors":"Henri Farrency, Henri Prade","title":"Positive and Negative Explanations of Uncertain Reasoning in the\n  Framework of Possibility Theory","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-95-101","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents an approach for developing the explanation capabilities\nof rule-based expert systems managing imprecise and uncertain knowledge. The\ntreatment of uncertainty takes place in the framework of possibility theory\nwhere the available information concerning the value of a logical or numerical\nvariable is represented by a possibility distribution which restricts its more\nor less possible values. We first discuss different kinds of queries asking for\nexplanations before focusing on the two following types : i) how, a particular\npossibility distribution is obtained (emphasizing the main reasons only) ; ii)\nwhy in a computed possibility distribution, a particular value has received a\npossibility degree which is so high, so low or so contrary to the expectation.\nThe approach is based on the exploitation of equations in max-min algebra. This\nformalism includes the limit case of certain and precise information.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:53 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1503","submitter":"Kenneth W. Fertig","authors":"Kenneth W. Fertig, John S. Breese","title":"Interval Influence Diagrams","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-102-111","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe a mechanism for performing probabilistic reasoning in influence\ndiagrams using interval rather than point valued probabilities. We derive the\nprocedures for node removal (corresponding to conditional expectation) and arc\nreversal (corresponding to Bayesian conditioning) in influence diagrams where\nlower bounds on probabilities are stored at each node. The resulting bounds for\nthe transformed diagram are shown to be optimal within the class of constraints\non probability distributions that can be expressed exclusively as lower bounds\non the component probabilities of the diagram. Sequences of these operations\ncan be performed to answer probabilistic queries with indeterminacies in the\ninput and for performing sensitivity analysis on an influence diagram. The\nstorage requirements and computational complexity of this approach are\ncomparable to those for point-valued probabilistic inference mechanisms, making\nthe approach attractive for performing sensitivity analysis and where\nprobability information is not available. Limited empirical data on an\nimplementation of the methodology are provided.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:37:59 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1504","submitter":"Robert Fung","authors":"Robert Fung, Kuo-Chu Chang","title":"Weighing and Integrating Evidence for Stochastic Simulation in Bayesian\n  Networks","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-112-117","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stochastic simulation approaches perform probabilistic inference in Bayesian\nnetworks by estimating the probability of an event based on the frequency that\nthe event occurs in a set of simulation trials. This paper describes the\nevidence weighting mechanism, for augmenting the logic sampling stochastic\nsimulation algorithm [Henrion, 1986]. Evidence weighting modifies the logic\nsampling algorithm by weighting each simulation trial by the likelihood of a\nnetwork's evidence given the sampled state node values for that trial. We also\ndescribe an enhancement to the basic algorithm which uses the evidential\nintegration technique [Chin and Cooper, 1987]. A comparison of the basic\nevidence weighting mechanism with the Markov blanket algorithm [Pearl, 1987],\nthe logic sampling algorithm, and the evidence integration algorithm is\npresented. The comparison is aided by analyzing the performance of the\nalgorithms in a simple example network.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:05 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1505","submitter":"Dan Geiger","authors":"Dan Geiger, Tom S. Verma, Judea Pearl","title":"d-Separation: From Theorems to Algorithms","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-118-125","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An efficient algorithm is developed that identifies all independencies\nimplied by the topology of a Bayesian network. Its correctness and maximality\nstems from the soundness and completeness of d-separation with respect to\nprobability theory. The algorithm runs in time O (l E l) where E is the number\nof edges in the network.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:11 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1506","submitter":"Maria Angeles Gil","authors":"Maria Angeles Gil, Pramod Jain","title":"The Effects of Perfect and Sample Information on Fuzzy Utilities in\n  Decision-Making","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-126-133","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we first consider a Bayesian framework and model the \"utility\nfunction\" in terms of fuzzy random variables. On the basis of this model, we\ndefine the \"prior (fuzzy) expected utility\" associated with each action, and\nthe corresponding \"posterior (fuzzy) expected utility given sample information\nfrom a random experiment\". The aim of this paper is to analyze how sample\ninformation can affect the expected utility. In this way, by using some fuzzy\npreference relations, we conclude that sample information allows a decision\nmaker to increase the expected utility on the average. The upper bound on the\nvalue of the expected utility is when the decision maker has perfect\ninformation. Applications of this work to the field of artificial intelligence\nare presented through two examples.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:16 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1507","submitter":"Moises Goldszmidt","authors":"Moises Goldszmidt, Judea Pearl","title":"Deciding Consistency of Databases Containing Defeasible and Strict\n  Information","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-134-141","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a norm of consistency for a mixed set of defeasible and strict\nsentences, based on a probabilistic semantics. This norm establishes a clear\ndistinction between knowledge bases depicting exceptions and those containing\noutright contradictions. We then define a notion of entailment based also on\nprobabilistic considerations and provide a characterization of the relation\nbetween consistency and entailment. We derive necessary and sufficient\nconditions for consistency, and provide a simple decision procedure for testing\nconsistency and deciding whether a sentence is entailed by a database. Finally,\nit is shown that if al1 sentences are Horn clauses, consistency and entailment\ncan be tested in polynomial time.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:23 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1508","submitter":"Joseph Y. Halpern","authors":"Joseph Y. Halpern","title":"The Relationship between Knowledge, Belief and Certainty","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-142-151","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the relation between knowledge and certainty, where a fact is\nknown if it is true at all worlds an agent considers possible and is certain if\nit holds with probability 1. We identify certainty with probabilistic belief.\nWe show that if we assume one fixed probability assignment, then the logic\nKD45, which has been identified as perhaps the most appropriate for belief,\nprovides a complete axiomatization for reasoning about certainty. Just as an\nagent may believe a fact although phi is false, he may be certain that a fact\nphi, is true although phi is false. However, it is easy to see that an agent\ncan have such false (probabilistic) beliefs only at a set of worlds of\nprobability 0. If we restrict attention to structures where all worlds have\npositive probability, then S5 provides a complete axiomatization. If we\nconsider a more general setting, where there might be a different probability\nassignment at each world, then by placing appropriate conditions on the support\nof the probability function (the set of worlds which have non-zero\nprobability), we can capture many other well-known modal logics, such as T and\nS4. Finally, we consider which axioms characterize structures satisfying\nMiller's principle.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:29 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1509","submitter":"Othar Hansson","authors":"Othar Hansson, Andy Mayer","title":"Heuristic Search as Evidential Reasoning","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-152-161","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  BPS, the Bayesian Problem Solver, applies probabilistic inference and\ndecision-theoretic control to flexible, resource-constrained problem-solving.\nThis paper focuses on the Bayesian inference mechanism in BPS, and contrasts it\nwith those of traditional heuristic search techniques. By performing sound\ninference, BPS can outperform traditional techniques with significantly less\ncomputational effort. Empirical tests on the Eight Puzzle show that after only\na few hundred node expansions, BPS makes better decisions than does the best\nexisting algorithm after several million node expansions\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:35 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1510","submitter":"David Heckerman","authors":"David Heckerman, John S. Breese, Eric J. Horvitz","title":"The Compilation of Decision Models","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-162-173","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce and analyze the problem of the compilation of decision models\nfrom a decision-theoretic perspective. The techniques described allow us to\nevaluate various configurations of compiled knowledge given the nature of\nevidential relationships in a domain, the utilities associated with alternative\nactions, the costs of run-time delays, and the costs of memory. We describe\nprocedures for selecting a subset of the total observations available to be\nincorporated into a compiled situation-action mapping, in the context of a\nbinary decision with conditional independence of evidence. The methods allow us\nto incrementally select the best pieces of evidence to add to the set of\ncompiled knowledge in an engineering setting. After presenting several\napproaches to compilation, we exercise one of the methods to provide insight\ninto the relationship between the distribution over weights of evidence and the\npreferred degree of compilation.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:41 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1511","submitter":"David Heckerman","authors":"David Heckerman","title":"A Tractable Inference Algorithm for Diagnosing Multiple Diseases","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-174-181","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We examine a probabilistic model for the diagnosis of multiple diseases. In\nthe model, diseases and findings are represented as binary variables. Also,\ndiseases are marginally independent, features are conditionally independent\ngiven disease instances, and diseases interact to produce findings via a noisy\nOR-gate. An algorithm for computing the posterior probability of each disease,\ngiven a set of observed findings, called quickscore, is presented. The time\ncomplexity of the algorithm is O(nm-2m+), where n is the number of diseases, m+\nis the number of positive findings and m- is the number of negative findings.\nAlthough the time complexity of quickscore i5 exponential in the number of\npositive findings, the algorithm is useful in practice because the number of\nobserved positive findings is usually far less than the number of diseases\nunder consideration. Performance results for quickscore applied to a\nprobabilistic version of Quick Medical Reference (QMR) are provided.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:47 GMT"},{"version":"v2","created":"Mon, 5 Dec 2022 23:49:18 GMT"}],"update_date":"2022-12-07"}
{"id":"1304.1512","submitter":"Eric J. Horvitz","authors":"Eric J. Horvitz, Jaap Suermondt, Gregory F. Cooper","title":"Bounded Conditioning: Flexible Inference for Decisions under Scarce\n  Resources","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-182-193","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a graceful approach to probabilistic inference called bounded\nconditioning. Bounded conditioning monotonically refines the bounds on\nposterior probabilities in a belief network with computation, and converges on\nfinal probabilities of interest with the allocation of a complete resource\nfraction. The approach allows a reasoner to exchange arbitrary quantities of\ncomputational resource for incremental gains in inference quality. As such,\nbounded conditioning holds promise as a useful inference technique for\nreasoning under the general conditions of uncertain and varying reasoning\nresources. The algorithm solves a probabilistic bounding problem in complex\nbelief networks by breaking the problem into a set of mutually exclusive,\ntractable subproblems and ordering their solution by the expected effect that\neach subproblem will have on the final answer. We introduce the algorithm,\ndiscuss its characterization, and present its performance on several belief\nnetworks, including a complex model for reasoning about problems in\nintensive-care medicine.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:53 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1513","submitter":"A. C. Kak","authors":"A. C. Kak, K. M. Andress, C. Lopez-Abadia, M. S. Carroll, J. R. Lewis","title":"Hierarchical Evidence Accumulation in the Pseiki System and Experiments\n  in Model-Driven Mobile Robot Navigation","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-194-207","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we will review the process of evidence accumulation in the\nPSEIKI system for expectation-driven interpretation of images of 3-D scenes.\nExpectations are presented to PSEIKI as a geometrical hierarchy of\nabstractions. PSEIKI's job is then to construct abstraction hierarchies in the\nperceived image taking cues from the abstraction hierarchies in the\nexpectations. The Dempster-Shafer formalism is used for associating belief\nvalues with the different possible labels for the constructed abstractions in\nthe perceived image. This system has been used successfully for autonomous\nnavigation of a mobile robot in indoor environments.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:38:59 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1514","submitter":"Harold P. Lehmann","authors":"Harold P. Lehmann","title":"A Decision-Theoretic Model for Using Scientific Data","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-208-215","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many Artificial Intelligence systems depend on the agent's updating its\nbeliefs about the world on the basis of experience. Experiments constitute one\ntype of experience, so scientific methodology offers a natural environment for\nexamining the issues attendant to using this class of evidence. This paper\npresents a framework which structures the process of using scientific data from\nresearch reports for the purpose of making decisions, using decision analysis\nas the basis for the structure and using medical research as the general\nscientific domain. The structure extends the basic influence diagram for\nupdating belief in an object domain parameter of interest by expanding the\nparameter into four parts: those of the patient, the population, the study\nsample, and the effective study sample. The structure uses biases to perform\nthe transformation of one parameter into another, so that, for instance,\nselection biases, in concert with the population parameter, yield the study\nsample parameter. The influence diagram structure provides decision theoretic\njustification for practices of good clinical research such as randomized\nassignment and blindfolding of care providers. The model covers most research\ndesigns used in medicine: case-control studies, cohort studies, and controlled\nclinical trials, and provides an architecture to separate clearly between\nstatistical knowledge and domain knowledge. The proposed general model can be\nthe basis for clinical epidemiological advisory systems, when coupled with\nheuristic pruning of irrelevant biases; of statistical workstations, when the\ncomputational machinery for calculation of posterior distributions is added;\nand of meta-analytic reviews, when multiple studies may impact on a single\npopulation parameter.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:05 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1515","submitter":"Paul E. Lehner","authors":"Paul E. Lehner, Theresa M. Mullin, Marvin S. Cohen","title":"When Should a Decision Maker Ignore the Advice of a Decision Aid?","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-216-223","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper argues that the principal difference between decision aids and\nmost other types of information systems is the greater reliance of decision\naids on fallible algorithms--algorithms that sometimes generate incorrect\nadvice. It is shown that interactive problem solving with a decision aid that\nis based on a fallible algorithm can easily result in aided performance which\nis poorer than unaided performance, even if the algorithm, by itself, performs\nsignificantly better than the unaided decision maker. This suggests that unless\ncertain conditions are satisfied, using a decision aid as an aid is\ncounterproductive. Some conditions under which a decision aid is best used as\nan aid are derived.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:11 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1516","submitter":"Paul E. Lehner","authors":"Paul E. Lehner","title":"Inference Policies","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-224-232","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is suggested that an AI inference system should reflect an inference\npolicy that is tailored to the domain of problems to which it is applied -- and\nfurthermore that an inference policy need not conform to any general theory of\nrational inference or induction. We note, for instance, that Bayesian reasoning\nabout the probabilistic characteristics of an inference domain may result in\nthe specification of an nonBayesian procedure for reasoning within the\ninference domain. In this paper, the idea of an inference policy is explored in\nsome detail. To support this exploration, the characteristics of some standard\nand nonstandard inference policies are examined.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:17 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1517","submitter":"Tod S. Levitt","authors":"Tod S. Levitt, John Mark Agosta, Thomas O. Binford","title":"Model-based Influence Diagrams for Machine Vision","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-233-244","categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show an approach to automated control of machine vision systems based on\nincremental creation and evaluation of a particular family of influence\ndiagrams that represent hypotheses of imagery interpretation and possible\nsubsequent processing decisions. In our approach, model-based machine vision\ntechniques are integrated with hierarchical Bayesian inference to provide a\nframework for representing and matching instances of objects and relationships\nin imagery and for accruing probabilities to rank order conflicting scene\ninterpretations. We extend a result of Tatman and Shachter to show that the\nsequence of processing decisions derived from evaluating the diagrams at each\nstage is the same as the sequence that would have been derived by evaluating\nthe final influence diagram that contains all random variables created during\nthe run of the vision system.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:23 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1518","submitter":"Ronald P. Loui","authors":"Ronald P. Loui","title":"Defeasible Decisions: What the Proposal is and isn't","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-245-252","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In two recent papers, I have proposed a description of decision analysis that\ndiffers from the Bayesian picture painted by Savage, Jeffrey and other classic\nauthors. Response to this view has been either overly enthusiastic or unduly\npessimistic. In this paper I try to place the idea in its proper place, which\nmust be somewhere in between. Looking at decision analysis as defeasible\nreasoning produces a framework in which planning and decision theory can be\nintegrated, but work on the details has barely begun. It also produces a\nframework in which the meta-decision regress can be stopped in a reasonable\nway, but it does not allow us to ignore meta-level decisions. The heuristics\nfor producing arguments that I have presented are only supposed to be\nsuggestive; but they are not open to the egregious errors about which some have\nworried. And though the idea is familiar to those who have studied heuristic\nsearch, it is somewhat richer because the control of dialectic is more\ninteresting than the deepening of search.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:29 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1519","submitter":"Mary McLeish","authors":"Mary McLeish, P. Yao, M. Cecile, T. Stirtzinger","title":"Experiments Using Belief Functions and Weights of Evidence incorporating\n  Statistical Data and Expert Opinions","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-253-264","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents some ideas and results of using uncertainty management\nmethods in the presence of data in preference to other statistical and machine\nlearning methods. A medical domain is used as a test-bed with data available\nfrom a large hospital database system which collects symptom and outcome\ninformation about patients. Data is often missing, of many variable types and\nsample sizes for particular outcomes is not large. Uncertainty management\nmethods are useful for such domains and have the added advantage of allowing\nfor expert modification of belief values originally obtained from data.\nMethodological considerations for using belief functions on statistical data\nare dealt with in some detail. Expert opinions are Incorporated at various\nlevels of the project development and results are reported on an application to\nliver disease diagnosis. Recent results contrasting the use of weights of\nevidence and logistic regression on another medical domain are also presented.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:35 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1520","submitter":"W. R. Moninger","authors":"W. R. Moninger, J. A. Flueck, C. Lusk, W. F. Roberts","title":"Shootout-89: A Comparative Evaluation of Knowledge-based Systems that\n  Forecast Severe Weather","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-265-271","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  During the summer of 1989, the Forecast Systems Laboratory of the National\nOceanic and Atmospheric Administration sponsored an evaluation of artificial\nintelligence-based systems that forecast severe convective storms. The\nevaluation experiment, called Shootout-89, took place in Boulder, and focussed\non storms over the northeastern Colorado foothills and plains (Moninger, et\nal., 1990). Six systems participated in Shootout-89. These included traditional\nexpert systems, an analogy-based system, and a system developed using methods\nfrom the cognitive science/judgment analysis tradition. Each day of the\nexercise, the systems generated 2 to 9 hour forecasts of the probabilities of\noccurrence of: non significant weather, significant weather, and severe\nweather, in each of four regions in northeastern Colorado. A verification\ncoordinator working at the Denver Weather Service Forecast Office gathered\nground-truth data from a network of observers. Systems were evaluated on the\nbasis of several measures of forecast skill, and on other metrics such as\ntimeliness, ease of learning, and ease of use. Systems were generally easy to\noperate, however the various systems required substantially different levels of\nmeteorological expertise on the part of their users--reflecting the various\noperational environments for which the systems had been designed. Systems\nvaried in their statistical behavior, but on this difficult forecast problem,\nthe systems generally showed a skill approximately equal to that of persistence\nforecasts and climatological (historical frequency) forecasts. The two systems\nthat appeared best able to discriminate significant from non significant\nweather events were traditional expert systems. Both of these systems required\nthe operator to make relatively sophisticated meteorological judgments. We are\nunable, based on only one summer's worth of data, to determine the extent to\nwhich the greater skill of the two systems was due to the content of their\nknowledge bases, or to the subjective judgments of the operator. A follow-on\nexperiment, Shootout-91, is currently being planned. Interested potential\nparticipants are encouraged to contact the author at the address above.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:40 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1521","submitter":"Eric Neufeld","authors":"Eric Neufeld, J. D. Horton","title":"Conditioning on Disjunctive Knowledge: Defaults and Probabilities","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-272-278","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many writers have observed that default logics appear to contain the \"lottery\nparadox\" of probability theory. This arises when a default \"proof by\ncontradiction\" lets us conclude that a typical X is not a Y where Y is an\nunusual subclass of X. We show that there is a similar problem with default\n\"proof by cases\" and construct a setting where we might draw a different\nconclusion knowing a disjunction than we would knowing any particular disjunct.\nThough Reiter's original formalism is capable of representing this distinction,\nother approaches are not. To represent and reason about this case, default\nlogicians must specify how a \"typical\" individual is selected. The problem is\nclosely related to Simpson's paradox of probability theory. If we accept a\nsimple probabilistic account of defaults based on the notion that one\nproposition may favour or increase belief in another, the \"multiple extension\nproblem\" for both conjunctive and disjunctive knowledge vanishes.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:46 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1522","submitter":"Michael Pittarelli","authors":"Michael Pittarelli","title":"Maximum Uncertainty Procedures for Interval-Valued Probability\n  Distributions","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-279-286","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Measures of uncertainty and divergence are introduced for interval-valued\nprobability distributions and are shown to have desirable mathematical\nproperties. A maximum uncertainty inference procedure for marginal interval\ndistributions is presented. A technique for reconstruction of interval\ndistributions from projections is developed based on this inference procedure\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:51 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1523","submitter":"Gregory M. Provan","authors":"Gregory M. Provan","title":"A Logical Interpretation of Dempster-Shafer Theory, with Application to\n  Visual Recognition","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-287-294","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We formulate Dempster Shafer Belief functions in terms of Propositional Logic\nusing the implicit notion of provability underlying Dempster Shafer Theory.\nGiven a set of propositional clauses, assigning weights to certain\npropositional literals enables the Belief functions to be explicitly computed\nusing Network Reliability techniques. Also, the logical procedure corresponding\nto updating Belief functions using Dempster's Rule of Combination is shown.\nThis analysis formalizes the implementation of Belief functions within an\nAssumption-based Truth Maintenance System (ATMS). We describe the extension of\nan ATMS-based visual recognition system, VICTORS, with this logical formulation\nof Dempster Shafer theory. Without Dempster Shafer theory, VICTORS computes all\npossible visual interpretations (i.e. all logical models) without determining\nthe best interpretation(s). Incorporating Dempster Shafer theory enables\noptimal visual interpretations to be computed and a logical semantics to be\nmaintained.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:39:57 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1524","submitter":"Peter Sember","authors":"Peter Sember, Ingrid Zukerman","title":"Strategies for Generating Micro Explanations for Bayesian Belief\n  Networks","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-295-302","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bayesian Belief Networks have been largely overlooked by Expert Systems\npractitioners on the grounds that they do not correspond to the human inference\nmechanism. In this paper, we introduce an explanation mechanism designed to\ngenerate intuitive yet probabilistically sound explanations of inferences drawn\nby a Bayesian Belief Network. In particular, our mechanism accounts for the\nresults obtained due to changes in the causal and the evidential support of a\nnode.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:04 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1525","submitter":"Ross D. Shachter","authors":"Ross D. Shachter","title":"Evidence Absorption and Propagation through Evidence Reversals","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-303-310","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The arc reversal/node reduction approach to probabilistic inference is\nextended to include the case of instantiated evidence by an operation called\n\"evidence reversal.\" This not only provides a technique for computing posterior\njoint distributions on general belief networks, but also provides insight into\nthe methods of Pearl [1986b] and Lauritzen and Spiegelhalter [1988]. Although\nit is well understood that the latter two algorithms are closely related, in\nfact all three algorithms are identical whenever the belief network is a\nforest.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:10 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1526","submitter":"Ross D. Shachter","authors":"Ross D. Shachter, Mark Alan Peot","title":"Simulation Approaches to General Probabilistic Inference on Belief\n  Networks","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-311-318","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A number of algorithms have been developed to solve probabilistic inference\nproblems on belief networks. These algorithms can be divided into two main\ngroups: exact techniques which exploit the conditional independence revealed\nwhen the graph structure is relatively sparse, and probabilistic sampling\ntechniques which exploit the \"conductance\" of an embedded Markov chain when the\nconditional probabilities have non-extreme values. In this paper, we\ninvestigate a family of \"forward\" Monte Carlo sampling techniques similar to\nLogic Sampling [Henrion, 1988] which appear to perform well even in some\nmultiply connected networks with extreme conditional probabilities, and thus\nwould be generally applicable. We consider several enhancements which reduce\nthe posterior variance using this approach and propose a framework and criteria\nfor choosing when to use those enhancements.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:16 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1527","submitter":"Philippe Smets","authors":"Philippe Smets","title":"Decision under Uncertainty","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-319-326","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We derive axiomatically the probability function that should be used to make\ndecisions given any form of underlying uncertainty.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:21 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1528","submitter":"Michael Smithson","authors":"Michael Smithson","title":"Freedom: A Measure of Second-order Uncertainty for Intervalic\n  Probability Schemes","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-327-334","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper discusses a new measure that is adaptable to certain intervalic\nprobability frameworks, possibility theory, and belief theory. As such, it has\nthe potential for wide use in knowledge engineering, expert systems, and\nrelated problems in the human sciences. This measure (denoted here by F) has\nbeen introduced in Smithson (1988) and is more formally discussed in Smithson\n(1989a)o Here, I propose to outline the conceptual basis for F and compare its\nproperties with other measures of second-order uncertainty. I will argue that F\nis an indicator of nonspecificity or alternatively, of freedom, as\ndistinguished from either ambiguity or vagueness.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:27 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1529","submitter":"David J. Spiegelhalter","authors":"David J. Spiegelhalter, Rodney C. Franklin, Kate Bull","title":"Assessment, Criticism and Improvement of Imprecise Subjective\n  Probabilities for a Medical Expert System","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-335-342","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Three paediatric cardiologists assessed nearly 1000 imprecise subjective\nconditional probabilities for a simple belief network representing congenital\nheart disease, and the quality of the assessments has been measured using\nprospective data on 200 babies. Quality has been assessed by a Brier scoring\nrule, which decomposes into terms measuring lack of discrimination and\nreliability. The results are displayed for each of 27 diseases and 24\nquestions, and generally the assessments are reliable although there was a\ntendency for the probabilities to be too extreme. The imprecision allows the\njudgements to be converted to implicit samples, and by combining with the\nobserved data the probabilities naturally adapt with experience. This appears\nto be a practical procedure even for reasonably large expert systems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:33 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1530","submitter":"Sampath Srinivas","authors":"Sampath Srinivas, Stuart Russell, Alice M. Agogino","title":"Automated Construction of Sparse Bayesian Networks from Unstructured\n  Probabilistic Models and Domain Information","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-343-350","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An algorithm for automated construction of a sparse Bayesian network given an\nunstructured probabilistic model and causal domain information from an expert\nhas been developed and implemented. The goal is to obtain a network that\nexplicitly reveals as much information regarding conditional independence as\npossible. The network is built incrementally adding one node at a time. The\nexpert's information and a greedy heuristic that tries to keep the number of\narcs added at each step to a minimum are used to guide the search for the next\nnode to add. The probabilistic model is a predicate that can answer queries\nabout independencies in the domain. In practice the model can be implemented in\nvarious ways. For example, the model could be a statistical independence test\noperating on empirical data or a deductive prover operating on a set of\nindependence statements about the domain.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:38 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1531","submitter":"Thomas M. Strat","authors":"Thomas M. Strat","title":"Making Decisions with Belief Functions","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-351-360","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A primary motivation for reasoning under uncertainty is to derive decisions\nin the face of inconclusive evidence. However, Shafer's theory of belief\nfunctions, which explicitly represents the underconstrained nature of many\nreasoning problems, lacks a formal procedure for making decisions. Clearly,\nwhen sufficient information is not available, no theory can prescribe actions\nwithout making additional assumptions. Faced with this situation, some\nassumption must be made if a clearly superior choice is to emerge. In this\npaper we offer a probabilistic interpretation of a simple assumption that\ndisambiguates decision problems represented with belief functions. We prove\nthat it yields expected values identical to those obtained by a probabilistic\nanalysis that makes the same assumption. In addition, we show how the decision\nanalysis methodology frequently employed in probabilistic reasoning can be\nextended for use with belief functions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:45 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1532","submitter":"Michael J. Swain","authors":"Michael J. Swain, Lambert E. Wixson, Paul B. Chou","title":"Efficient Parallel Estimation for Markov Random Fields","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-361-368","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a new, deterministic, distributed MAP estimation algorithm for\nMarkov Random Fields called Local Highest Confidence First (Local HCF). The\nalgorithm has been applied to segmentation problems in computer vision and its\nperformance compared with stochastic algorithms. The experiments show that\nLocal HCF finds better estimates than stochastic algorithms with much less\ncomputation.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:50 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1533","submitter":"David S. Vaughan","authors":"David S. Vaughan, Bruce M. Perrin, Robert M. Yadrick","title":"Comparing Expert Systems Built Using Different Uncertain Inference\n  Systems","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-369-376","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study compares the inherent intuitiveness or usability of the most\nprominent methods for managing uncertainty in expert systems, including those\nof EMYCIN, PROSPECTOR, Dempster-Shafer theory, fuzzy set theory, simplified\nprobability theory (assuming marginal independence), and linear regression\nusing probability estimates. Participants in the study gained experience in a\nsimple, hypothetical problem domain through a series of learning trials. They\nwere then randomly assigned to develop an expert system using one of the six\nUncertain Inference Systems (UISs) listed above. Performance of the resulting\nsystems was then compared. The results indicate that the systems based on the\nPROSPECTOR and EMYCIN models were significantly less accurate for certain types\nof problems compared to systems based on the other UISs. Possible reasons for\nthese differences are discussed.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:40:56 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1534","submitter":"Wilson X. Wen","authors":"Wilson X. Wen","title":"Directed Cycles in Belief Networks","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-377-384","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The most difficult task in probabilistic reasoning may be handling directed\ncycles in belief networks. To the best knowledge of this author, there is no\nserious discussion of this problem at all in the literature of probabilistic\nreasoning so far.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:02 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1535","submitter":"Yang Xiang","authors":"Yang Xiang, Michael P. Beddoes, David L Poole","title":"Can Uncertainty Management be Realized in a Finite Totally Ordered\n  Probability Algebra?","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-385-393","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, the feasibility of using finite totally ordered probability\nmodels under Alelinnas's Theory of Probabilistic Logic [Aleliunas, 1988] is\ninvestigated. The general form of the probability algebra of these models is\nderived and the number of possible algebras with given size is deduced. Based\non this analysis, we discuss problems of denominator-indifference and\nambiguity-generation that arise in reasoning by cases and abductive reasoning.\nAn example is given that illustrates how these problems arise. The\ninvestigation shows that a finite probability model may be of very limited\nusage.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:07 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1536","submitter":"Ronald R. Yager","authors":"Ronald R. Yager","title":"Normalization and the Representation of Nonmonotonic Knowledge in the\n  Theory of Evidence","comments":"Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)","journal-ref":null,"doi":null,"report-no":"UAI-P-1989-PG-394-403","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss the Dempster-Shafer theory of evidence. We introduce a concept of\nmonotonicity which is related to the diminution of the range between belief and\nplausibility. We show that the accumulation of knowledge in this framework\nexhibits a nonmonotonic property. We show how the belief structure can be used\nto represent typical or commonsense knowledge.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:14 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.1785","submitter":"Farzad Hessar","authors":"Farzad Hessar and Sumit Roy","title":"Capacity Considerations for Secondary Networks in TV White Space","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The so-called `TV white spaces' (TVWS) - representing unused TV channels in\nany given location as the result of the transition to digital broadcasting -\ndesignated by U.S. Federal Communications Commission (FCC) for unlicensed use\npresents significant new opportunities within the context of emerging 4G\nnetworks for developing new wireless access technologies that meet the goals of\nthe US National Broadband Plan (notably true broadband access for an increasing\nfraction of the population). There are multiple challenges in realizing this\ngoal; the most fundamental being the fact that the available WS capacity is\ncurrently not accurately known, since it depends on a multiplicity of factors -\nincluding system parameters of existing incumbents (broadcasters), propagation\ncharacteristics of local terrain as well as FCC rules. In this paper, we\nexplore the capacity of white space networks by developing a detailed model\nthat includes all the major variables, and is cognizant of FCC regulations that\nprovide constraints on incumbent protection. Real terrain information and\npropagation models for the primary broadcaster and adjacent channel\ninterference from TV transmitters are included to estimate their impact on\nachievable WS capacity. The model is later used to explore various trade-offs\nbetween network capacity and system parameters and suggest possible amendments\nto FCC's incumbent protection rules in the favor of furthering white space\ncapacity.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 03:14:07 GMT"}],"update_date":"2013-04-08"}
{"id":"1304.2277","submitter":"Alexei Nesteruk Dr","authors":"Alexei V. Nesteruk","title":"A Participatory Universe of J. A. Wheeler as an Intentional Correlate of\n  Embodied Subjects and an Example of Purposiveness in Physics","comments":"22 pages, 1 figure","journal-ref":"Journal of Siberian Federal University. Humanities & Social\n  Sciences, vol. 6, n. 3, 2013, pp. 415-437","doi":null,"report-no":null,"categories":"physics.gen-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper investigates the role of human subjectivity and its delimiters in\narticulating the universe in physics and cosmology. As a case study, we reflect\nupon the complex of ideas of the so called Participatory Universe by later J.\nA. Wheeler. The objective of the paper is to explicate the role of the human\nagency as a centre of disclosure and manifestation of the universe as well the\nas teleology of scientific representation of the world implied by the intrinsic\npurposiveness of human actions.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 14:06:36 GMT"}],"update_date":"2013-04-09"}
{"id":"1304.2339","submitter":"John Mark Agosta","authors":"John Mark Agosta","title":"The structure of Bayes nets for vision recognition","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-1-7","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is part of a study whose goal is to show the effciency of using\nBayes networks to carry out model based vision calculations. [Binford et al.\n1987] Recognition proceeds by drawing up a network model from the object's\ngeometric and functional description that predicts the appearance of an object.\nThen this network is used to find the object within a photographic image. Many\nexisting and proposed techniques for vision recognition resemble the\nuncertainty calculations of a Bayes net. In contrast, though, they lack a\nderivation from first principles, and tend to rely on arbitrary parameters that\nwe hope to avoid by a network model. The connectedness of the network depends\non what independence considerations can be identified in the vision problem.\nGreater independence leads to easier calculations, at the expense of the net's\nexpressiveness. Once this trade-off is made and the structure of the network is\ndetermined, it should be possible to tailor a solution technique for it. This\npaper explores the use of a network with multiply connected paths, drawing on\nboth techniques of belief networks [Pearl 86] and influence diagrams. We then\ndemonstrate how one formulation of a multiply connected network can be solved.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:36 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2340","submitter":"Romas Aleliunas","authors":"Romas Aleliunas","title":"Summary of A New Normative Theory of Probabilistic Logic","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-8-14","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  By probabilistic logic I mean a normative theory of belief that explains how\na body of evidence affects one's degree of belief in a possible hypothesis. A\nnew axiomatization of such a theory is presented which avoids a finite\nadditivity axiom, yet which retains many useful inference rules. Many of the\nexamples of this theory--its models do not use numerical probabilities. Put\nanother way, this article gives sharper answers to the two questions: 1.What\nkinds of sets can used as the range of a probability function? 2.Under what\nconditions is the range set of a probability function isomorphic to the set of\nreal numbers in the interval 10,1/ with the usual arithmetical operations?\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:42 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2341","submitter":"Fahiem Bacchus","authors":"Fahiem Bacchus","title":"Probability Distributions Over Possible Worlds","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-15-21","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In Probabilistic Logic Nilsson uses the device of a probability distribution\nover a set of possible worlds to assign probabilities to the sentences of a\nlogical language. In his paper Nilsson concentrated on inference and associated\ncomputational issues. This paper, on the other hand, examines the probabilistic\nsemantics in more detail, particularly for the case of first-order languages,\nand attempts to explain some of the features and limitations of this form of\nprobability logic. It is pointed out that the device of assigning probabilities\nto logical sentences has certain expressive limitations. In particular,\nstatistical assertions are not easily expressed by such a device. This leads to\ncertain difficulties with attempts to give probabilistic semantics to default\nreasoning using probabilities assigned to logical sentences.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:48 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2342","submitter":"Paul K. Black","authors":"Paul K. Black, Kathryn Blackmond Laskey","title":"Hierarchical Evidence and Belief Functions","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-22-29","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dempster/Shafer (D/S) theory has been advocated as a way of representing\nincompleteness of evidence in a system's knowledge base. Methods now exist for\npropagating beliefs through chains of inference. This paper discusses how rules\nwith attached beliefs, a common representation for knowledge in automated\nreasoning systems, can be transformed into the joint belief functions required\nby propagation algorithms. A rule is taken as defining a conditional belief\nfunction on the consequent given the antecedents. It is demonstrated by example\nthat different joint belief functions may be consistent with a given set of\nrules. Moreover, different representations of the same rules may yield\ndifferent beliefs on the consequent hypotheses.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:53 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2343","submitter":"John S. Breese","authors":"John S. Breese, Michael R. Fehling","title":"Decision-Theoretic Control of Problem Solving: Principles and\n  Architecture","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-30-37","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents an approach to the design of autonomous, real-time\nsystems operating in uncertain environments. We address issues of problem\nsolving and reflective control of reasoning under uncertainty in terms of two\nfundamental elements: l) a set of decision-theoretic models for selecting among\nalternative problem-solving methods and 2) a general computational architecture\nfor resource-bounded problem solving. The decisiontheoretic models provide a\nset of principles for choosing among alternative problem-solving methods based\non their relative costs and benefits, where benefits are characterized in terms\nof the value of information provided by the output of a reasoning activity. The\noutput may be an estimate of some uncertain quantity or a recommendation for\naction. The computational architecture, called Schemer-ll, provides for\ninterleaving of and communication among various problem-solving subsystems.\nThese subsystems provide alternative approaches to information gathering,\nbelief refinement, solution construction, and solution execution. In\nparticular, the architecture provides a mechanism for interrupting the\nsubsystems in response to critical events. We provide a decision theoretic\naccount for scheduling problem-solving elements and for critical-event-driven\ninterruption of activities in an architecture such as Schemer-II.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:41:57 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2344","submitter":"M. Cecile","authors":"M. Cecile, Mary McLeish, P. Pascoe, W. Taylor","title":"Induction and Uncertainty Management Techniques Applied to Veterinary\n  Medical Diagnosis","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-38-48","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper discusses a project undertaken between the Departments of\nComputing Science, Statistics, and the College of Veterinary Medicine to design\na medical diagnostic system. On-line medical data has been collected in the\nhospital database system for several years. A number of induction methods are\nbeing used to extract knowledge from the data in an attempt to improve upon\nsimple diagnostic charts used by the clinicians. They also enhance the results\nof classical statistical methods - finding many more significant variables. The\nsecond part of the paper describes an essentially Bayesian method of evidence\ncombination using fuzzy events at an initial step. Results are presented and\ncomparisons are made with other methods.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:03 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2345","submitter":"R. Martin Chavez","authors":"R. Martin Chavez, Gregory F. Cooper","title":"KNET: Integrating Hypermedia and Bayesian Modeling","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-49-54","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  KNET is a general-purpose shell for constructing expert systems based on\nbelief networks and decision networks. Such networks serve as graphical\nrepresentations for decision models, in which the knowledge engineer must\ndefine clearly the alternatives, states, preferences, and relationships that\nconstitute a decision basis. KNET contains a knowledge-engineering core written\nin Object Pascal and an interface that tightly integrates HyperCard, a\nhypertext authoring tool for the Apple Macintosh computer, into a novel\nexpert-system architecture. Hypertext and hypermedia have become increasingly\nimportant in the storage management, and retrieval of information. In broad\nterms, hypermedia deliver heterogeneous bits of information in dynamic,\nextensively cross-referenced packages. The resulting KNET system features a\ncoherent probabilistic scheme for managing uncertainty, an objectoriented\ngraphics editor for drawing and manipulating decision networks, and HyperCard's\npotential for quickly constructing flexible and friendly user interfaces. We\nenvision KNET as a useful prototyping tool for our ongoing research on a\nvariety of Bayesian reasoning problems, including tractable representation,\ninference, and explanation.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:09 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2346","submitter":"Gregory F. Cooper","authors":"Gregory F. Cooper","title":"A Method for Using Belief Networks as Influence Diagrams","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-55-63","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper demonstrates a method for using belief-network algorithms to solve\ninfluence diagram problems. In particular, both exact and approximation\nbelief-network algorithms may be applied to solve influence-diagram problems.\nMore generally, knowing the relationship between belief-network and\ninfluence-diagram problems may be useful in the design and development of more\nefficient influence diagram algorithms.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:15 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2347","submitter":"Bruce D'Ambrosio","authors":"Bruce D'Ambrosio","title":"Process, Structure, and Modularity in Reasoning with Uncertainty","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-64-72","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Computational mechanisms for uncertainty management must support interactive\nand incremental problem formulation, inference, hypothesis testing, and\ndecision making. However, most current uncertainty inference systems\nconcentrate primarily on inference, and provide no support for the larger\nissues. We present a computational approach to uncertainty management which\nprovides direct support for the dynamic, incremental aspect of this task, while\nat the same time permitting direct representation of the structure of\nevidential relationships. At the same time, we show that this approach responds\nto the modularity concerns of Heckerman and Horvitz [Heck87]. This paper\nemphasizes examples of the capabilities of this approach. Another paper\n[D'Am89] details the representations and algorithms involved.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:20 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2348","submitter":"Thomas L. Dean","authors":"Thomas L. Dean, Keiji Kanazawa","title":"Probabilistic Causal Reasoning","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-73-80","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Predicting the future is an important component of decision making. In most\nsituations, however, there is not enough information to make accurate\npredictions. In this paper, we develop a theory of causal reasoning for\npredictive inference under uncertainty. We emphasize a common type of\nprediction that involves reasoning about persistence: whether or not a\nproposition once made true remains true at some later time. We provide a\ndecision procedure with a polynomial-time algorithm for determining the\nprobability of the possible consequences of a set events and initial\nconditions. The integration of simple probability theory with temporal\nprojection enables us to circumvent problems that nonmonotonic temporal\nreasoning schemes have in dealing with persistence. The ideas in this paper\nhave been implemented in a prototype system that refines a database of causal\nrules in the course of applying those rules to construct and carry out plans in\na manufacturing domain.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:26 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2349","submitter":"Didier Dubois","authors":"Didier Dubois, Henri Prade","title":"Modeling uncertain and vague knowledge in possibility and evidence\n  theories","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-81-89","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper advocates the usefulness of new theories of uncertainty for the\npurpose of modeling some facets of uncertain knowledge, especially vagueness,\nin AI. It can be viewed as a partial reply to Cheeseman's (among others)\ndefense of probability.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:31 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2350","submitter":"Soumitra Dutta","authors":"Soumitra Dutta","title":"A Temporal Logic for Uncertain Events and An Outline of A Possible\n  Implementation in An Extension of PROLOG","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-90-97","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is uncertainty associated with the occurrence of many events in real\nlife. In this paper we develop a temporal logic to deal with such uncertain\nevents and outline a possible implementation in an extension of PROLOG. Events\nare represented as fuzzy sets with the membership function giving the\npossibility of occurrence of the event in a given interval of time. The\ndeveloped temporal logic is simple but powerful. It can determine effectively\nthe various temporal relations between uncertain events or their combinations.\nPROLOG provides a uniform substrate on which to effectively implement such a\ntemporal logic for uncertain events\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:37 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2351","submitter":"Christoph F. Eick","authors":"Christoph F. Eick","title":"Uncertainty Management for Fuzzy Decision Support Systems","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-98-108","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A new approach for uncertainty management for fuzzy, rule based decision\nsupport systems is proposed: The domain expert's knowledge is expressed by a\nset of rules that frequently refer to vague and uncertain propositions. The\ncertainty of propositions is represented using intervals [a, b] expressing that\nthe proposition's probability is at least a and at most b. Methods and\ntechniques for computing the overall certainty of fuzzy compound propositions\nthat have been defined by using logical connectives 'and', 'or' and 'not' are\nintroduced. Different inference schemas for applying fuzzy rules by using modus\nponens are discussed. Different algorithms for combining evidence that has been\nreceived from different rules for the same proposition are provided. The\nrelationship of the approach to other approaches is analyzed and its problems\nof knowledge acquisition and knowledge representation are discussed in some\ndetail. The basic concepts of a rule-based programming language called PICASSO,\nfor which the approach is a theoretical foundation, are outlined.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:43 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2352","submitter":"Alan M. Frisch","authors":"Alan M. Frisch, Peter Haddawy","title":"Probability as a Modal Operator","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-109-118","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper argues for a modal view of probability. The syntax and semantics\nof one particularly strong probability logic are discussed and some examples of\nthe use of the logic are provided. We show that it is both natural and useful\nto think of probability as a modal operator. Contrary to popular belief in AI,\na probability ranging between 0 and 1 represents a continuum between\nimpossibility and necessity, not between simple falsity and truth. The present\nwork provides a clear semantics for quantification into the scope of the\nprobability operator and for higher-order probabilities. Probability logic is a\nlanguage for expressing both probabilistic and logical concepts.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:49 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2353","submitter":"Li-Min Fu","authors":"Li-Min Fu","title":"Truth Maintenance Under Uncertainty","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-119-126","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper addresses the problem of resolving errors under uncertainty in a\nrule-based system. A new approach has been developed that reformulates this\nproblem as a neural-network learning problem. The strength and the fundamental\nlimitations of this approach are explored and discussed. The main result is\nthat neural heuristics can be applied to solve some but not all problems in\nrule-based systems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:42:55 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2354","submitter":"Stephen I. Gallant","authors":"Stephen I. Gallant","title":"Bayesian Assessment of a Connectionist Model for Fault Detection","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-127-135","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A previous paper [2] showed how to generate a linear discriminant network\n(LDN) that computes likely faults for a noisy fault detection problem by using\na modification of the perceptron learning algorithm called the pocket\nalgorithm. Here we compare the performance of this connectionist model with\nperformance of the optimal Bayesian decision rule for the example that was\npreviously described. We find that for this particular problem the\nconnectionist model performs about 97% as well as the optimal Bayesian\nprocedure. We then define a more general class of noisy single-pattern boolean\n(NSB) fault detection problems where each fault corresponds to a single\n:pattern of boolean instrument readings and instruments are independently\nnoisy. This is equivalent to specifying that instrument readings are\nprobabilistic but conditionally independent given any particular fault. We\nprove:\n  1. The optimal Bayesian decision rule for every NSB fault detection problem\nis representable by an LDN containing no intermediate nodes. (This slightly\nextends a result first published by Minsky & Selfridge.) 2. Given an NSB fault\ndetection problem, then with arbitrarily high probability after sufficient\niterations the pocket algorithm will generate an LDN that computes an optimal\nBayesian decision rule for that problem. In practice we find that a reasonable\nnumber of iterations of the pocket algorithm produces a network with good, but\nnot optimal, performance.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:01 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2355","submitter":"Dan Geiger","authors":"Dan Geiger, Judea Pearl","title":"On the Logic of Causal Models","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-136-147","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper explores the role of Directed Acyclic Graphs (DAGs) as a\nrepresentation of conditional independence relationships. We show that DAGs\noffer polynomially sound and complete inference mechanisms for inferring\nconditional independence relationships from a given causal set of such\nrelationships. As a consequence, d-separation, a graphical criterion for\nidentifying independencies in a DAG, is shown to uncover more valid\nindependencies then any other criterion. In addition, we employ the Armstrong\nproperty of conditional independence to show that the dependence relationships\ndisplayed by a DAG are inherently consistent, i.e. for every DAG D there exists\nsome probability distribution P that embodies all the conditional\nindependencies displayed in D and none other.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:07 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2356","submitter":"Othar Hansson","authors":"Othar Hansson, Andy Mayer","title":"The Optimality of Satisficing Solutions","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-148-157","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper addresses a prevailing assumption in single-agent heuristic search\ntheory- that problem-solving algorithms should guarantee shortest-path\nsolutions, which are typically called optimal. Optimality implies a metric for\njudging solution quality, where the optimal solution is the solution with the\nhighest quality. When path-length is the metric, we will distinguish such\nsolutions as p-optimal.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:12 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2357","submitter":"David Heckerman","authors":"David Heckerman","title":"An Empirical Comparison of Three Inference Methods","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988). LaTex errors corrected in this version","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-158-169","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, an empirical evaluation of three inference methods for\nuncertain reasoning is presented in the context of Pathfinder, a large expert\nsystem for the diagnosis of lymph-node pathology. The inference procedures\nevaluated are (1) Bayes' theorem, assuming evidence is conditionally\nindependent given each hypothesis; (2) odds-likelihood updating, assuming\nevidence is conditionally independent given each hypothesis and given the\nnegation of each hypothesis; and (3) a inference method related to the\nDempster-Shafer theory of belief. Both expert-rating and decision-theoretic\nmetrics are used to compare the diagnostic accuracy of the inference methods.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:18 GMT"},{"version":"v2","created":"Sun, 17 May 2015 00:00:15 GMT"},{"version":"v3","created":"Tue, 24 Jan 2023 21:10:19 GMT"}],"update_date":"2023-01-26"}
{"id":"1304.2358","submitter":"Daniel Hunter","authors":"Daniel Hunter","title":"Parallel Belief Revision","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-170-177","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper describes a formal system of belief revision developed by Wolfgang\nSpohn and shows that this system has a parallel implementation that can be\nderived from an influence diagram in a manner similar to that in which Bayesian\nnetworks are derived. The proof rests upon completeness results for an\naxiomatization of the notion of conditional independence, with the Spohn system\nbeing used as a semantics for the relation of conditional independence.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:24 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2359","submitter":"Pramod Jain","authors":"Pramod Jain, Alice M. Agogino","title":"Stochastic Sensitivity Analysis Using Fuzzy Influence Diagrams","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-178-188","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The practice of stochastic sensitivity analysis described in the decision\nanalysis literature is a testimonial to the need for considering deviations\nfrom precise point estimates of uncertainty. We propose the use of Bayesian\nfuzzy probabilities within an influence diagram computational scheme for\nperforming sensitivity analysis during the solution of probabilistic inference\nand decision problems. Unlike other parametric approaches, the proposed scheme\ndoes not require resolving the problem for the varying probability point\nestimates. We claim that the solution to fuzzy influence diagrams provides as\nmuch information as the classical point estimate approach plus additional\ninformation concerning stochastic sensitivity. An example based on diagnostic\ndecision making in microcomputer assembly is used to illustrate this idea. We\nclaim that the solution to fuzzy influence diagrams provides as much\ninformation as the classical point estimate approach plus additional interval\ninformation that is useful for stochastic sensitivity analysis.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:30 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2360","submitter":"Holly B. Jimison","authors":"Holly B. Jimison","title":"A Representation of Uncertainty to Aid Insight into Decision Models","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-189-196","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many real world models can be characterized as weak, meaning that there is\nsignificant uncertainty in both the data input and inferences. This lack of\ndeterminism makes it especially difficult for users of computer decision aids\nto understand and have confidence in the models. This paper presents a\nrepresentation for uncertainty and utilities that serves as a framework for\ngraphical summary and computer-generated explanation of decision models. The\napplication described that tests the methodology is a computer decision aid\ndesigned to enhance the clinician-patient consultation process for patients\nwith angina (chest pain due to lack of blood flow to the heart muscle). The\nangina model is represented as a Bayesian decision network. Additionally, the\nprobabilities and utilities are treated as random variables with probability\ndistributions on their range of possible values. The initial distributions\nrepresent information on all patients with anginal symptoms, and the approach\nallows for rapid tailoring to more patientspecific distributions. This\nframework provides a metric for judging the importance of each variable in the\nmodel dynamically.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:36 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2361","submitter":"Carl Kadie","authors":"Carl Kadie","title":"Rational Nonmonotonic Reasoning","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-197-204","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nonmonotonic reasoning is a pattern of reasoning that allows an agent to make\nand retract (tentative) conclusions from inconclusive evidence. This paper\ngives a possible-worlds interpretation of the nonmonotonic reasoning problem\nbased on standard decision theory and the emerging probability logic. The\nsystem's central principle is that a tentative conclusion is a decision to make\na bet, not an assertion of fact. The system is rational, and as sound as the\nproof theory of its underlying probability log.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:41 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2362","submitter":"Jayant Kalagnanam","authors":"Jayant Kalagnanam, Max Henrion","title":"A Comparison of Decision Analysis and Expert Rules for Sequential\n  Diagnosis","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-205-212","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There has long been debate about the relative merits of decision theoretic\nmethods and heuristic rule-based approaches for reasoning under uncertainty. We\nreport an experimental comparison of the performance of the two approaches to\ntroubleshooting, specifically to test selection for fault diagnosis. We use as\nexperimental testbed the problem of diagnosing motorcycle engines. The first\napproach employs heuristic test selection rules obtained from expert mechanics.\nWe compare it with the optimal decision analytic algorithm for test selection\nwhich employs estimated component failure probabilities and test costs. The\ndecision analytic algorithm was found to reduce the expected cost (i.e. time)\nto arrive at a diagnosis by an average of 14% relative to the expert rules.\nSensitivity analysis shows the results are quite robust to inaccuracy in the\nprobability and cost estimates. This difference suggests some interesting\nimplications for knowledge acquisition.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:47 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2363","submitter":"Suk Wah Kwok","authors":"Suk Wah Kwok, Chris Carter","title":"Multiple decision trees","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-213-220","categories":"cs.LG cs.AI stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper describes experiments, on two domains, to investigate the effect\nof averaging over predictions of multiple decision trees, instead of using a\nsingle tree. Other authors have pointed out theoretical and commonsense reasons\nfor preferring the multiple tree approach. Ideally, we would like to consider\npredictions from all trees, weighted by their probability. However, there is a\nvast number of different trees, and it is difficult to estimate the probability\nof each tree. We sidestep the estimation problem by using a modified version of\nthe ID3 algorithm to build good trees, and average over only these trees. Our\nresults are encouraging. For each domain, we managed to produce a small number\nof good trees. We find that it is best to average across sets of trees with\ndifferent structure; this usually gives better performance than any of the\nconstituent trees, including the ID3 tree.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:53 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2364","submitter":"Henry E. Kyburg Jr.","authors":"Henry E. Kyburg Jr","title":"Probabilistic Inference and Probabilistic Reasoning","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-221-228","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Uncertainty enters into human reasoning and inference in at least two ways.\nIt is reasonable to suppose that there will be roles for these distinct uses of\nuncertainty also in automated reasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:43:58 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2365","submitter":"Henry E. Kyburg Jr.","authors":"Henry E. Kyburg Jr","title":"Probabilistic and Non-Monotonic Inference","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-229-236","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  (l) I have enough evidence to render the sentence S probable. (la) So,\nrelative to what I know, it is rational of me to believe S. (2) Now that I have\nmore evidence, S may no longer be probable. (2a) So now, relative to what I\nknow, it is not rational of me to believe S. These seem a perfectly ordinary,\ncommon sense, pair of situations. Generally and vaguely, I take them to embody\nwhat I shall call probabilistic inference. This form of inference is clearly\nnon-monotonic. Relatively few people have taken this form of inference, based\non high probability, to serve as a foundation for non-monotonic logic or for a\nlogical or defeasible inference. There are exceptions: Jane Nutter [16] thinks\nthat sometimes probability has something to do with non-monotonic reasoning.\nJudea Pearl [ 17] has recently been exploring the possibility. There are any\nnumber of people whom one might call probability enthusiasts who feel that\nprobability provides all the answers by itself, with no need of help from\nlogic. Cheeseman [1], Henrion [5] and others think it useful to look at a\ndistribution of probabilities over a whole algebra of statements, to update\nthat distribution in the light of new evidence, and to use the latest updated\ndistribution of probability over the algebra as a basis for planning and\ndecision making. A slightly weaker form of this approach is captured by Nilsson\n[15], where one assumes certain probabilities for certain statements, and\ninfers the probabilities, or constraints on the probabilities of other\nstatement. None of this corresponds to what I call probabilistic inference. All\nof the inference that is taking place, either in Bayesian updating, or in\nprobabilistic logic, is strictly deductive. Deductive inference, particularly\nthat concerned with the distribution of classical probabilities or chances, is\nof great importance. But this is not to say that there is no important role for\nwhat earlier logicians have called \"ampliative\" or \"inductive\" or \"scientific\"\ninference, in which the conclusion goes beyond the premises, asserts more than\ndo the premises. This depends on what David Israel [6] has called \"real rules\nof inference\". It is characteristic of any such logic or inference procedure\nthat it can go wrong: that statements accepted at one point may be rejected at\na later point. Research underlying the results reported here has been partially\nsupported by the Signals Warfare Center of the United States Army.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:04 GMT"}],"update_date":"2016-11-26"}
{"id":"1304.2366","submitter":"Henry E. Kyburg Jr.","authors":"Henry E. Kyburg Jr","title":"Epistemological Relevance and Statistical Knowledge","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-237-244","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For many years, at least since McCarthy and Hayes (1969), writers have\nlamented, and attempted to compensate for, the alleged fact that we often do\nnot have adequate statistical knowledge for governing the uncertainty of\nbelief, for making uncertain inferences, and the like. It is hardly ever\nspelled out what \"adequate statistical knowledge\" would be, if we had it, and\nhow adequate statistical knowledge could be used to control and regulate\nepistemic uncertainty.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:10 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2367","submitter":"Tod S. Levitt","authors":"Tod S. Levitt, Thomas O. Binford, Gil J. Ettinger, Patrice Gelband","title":"Utility-Based Control for Computer Vision","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-245-256","categories":"cs.CV cs.AI cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Several key issues arise in implementing computer vision recognition of world\nobjects in terms of Bayesian networks. Computational efficiency is a driving\nforce. Perceptual networks are very deep, typically fifteen levels of\nstructure. Images are wide, e.g., an unspecified-number of edges may appear\nanywhere in an image 512 x 512 pixels or larger. For efficiency, we dynamically\ninstantiate hypotheses of observed objects. The network is not fixed, but is\ncreated incrementally at runtime. Generation of hypotheses of world objects and\nindexing of models for recognition are important, but they are not considered\nhere [4,11]. This work is aimed at near-term implementation with parallel\ncomputation in a radar surveillance system, ADRIES [5, 15], and a system for\nindustrial part recognition, SUCCESSOR [2]. For many applications, vision must\nbe faster to be practical and so efficiently controlling the machine vision\nprocess is critical. Perceptual operators may scan megapixels and may require\nminutes of computation time. It is necessary to avoid unnecessary sensor\nactions and computation. Parallel computation is available at several levels of\nprocessor capability. The potential for parallel, distributed computation for\nhigh-level vision means distributing non-homogeneous computations. This paper\naddresses the problem of task control in machine vision systems based on\nBayesian probability models. We separate control and inference to extend the\nprevious work [3] to maximize utility instead of probability. Maximizing\nutility allows adopting perceptual strategies for efficient information\ngathering with sensors and analysis of sensor data. Results of controlling\nmachine vision via utility to recognize military situations are presented in\nthis paper. Future work extends this to industrial part recognition for\nSUCCESSOR.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:16 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2368","submitter":"Ronald P. Loui","authors":"Ronald P. Loui","title":"Evidential Reasoning in a Network Usage Prediction Testbed","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-257-265","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper reports on empirical work aimed at comparing evidential reasoning\ntechniques. While there is prima facie evidence for some conclusions, this i6\nwork in progress; the present focus is methodology, with the goal that\nsubsequent results be meaningful. The domain is a network of UNIX* cycle\nservers, and the task is to predict properties of the state of the network from\npartial descriptions of the state. Actual data from the network are taken and\nused for blindfold testing in a betting game that allows abstention. The focal\ntechnique has been Kyburg's method for reasoning with data of varying relevance\nto a particular query, though the aim is to be able eventually to compare\nvarious uncertainty calculi. The conclusions are not novel, but are\ninstructive. 1. All of the calculi performed better than human subjects, so\nunbiased access to sample experience is apparently of value. 2. Performance\ndepends on metric: (a) when trials are repeated, net = gains - losses favors\nmethods that place many bets, if the probability of placing a correct bet is\nsufficiently high; that is, it favors point-valued formalisms; (b) yield =\ngains/(gains + lossee) favors methods that bet only when sure to bet correctly;\nthat is, it favors interval-valued formalisms. 3. Among the calculi, there were\nno clear winners or losers. Methods are identified for eliminating the bias of\nthe net as a performance criterion and for separating the calculi effectively:\nin both cases by posting odds for the betting game in the appropriate way.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:22 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2369","submitter":"Richard E. Neapolitan","authors":"Richard E. Neapolitan, James Kenevan","title":"Justifying the Principle of Interval Constraints","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-266-274","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  When knowledge is obtained from a database, it is only possible to deduce\nconfidence intervals for probability values. With confidence intervals\nreplacing point values, the results in the set covering model include interval\nconstraints for the probabilities of mutually exclusive and exhaustive\nexplanations. The Principle of Interval Constraints ranks these explanations by\ndetermining the expected values of the probabilities based on distributions\ndetermined from the interval, constraints. This principle was developed using\nthe Classical Approach to probability. This paper justifies the Principle of\nInterval Constraints with a more rigorous statement of the Classical Approach\nand by defending the concept of probabilities of probabilities.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:27 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2370","submitter":"Eric Neufeld","authors":"Eric Neufeld, David L Poole","title":"Probabilistic Semantics and Defaults","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-275-282","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is much interest in providing probabilistic semantics for defaults but\nmost approaches seem to suffer from one of two problems: either they require\nnumbers, a problem defaults were intended to avoid, or they generate peculiar\nside effects. Rather than provide semantics for defaults, we address the\nproblem defaults were intended to solve: that of reasoning under uncertainty\nwhere numeric probability distributions are not available. We describe a\nnon-numeric formalism called an inference graph based on standard probability\ntheory, conditional independence and sentences of favouring where a favours b -\nfavours(a, b) - p(a|b) > p(a). The formalism seems to handle the examples from\nthe nonmonotonic literature. Most importantly, the sentences of our system can\nbe verified by performing an appropriate experiment in the semantic domain.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:33 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2371","submitter":"Michael Pittarelli","authors":"Michael Pittarelli","title":"Decision Making with Linear Constraints on Probabilities","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-283-290","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Techniques for decision making with knowledge of linear constraints on\ncondition probabilities are examined. These constraints arise naturally in many\nsituations: upper and lower condition probabilities are known; an ordering\namong the probabilities is determined; marginal probabilities or bounds on such\nprobabilities are known, e.g., data are available in the form of a\nprobabilistic database (Cavallo and Pittarelli, 1987a); etc. Standard\nsituations of decision making under risk and uncertainty may also be\ncharacterized by linear constraints. Each of these types of information may be\nrepresented by a convex polyhedron of numerically determinate condition\nprobabilities. A uniform approach to decision making under risk, uncertainty,\nand partial uncertainty based on a generalized version of a criterion of\nHurwicz is proposed, Methods for processing marginal probabilities to improve\ndecision making using any of the criteria discussed are presented.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:38 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2372","submitter":"Thomas F. Reid","authors":"Thomas F. Reid, Gregory S. Parnell","title":"Maintenance in Probabilistic Knowledge-Based Systems","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-291-298","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent developments using directed acyclical graphs (i.e., influence diagrams\nand Bayesian networks) for knowledge representation have lessened the problems\nof using probability in knowledge-based systems (KBS). Most current research\ninvolves the efficient propagation of new evidence, but little has been done\nconcerning the maintenance of domain-specific knowledge, which includes the\nprobabilistic information about the problem domain. By making use of\nconditional independencies represented in she graphs, however, probability\nassessments are required only for certain variables when the knowledge base is\nupdated. The purpose of this study was to investigate, for those variables\nwhich require probability assessments, ways to reduce the amount of new\nknowledge required from the expert when updating probabilistic information in a\nprobabilistic knowledge-based system. Three special cases (ignored outcome,\nsplit outcome, and assumed constraint outcome) were identified under which many\nof the original probabilities (those already in the knowledge-base) do not need\nto be reassessed when maintenance is required.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:46 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2373","submitter":"Ross D. Shachter","authors":"Ross D. Shachter","title":"A Linear Approximation Method for Probabilistic Inference","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-299-306","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An approximation method is presented for probabilistic inference with\ncontinuous random variables. These problems can arise in many practical\nproblems, in particular where there are \"second order\" probabilities. The\napproximation, based on the Gaussian influence diagram, iterates over linear\napproximations to the inference problem.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:52 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2374","submitter":"Prakash P. Shenoy","authors":"Prakash P. Shenoy, Glenn Shafer","title":"An Axiomatic Framework for Bayesian and Belief-function Propagation","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-307-314","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we describe an abstract framework and axioms under which exact\nlocal computation of marginals is possible. The primitive objects of the\nframework are variables and valuations. The primitive operators of the\nframework are combination and marginalization. These operate on valuations. We\nstate three axioms for these operators and we derive the possibility of local\ncomputation from the axioms. Next, we describe a propagation scheme for\ncomputing marginals of a valuation when we have a factorization of the\nvaluation on a hypertree. Finally we show how the problem of computing\nmarginals of joint probability distributions and joint belief functions fits\nthe general framework.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:44:57 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2375","submitter":"Wolfgang Spohn","authors":"Wolfgang Spohn","title":"A General Non-Probabilistic Theory of Inductive Reasoning","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-315-322","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Probability theory, epistemically interpreted, provides an excellent, if not\nthe best available account of inductive reasoning. This is so because there are\ngeneral and definite rules for the change of subjective probabilities through\ninformation or experience; induction and belief change are one and same topic,\nafter all. The most basic of these rules is simply to conditionalize with\nrespect to the information received; and there are similar and more general\nrules. 1 Hence, a fundamental reason for the epistemological success of\nprobability theory is that there at all exists a well-behaved concept of\nconditional probability. Still, people have, and have reasons for, various\nconcerns over probability theory. One of these is my starting point:\nIntuitively, we have the notion of plain belief; we believe propositions2 to be\ntrue (or to be false or neither). Probability theory, however, offers no formal\ncounterpart to this notion. Believing A is not the same as having probability 1\nfor A, because probability 1 is incorrigible3; but plain belief is clearly\ncorrigible. And believing A is not the same as giving A a probability larger\nthan some 1 - c, because believing A and believing B is usually taken to be\nequivalent to believing A & B.4 Thus, it seems that the formal representation\nof plain belief has to take a non-probabilistic route. Indeed, representing\nplain belief seems easy enough: simply represent an epistemic state by the set\nof all propositions believed true in it or, since I make the common assumption\nthat plain belief is deductively closed, by the conjunction of all propositions\nbelieved true in it. But this does not yet provide a theory of induction, i.e.\nan answer to the question how epistemic states so represented are changed\ntbrough information or experience. There is a convincing partial answer: if the\nnew information is compatible with the old epistemic state, then the new\nepistemic state is simply represented by the conjunction of the new information\nand the old beliefs. This answer is partial because it does not cover the quite\ncommon case where the new information is incompatible with the old beliefs. It\nis, however, important to complete the answer and to cover this case, too;\notherwise, we would not represent plain belief as conigible. The crucial\nproblem is that there is no good completion. When epistemic states are\nrepresented simply by the conjunction of all propositions believed true in it,\nthe answer cannot be completed; and though there is a lot of fruitful work, no\nother representation of epistemic states has been proposed, as far as I know,\nwhich provides a complete solution to this problem. In this paper, I want to\nsuggest such a solution. In [4], I have more fully argued that this is the only\nsolution, if certain plausible desiderata are to be satisfied. Here, in section\n2, I will be content with formally defining and intuitively explaining my\nproposal. I will compare my proposal with probability theory in section 3. It\nwill turn out that the theory I am proposing is structurally homomorphic to\nprobability theory in important respects and that it is thus equally easily\nimplementable, but moreover computationally simpler. Section 4 contains a very\nbrief comparison with various kinds of logics, in particular conditional logic,\nwith Shackle's functions of potential surprise and related theories, and with\nthe Dempster - Shafer theory of belief functions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:03 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2376","submitter":"Spencer Star","authors":"Spencer Star","title":"Generating Decision Structures and Causal Explanations for Decision\n  Making","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-323-334","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper examines two related problems that are central to developing an\nautonomous decision-making agent, such as a robot. Both problems require\ngenerating structured representafions from a database of unstructured\ndeclarative knowledge that includes many facts and rules that are irrelevant in\nthe problem context. The first problem is how to generate a well structured\ndecision problem from such a database. The second problem is how to generate,\nfrom the same database, a well-structured explanation of why some possible\nworld occurred. In this paper it is shown that the problem of generating the\nappropriate decision structure or explanation is intractable without\nintroducing further constraints on the knowledge in the database. The paper\nproposes that the problem search space can be constrained by adding knowledge\nto the database about causal relafions between events. In order to determine\nthe causal knowledge that would be most useful, causal theories for\ndeterministic and indeterministic universes are proposed. A program that uses\nsome of these causal constraints has been used to generate explanations about\nfaulty plans. The program shows the expected increase in efficiency as the\ncausal constraints are introduced.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:09 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2377","submitter":"Jaap Suermondt","authors":"Jaap Suermondt, Gregory F. Cooper","title":"Updating Probabilities in Multiply-Connected Belief Networks","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-335-343","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper focuses on probability updates in multiply-connected belief\nnetworks. Pearl has designed the method of conditioning, which enables us to\napply his algorithm for belief updates in singly-connected networks to\nmultiply-connected belief networks by selecting a loop-cutset for the network\nand instantiating these loop-cutset nodes. We discuss conditions that need to\nbe satisfied by the selected nodes. We present a heuristic algorithm for\nfinding a loop-cutset that satisfies these conditions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:15 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2378","submitter":"Bjornar Tessem","authors":"Bjornar Tessem, Lars Johan Ersland","title":"Handling uncertainty in a system for text-symbol context analysis","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-344-351","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In pattern analysis, information regarding an object can often be drawn from\nits surroundings. This paper presents a method for handling uncertainty when\nusing context of symbols and texts for analyzing technical drawings. The method\nis based on Dempster-Shafer theory and possibility theory.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:21 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2379","submitter":"Tom S. Verma","authors":"Tom S. Verma, Judea Pearl","title":"Causal Networks: Semantics and Expressiveness","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-352-359","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dependency knowledge of the form \"x is independent of y once z is known\"\ninvariably obeys the four graphoid axioms, examples include probabilistic and\ndatabase dependencies. Often, such knowledge can be represented efficiently\nwith graphical structures such as undirected graphs and directed acyclic graphs\n(DAGs). In this paper we show that the graphical criterion called d-separation\nis a sound rule for reading independencies from any DAG based on a causal input\nlist drawn from a graphoid. The rule may be extended to cover DAGs that\nrepresent functional dependencies as well as conditional dependencies.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:27 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2380","submitter":"Wilson X. Wen","authors":"Wilson X. Wen","title":"MCE Reasoning in Recursive Causal Networks","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-360-367","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A probabilistic method of reasoning under uncertainty is proposed based on\nthe principle of Minimum Cross Entropy (MCE) and concept of Recursive Causal\nModel (RCM). The dependency and correlations among the variables are described\nin a special language BNDL (Belief Networks Description Language). Beliefs are\npropagated among the clauses of the BNDL programs representing the underlying\nprobabilistic distributions. BNDL interpreters in both Prolog and C has been\ndeveloped and the performance of the method is compared with those of the\nothers.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:33 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2381","submitter":"Ronald R. Yager","authors":"Ronald R. Yager","title":"Nonmonotonic Reasoning via Possibility Theory","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-368-373","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce the operation of possibility qualification and show how. this\nmodal-like operator can be used to represent \"typical\" or default knowledge in\na theory of nonmonotonic reasoning. We investigate the representational power\nof this approach by looking at a number of prototypical problems from the\nnonmonotonic reasoning literature. In particular we look at the so called Yale\nshooting problem and its relation to priority in default reasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:38 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2382","submitter":"Alexander Yeh","authors":"Alexander Yeh","title":"Predicting the Likely Behaviors of Continuous Nonlinear Systems in\n  Equilibrium","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-374-381","categories":"cs.SY cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper introduces a method for predicting the likely behaviors of\ncontinuous nonlinear systems in equilibrium in which the input values can vary.\nThe method uses a parameterized equation model and a lower bound on the input\njoint density to bound the likelihood that some behavior will occur, such as a\nstate variable being inside a given numeric range. Using a bound on the density\ninstead of the density itself is desirable because often the input density's\nparameters and shape are not exactly known. The new method is called SAB after\nits basic operations: split the input value space into smaller regions, and\nthen bound those regions' possible behaviors and the probability of being in\nthem. SAB finds rough bounds at first, and then refines them as more time is\ngiven. In contrast to other researchers' methods, SAB can (1) find all the\npossible system behaviors, and indicate how likely they are, (2) does not\napproximate the distribution of possible outcomes without some measure of the\nerror magnitude, (3) does not use discretized variable values, which limit the\nevents one can find probability bounds for, (4) can handle density bounds, and\n(5) can handle such criteria as two state variables both being inside a numeric\nrange.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:44 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2383","submitter":"John Yen","authors":"John Yen","title":"Generalizing the Dempster-Shafer Theory to Fuzzy Sets","comments":"Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)","journal-ref":null,"doi":null,"report-no":"UAI-P-1988-PG-382-391","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With the desire to apply the Dempster-Shafer theory to complex real world\nproblems where the evidential strength is often imprecise and vague, several\nattempts have been made to generalize the theory. However, the important\nconcept in the D-S theory that the belief and plausibility functions are lower\nand upper probabilities is no longer preserved in these generalizations. In\nthis paper, we describe a generalized theory of evidence where the degree of\nbelief in a fuzzy set is obtained by minimizing the probability of the fuzzy\nset under the constraints imposed by a basic probability assignment. To\nformulate the probabilistic constraint of a fuzzy focal element, we decompose\nit into a set of consonant non-fuzzy focal elements. By generalizing the\ncompatibility relation to a possibility theory, we are able to justify our\ngeneralization to Dempster's rule based on possibility distribution. Our\ngeneralization not only extends the application of the D-S theory but also\nillustrates a way that probability theory and fuzzy set theory can be combined\nto deal with different kinds of uncertain information in AI systems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:45:50 GMT"}],"update_date":"2013-04-10"}
{"id":"1304.2711","submitter":"Paul K. Black","authors":"Paul K. Black","title":"Is Shafer General Bayes?","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-2-9","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper examines the relationship between Shafer's belief functions and\nconvex sets of probability distributions. Kyburg's (1986) result showed that\nbelief function models form a subset of the class of closed convex probability\ndistributions. This paper emphasizes the importance of Kyburg's result by\nlooking at simple examples involving Bernoulli trials. Furthermore, it is shown\nthat many convex sets of probability distributions generate the same belief\nfunction in the sense that they support the same lower and upper values. This\nhas implications for a decision theoretic extension. Dempster's rule of\ncombination is also compared with Bayes' rule of conditioning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:18 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2712","submitter":"Paul Cohen","authors":"Paul Cohen, Glenn Shafer, Prakash P. Shenoy","title":"Modifiable Combining Functions","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-10-21","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modifiable combining functions are a synthesis of two common approaches to\ncombining evidence. They offer many of the advantages of these approaches and\navoid some disadvantages. Because they facilitate the acquisition,\nrepresentation, explanation, and modification of knowledge about combinations\nof evidence, they are proposed as a tool for knowledge engineers who build\nsystems that reason under uncertainty, not as a normative theory of evidence.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:23 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2713","submitter":"Daniel Hunter","authors":"Daniel Hunter","title":"Dempster-Shafer vs. Probabilistic Logic","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-22-29","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The combination of evidence in Dempster-Shafer theory is compared with the\ncombination of evidence in probabilistic logic. Sufficient conditions are\nstated for these two methods to agree. It is then shown that these conditions\nare minimal in the sense that disagreement can occur when any one of them is\nremoved. An example is given in which the traditional assumption of conditional\nindependence of evidence on hypotheses holds and a uniform prior is assumed,\nbut probabilistic logic and Dempster's rule give radically different results\nfor the combination of two evidence events.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:27 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2714","submitter":"Henry E. Kyburg Jr.","authors":"Henry E. Kyburg Jr","title":"Higher Order Probabilities","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-30-38","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A number of writers have supposed that for the full specification of belief,\nhigher order probabilities are required. Some have even supposed that there may\nbe an unending sequence of higher order probabilities of probabilities of\nprobabilities.... In the present paper we show that higher order probabilities\ncan always be replaced by the marginal distributions of joint probability\ndistributions. We consider both the case in which higher order probabilities\nare of the same sort as lower order probabilities and that in which higher\norder probabilities are distinct in character, as when lower order\nprobabilities are construed as frequencies and higher order probabilities are\nconstrued as subjective degrees of belief. In neither case do higher order\nprobabilities appear to offer any advantages, either conceptually or\ncomputationally.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:32 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2715","submitter":"Kathryn Blackmond Laskey","authors":"Kathryn Blackmond Laskey","title":"Belief in Belief Functions: An Examination of Shafer's Canonical\n  Examples","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-39-46","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the canonical examples underlying Shafer-Dempster theory, beliefs over the\nhypotheses of interest are derived from a probability model for a set of\nauxiliary hypotheses. Beliefs are derived via a compatibility relation\nconnecting the auxiliary hypotheses to subsets of the primary hypotheses. A\nbelief function differs from a Bayesian probability model in that one does not\ncondition on those parts of the evidence for which no probabilities are\nspecified. The significance of this difference in conditioning assumptions is\nillustrated with two examples giving rise to identical belief functions but\ndifferent Bayesian probability distributions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:37 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2716","submitter":"Judea Pearl","authors":"Judea Pearl","title":"Do We Need Higher-Order Probabilities and, If So, What Do They Mean?","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-47-60","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The apparent failure of individual probabilistic expressions to distinguish\nuncertainty about truths from uncertainty about probabilistic assessments have\nprompted researchers to seek formalisms where the two types of uncertainties\nare given notational distinction. This paper demonstrates that the desired\ndistinction is already a built-in feature of classical probabilistic models,\nthus, specialized notations are unnecessary.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:42 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2717","submitter":"Matthew Self","authors":"Matthew Self, Peter Cheeseman","title":"Bayesian Prediction for Artificial Intelligence","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-61-69","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper shows that the common method used for making predictions under\nuncertainty in A1 and science is in error. This method is to use currently\navailable data to select the best model from a given class of models-this\nprocess is called abduction-and then to use this model to make predictions\nabout future data. The correct method requires averaging over all the models to\nmake a prediction-we call this method transduction. Using transduction, an AI\nsystem will not give misleading results when basing predictions on small\namounts of data, when no model is clearly best. For common classes of models we\nshow that the optimal solution can be given in closed form.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:47 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2718","submitter":"John Yen","authors":"John Yen","title":"Can Evidence Be Combined in the Dempster-Shafer Theory","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-70-76","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dempster's rule of combination has been the most controversial part of the\nDempster-Shafer (D-S) theory. In particular, Zadeh has reached a conjecture on\nthe noncombinability of evidence from a relational model of the D-S theory. In\nthis paper, we will describe another relational model where D-S masses are\nrepresented as conditional granular distributions. By comparing it with Zadeh's\nrelational model, we will show how Zadeh's conjecture on combinability does not\naffect the applicability of Dempster's rule in our model.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:52 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2719","submitter":"John B. Bacon","authors":"John B. Bacon","title":"An Interesting Uncertainty-Based Combinatoric Problem in Spare Parts\n  Forecasting: The FRED System","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-78-85","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The domain of spare parts forecasting is examined, and is found to present\nunique uncertainty based problems in the architectural design of a\nknowledge-based system. A mixture of different uncertainty paradigms is\nrequired for the solution, with an intriguing combinatoric problem arising from\nan uncertain choice of inference engines. Thus, uncertainty in the system is\nmanifested in two different meta-levels. The different uncertainty paradigms\nand meta-levels must be integrated into a functioning whole. FRED is an example\nof a difficult real-world domain to which no existing uncertainty approach is\ncompletely appropriate. This paper discusses the architecture of FRED,\nhighlighting: the points of uncertainty and other interesting features of the\ndomain, the specific implications of those features on the system design\n(including the combinatoric explosions), their current implementation & future\nplans,and other problems and issues with the architecture.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:46:57 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2720","submitter":"Thomas O. Binford","authors":"Thomas O. Binford, Tod S. Levitt, Wallace B. Mann","title":"Bayesian Inference in Model-Based Machine Vision","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-86-97","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This is a preliminary version of visual interpretation integrating multiple\nsensors in SUCCESSOR, an intelligent, model-based vision system. We pursue a\nthorough integration of hierarchical Bayesian inference with comprehensive\nphysical representation of objects and their relations in a system for\nreasoning with geometry, surface materials and sensor models in machine vision.\nBayesian inference provides a framework for accruing_ probabilities to rank\norder hypotheses.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:03 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2721","submitter":"Gautam Biswas","authors":"Gautam Biswas, Teywansh S. Anand","title":"Using the Dempster-Shafer Scheme in a Diagnostic Expert System Shell","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-98-105","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper discusses an expert system shell that integrates rule-based\nreasoning and the Dempster-Shafer evidence combination scheme. Domain knowledge\nis stored as rules with associated belief functions. The reasoning component\nuses a combination of forward and backward inferencing mechanisms to allow\ninteraction with users in a mixed-initiative format.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:07 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2722","submitter":"Homer L. Chin","authors":"Homer L. Chin, Gregory F. Cooper","title":"Stochastic Simulation of Bayesian Belief Networks","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-106-113","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper examines Bayesian belief network inference using simulation as a\nmethod for computing the posterior probabilities of network variables.\nSpecifically, it examines the use of a method described by Henrion, called\nlogic sampling, and a method described by Pearl, called stochastic simulation.\nWe first review the conditions under which logic sampling is computationally\ninfeasible. Such cases motivated the development of the Pearl's stochastic\nsimulation algorithm. We have found that this stochastic simulation algorithm,\nwhen applied to certain networks, leads to much slower than expected\nconvergence to the true posterior probabilities. This behavior is a result of\nthe tendency for local areas in the network to become fixed through many\nsimulation cycles. The time required to obtain significant convergence can be\nmade arbitrarily long by strengthening the probabilistic dependency between\nnodes. We propose the use of several forms of graph modification, such as graph\npruning, arc reversal, and node reduction, in order to convert some networks\ninto formats that are computationally more efficient for simulation.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:13 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2723","submitter":"Steve Hanks","authors":"Steve Hanks","title":"Temporal Reasoning About Uncertain Worlds","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-114-122","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a program that manages a database of temporally scoped beliefs.\nThe basic functionality of the system includes maintaining a network of\nconstraints among time points, supporting a variety of fetches, mediating the\napplication of causal rules, monitoring intervals of time for the addition of\nnew facts, and managing data dependencies that keep the database consistent. At\nthis level the system operates independent of any measure of belief or belief\ncalculus. We provide an example of how an application program mi9ght use this\nfunctionality to implement a belief calculus.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:17 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2724","submitter":"David Heckerman","authors":"David Heckerman, Holly B. Jimison","title":"A Perspective on Confidence and Its Use in Focusing Attention During\n  Knowledge Acquisition","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-123-131","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a representation of partial confidence in belief and preference\nthat is consistent with the tenets of decision-theory. The fundamental insight\nunderlying the representation is that if a person is not completely confident\nin a probability or utility assessment, additional modeling of the assessment\nmay improve decisions to which it is relevant. We show how a traditional\ndecision-analytic approach can be used to balance the benefits of additional\nmodeling with associated costs. The approach can be used during knowledge\nacquisition to focus the attention of a knowledge engineer or expert on parts\nof a decision model that deserve additional refinement.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:22 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2725","submitter":"Max Henrion","authors":"Max Henrion","title":"Practical Issues in Constructing a Bayes' Belief Network","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-132-139","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bayes belief networks and influence diagrams are tools for constructing\ncoherent probabilistic representations of uncertain knowledge. The process of\nconstructing such a network to represent an expert's knowledge is used to\nillustrate a variety of techniques which can facilitate the process of\nstructuring and quantifying uncertain relationships. These include some\ngeneralizations of the \"noisy OR gate\" concept. Sensitivity analysis of generic\nelements of Bayes' networks provides insight into when rough probability\nassessments are sufficient and when greater precision may be important.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:27 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2726","submitter":"Michael C. Higgins","authors":"Michael C. Higgins","title":"NAIVE: A Method for Representing Uncertainty and Temporal Relationships\n  in an Automated Reasoner","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-140-147","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper describes NAIVE, a low-level knowledge representation language and\ninferencing process. NAIVE has been designed for reasoning about\nnondeterministic dynamic systems like those found in medicine. Knowledge is\nrepresented in a graph structure consisting of nodes, which correspond to the\nvariables describing the system of interest, and arcs, which correspond to the\nprocedures used to infer the value of a variable from the values of other\nvariables. The value of a variable can be determined at an instant in time,\nover a time interval or for a series of times. Information about the value of a\nvariable is expressed as a probability density function which quantifies the\nlikelihood of each possible value. The inferencing process uses these\nprobability density functions to propagate uncertainty. NAIVE has been used to\ndevelop medical knowledge bases including over 100 variables.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:31 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2727","submitter":"Henry E. Kyburg Jr.","authors":"Henry E. Kyburg Jr","title":"Objective Probability","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-148-155","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A distinction is sometimes made between \"statistical\" and \"subjective\"\nprobabilities. This is based on a distinction between \"unique\" events and\n\"repeatable\" events. We argue that this distinction is untenable, since all\nevents are \"unique\" and all events belong to \"kinds\", and offer a conception of\nprobability for A1 in which (1) all probabilities are based on -- possibly\nvague -- statistical knowledge, and (2) every statement in the language has a\nprobability. This conception of probability can be applied to very rich\nlanguages.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:36 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2728","submitter":"Silvio Ursic","authors":"Silvio Ursic","title":"Coefficients of Relations for Probabilistic Reasoning","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-156-162","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Definitions and notations with historical references are given for some\nnumerical coefficients commonly used to quantify relations among collections of\nobjects for the purpose of expressing approximate knowledge and probabilistic\nreasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:41 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2729","submitter":"Ben P. Wise","authors":"Ben P. Wise","title":"Satisfaction of Assumptions is a Weak Predictor of Performance","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-163-169","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper demonstrates a methodology for examining the accuracy of uncertain\ninference systems (UIS), after their parameters have been optimized, and does\nso for several common UIS's. This methodology may be used to test the accuracy\nwhen either the prior assumptions or updating formulae are not exactly\nsatisfied. Surprisingly, these UIS's were revealed to be no more accurate on\nthe average than a simple linear regression. Moreover, even on prior\ndistributions which were deliberately biased so as give very good accuracy,\nthey were less accurate than the simple probabilistic model which assumes\nmarginal independence between inputs. This demonstrates that the importance of\nupdating formulae can outweigh that of prior assumptions. Thus, when UIS's are\njudged by their final accuracy after optimization, we get completely different\nresults than when they are judged by whether or not their prior assumptions are\nperfectly satisfied.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:45 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2730","submitter":"Lei Xu","authors":"Lei Xu, Judea Pearl","title":"Structuring Causal Tree Models with Continuous Variables","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-170-179","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper considers the problem of invoking auxiliary, unobservable\nvariables to facilitate the structuring of causal tree models for a given set\nof continuous variables. Paralleling the treatment of bi-valued variables in\n[Pearl 1986], we show that if a collection of coupled variables are governed by\na joint normal distribution and a tree-structured representation exists, then\nboth the topology and all internal relationships of the tree can be uncovered\nby observing pairwise dependencies among the observed variables (i.e., the\nleaves of the tree). Furthermore, the conditions for normally distributed\nvariables are less restrictive than those governing bi-valued variables. The\nresult extends the applications of causal tree models which were found useful\nin evidential reasoning tasks.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:50 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2731","submitter":"John Yen","authors":"John Yen","title":"Implementing Evidential Reasoning in Expert Systems","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-180-188","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Dempster-Shafer theory has been extended recently for its application to\nexpert systems. However, implementing the extended D-S reasoning model in\nrule-based systems greatly complicates the task of generating informative\nexplanations. By implementing GERTIS, a prototype system for diagnosing\nrheumatoid arthritis, we show that two kinds of knowledge are essential for\nexplanation generation: (l) taxonomic class relationships between hypotheses\nand (2) pointers to the rules that significantly contribute to belief in the\nhypothesis. As a result, the knowledge represented in GERTIS is richer and more\ncomplex than that of conventional rule-based systems. GERTIS not only\ndemonstrates the feasibility of rule-based evidential-reasoning systems, but\nalso suggests ways to generate better explanations, and to explicitly represent\nvarious useful relationships among hypotheses and rules.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:47:55 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2732","submitter":"Wray L. Buntine","authors":"Wray L. Buntine","title":"Decision Tree Induction Systems: A Bayesian Analysis","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-190-197","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Decision tree induction systems are being used for knowledge acquisition in\nnoisy domains. This paper develops a subjective Bayesian interpretation of the\ntask tackled by these systems and the heuristic methods they use. It is argued\nthat decision tree systems implicitly incorporate a prior belief that the\nsimpler (in terms of decision tree complexity) of two hypotheses be preferred,\nall else being equal, and that they perform a greedy search of the space of\ndecision rules to find one in which there is strong posterior belief. A number\nof improvements to these systems are then suggested.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:00 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2733","submitter":"Richard A. Caruana","authors":"Richard A. Caruana","title":"The Automatic Training of Rule Bases that Use Numerical Uncertainty\n  Representations","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-198-204","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The use of numerical uncertainty representations allows better modeling of\nsome aspects of human evidential reasoning. It also makes knowledge acquisition\nand system development, test, and modification more difficult. We propose that\nwhere possible, the assignment and/or refinement of rule weights should be\nperformed automatically. We present one approach to performing this training -\nnumerical optimization - and report on the results of some preliminary tests in\ntraining rule bases. We also show that truth maintenance can be used to make\ntraining more efficient and ask some epistemological questions raised by\ntraining rule weights.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:04 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2734","submitter":"Norman C. Dalkey","authors":"Norman C. Dalkey","title":"The Inductive Logic of Information Systems","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-205-211","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An inductive logic can be formulated in which the elements are not\npropositions or probability distributions, but information systems. The logic\nis complete for information systems with binary hypotheses, i.e., it applies to\nall such systems. It is not complete for information systems with more than two\nhypotheses, but applies to a subset of such systems. The logic is inductive in\nthat conclusions are more informative than premises. Inferences using the\nformalism have a strong justification in terms of the expected value of the\nderived information system.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:09 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2735","submitter":"Stephen I. Gallant","authors":"Stephen I. Gallant","title":"Automated Generation of Connectionist Expert Systems for Problems\n  Involving Noise and Redundancy","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-212-221","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  When creating an expert system, the most difficult and expensive task is\nconstructing a knowledge base. This is particularly true if the problem\ninvolves noisy data and redundant measurements. This paper shows how to modify\nthe MACIE process for generating connectionist expert systems from training\nexamples so that it can accommodate noisy and redundant data. The basic idea is\nto dynamically generate appropriate training examples by constructing both a\n'deep' model and a noise model for the underlying problem. The use of\nwinner-take-all groups of variables is also discussed. These techniques are\nillustrated with a small example that would be very difficult for standard\nexpert system approaches.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:14 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2736","submitter":"George Rebane","authors":"George Rebane, Judea Pearl","title":"The Recovery of Causal Poly-Trees from Statistical Data","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-222-228","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Poly-trees are singly connected causal networks in which variables may arise\nfrom multiple causes. This paper develops a method of recovering ply-trees from\nempirically measured probability distributions of pairs of variables. The\nmethod guarantees that, if the measured distributions are generated by a causal\nprocess structured as a ply-tree then the topological structure of such tree\ncan be recovered precisely and, in addition, the causal directionality of the\nbranches can be determined up to the maximum extent possible. The method also\npinpoints the minimum (if any) external semantics required to determine the\ncausal relationships among the variables considered.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:18 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2737","submitter":"Ross D. Shachter","authors":"Ross D. Shachter, David M. Eddy, Vic Hasselblad, Robert Wolpert","title":"A Heuristic Bayesian Approach to Knowledge Acquisition: Application to\n  Analysis of Tissue-Type Plasminogen Activator","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-229-236","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper describes a heuristic Bayesian method for computing probability\ndistributions from experimental data, based upon the multivariate normal form\nof the influence diagram. An example illustrates its use in medical technology\nassessment. This approach facilitates the integration of results from different\nstudies, and permits a medical expert to make proper assessments without\nconsiderable statistical training.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:23 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2738","submitter":"Spencer Star","authors":"Spencer Star","title":"Theory-Based Inductive Learning: An Integration of Symbolic and\n  Quantitative Methods","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-237-248","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The objective of this paper is to propose a method that will generate a\ncausal explanation of observed events in an uncertain world and then make\ndecisions based on that explanation. Feedback can cause the explanation and\ndecisions to be modified. I call the method Theory-Based Inductive Learning\n(T-BIL). T-BIL integrates deductive learning, based on a technique called\nExplanation-Based Generalization (EBG) from the field of machine learning, with\ninductive learning methods from Bayesian decision theory. T-BIL takes as inputs\n(1) a decision problem involving a sequence of related decisions over time, (2)\na training example of a solution to the decision problem in one period, and (3)\nthe domain theory relevant to the decision problem. T-BIL uses these inputs to\nconstruct a probabilistic explanation of why the training example is an\ninstance of a solution to one stage of the sequential decision problem. This\nexplanation is then generalized to cover a more general class of instances and\nis used as the basis for making the next-stage decisions. As the outcomes of\neach decision are observed, the explanation is revised, which in turn affects\nthe subsequent decisions. A detailed example is presented that uses T-BIL to\nsolve a very general stochastic adaptive control problem for an autonomous\nmobile robot.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:28 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2739","submitter":"Piero P. Bonissone","authors":"Piero P. Bonissone","title":"Using T-Norm Based Uncertainty Calculi in a Naval Situation Assessment\n  Application","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-250-261","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  RUM (Reasoning with Uncertainty Module), is an integrated software tool based\non a KEE, a frame system implemented in an object oriented language. RUM's\narchitecture is composed of three layers: representation, inference, and\ncontrol. The representation layer is based on frame-like data structures that\ncapture the uncertainty information used in the inference layer and the\nuncertainty meta-information used in the control layer. The inference layer\nprovides a selection of five T-norm based uncertainty calculi with which to\nperform the intersection, detachment, union, and pooling of information. The\ncontrol layer uses the meta-information to select the appropriate calculus for\neach context and to resolve eventual ignorance or conflict in the information.\nThis layer also provides a context mechanism that allows the system to focus on\nthe relevant portion of the knowledge base, and an uncertain-belief revision\nsystem that incrementally updates the certainty values of well-formed formulae\n(wffs) in an acyclic directed deduction graph. RUM has been tested and\nvalidated in a sequence of experiments in both naval and aerial situation\nassessment (SA), consisting of correlating reports and tracks, locating and\nclassifying platforms, and identifying intents and threats. An example of naval\nsituation assessment is illustrated. The testbed environment for developing\nthese experiments has been provided by LOTTA, a symbolic simulator implemented\nin Flavors. This simulator maintains time-varying situations in a multi-player\nantagonistic game where players must make decisions in light of uncertain and\nincomplete data. RUM has been used to assist one of the LOTTA players to\nperform the SA task.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:34 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2740","submitter":"Yizong Cheng","authors":"Yizong Cheng, Rangasami L. Kashyap","title":"A Study of Associative Evidential Reasoning","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-262-269","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Evidential reasoning is cast as the problem of simplifying the\nevidence-hypothesis relation and constructing combination formulas that possess\ncertain testable properties. Important classes of evidence as identifiers,\nannihilators, and idempotents and their roles in determining binary operations\non intervals of reals are discussed. The appropriate way of constructing\nformulas for combining evidence and their limitations, for instance, in\nrobustness, are presented.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:39 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2741","submitter":"I. R. Goodman","authors":"I. R. Goodman","title":"A Measure-Free Approach to Conditioning","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-270-277","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In an earlier paper, a new theory of measurefree \"conditional\" objects was\npresented. In this paper, emphasis is placed upon the motivation of the theory.\nThe central part of this motivation is established through an example involving\na knowledge-based system. In order to evaluate combination of evidence for this\nsystem, using observed data, auxiliary at tribute and diagnosis variables, and\ninference rules connecting them, one must first choose an appropriate algebraic\nlogic description pair (ALDP): a formal language or syntax followed by a\ncompatible logic or semantic evaluation (or model). Three common choices- for\nthis highly non-unique choice - are briefly discussed, the logics being\nClassical Logic, Fuzzy Logic, and Probability Logic. In all three,the key\noperator representing implication for the inference rules is interpreted as the\noften-used disjunction of a negation (b => a) = (b'v a), for any events a,b.\n  However, another reasonable interpretation of the implication operator is\nthrough the familiar form of probabilistic conditioning. But, it can be shown -\nquite surprisingly - that the ALDP corresponding to Probability Logic cannot be\nused as a rigorous basis for this interpretation! To fill this gap, a new ALDP\nis constructed consisting of \"conditional objects\", extending ordinary\nProbability Logic, and compatible with the desired conditional probability\ninterpretation of inference rules. It is shown also that this choice of ALDP\nleads to feasible computations for the combination of evidence evaluation in\nthe example. In addition, a number of basic properties of conditional objects\nand the resulting Conditional Probability Logic are given, including a\ncharacterization property and a developed calculus of relations.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:45 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2742","submitter":"Peter Haddawy","authors":"Peter Haddawy, Alan M. Frisch","title":"Convergent Deduction for Probabilistic Logic","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-278-286","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper discusses the semantics and proof theory of Nilsson's\nprobabilistic logic, outlining both the benefits of its well-defined model\ntheory and the drawbacks of its proof theory. Within Nilsson's semantic\nframework, we derive a set of inference rules which are provably sound. The\nresulting proof system, in contrast to Nilsson's approach, has the important\nfeature of convergence - that is, the inference process proceeds by computing\nincreasingly narrow probability intervals which converge from above and below\non the smallest entailed probability interval. Thus the procedure can be\nstopped at any time to yield partial information concerning the smallest\nentailed interval.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:49 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2743","submitter":"Ze-Nian Li","authors":"Ze-Nian Li","title":"Comparisons of Reasoning Mechanisms for Computer Vision","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-287-294","categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An evidential reasoning mechanism based on the Dempster-Shafer theory of\nevidence is introduced. Its performance in real-world image analysis is\ncompared with other mechanisms based on the Bayesian formalism and a simple\nweight combination method.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:54 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2744","submitter":"Donald H. Mitchell","authors":"Donald H. Mitchell, Steven A. Harp, David K. Simkin","title":"A Knowledge Engineer's Comparison of Three Evidence Aggregation Methods","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-297-304","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The comparisons of uncertainty calculi from the last two Uncertainty\nWorkshops have all used theoretical probabilistic accuracy as the sole metric.\nWhile mathematical correctness is important, there are other factors which\nshould be considered when developing reasoning systems. These other factors\ninclude, among other things, the error in uncertainty measures obtainable for\nthe problem and the effect of this error on the performance of the resulting\nsystem.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:48:59 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2745","submitter":"Eric Neufeld","authors":"Eric Neufeld, David L Poole","title":"Towards Solving the Multiple Extension Problem: Combining Defaults and\n  Probabilities","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-305-312","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The multiple extension problem arises frequently in diagnostic and default\ninference. That is, we can often use any of a number of sets of defaults or\npossible hypotheses to explain observations or make Predictions. In default\ninference, some extensions seem to be simply wrong and we use qualitative\ntechniques to weed out the unwanted ones. In the area of diagnosis, however,\nthe multiple explanations may all seem reasonable, however improbable. Choosing\namong them is a matter of quantitative preference. Quantitative preference\nworks well in diagnosis when knowledge is modelled causally. Here we suggest a\nframework that combines probabilities and defaults in a single unified\nframework that retains the semantics of diagnosis as construction of\nexplanations from a fixed set of possible hypotheses. We can then compute\nprobabilities incrementally as we construct explanations. Here we describe a\nbranch and bound algorithm that maintains a set of all partial explanations\nwhile exploring a most promising one first. A most probable explanation is\nfound first if explanations are partially ordered.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:04 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2746","submitter":"Richard M. Tong","authors":"Richard M. Tong, Lee A. Appelbaum","title":"Problem Structure and Evidential Reasoning","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-313-320","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In our previous series of studies to investigate the role of evidential\nreasoning in the RUBRIC system for full-text document retrieval (Tong et al.,\n1985; Tong and Shapiro, 1985; Tong and Appelbaum, 1987), we identified the\nimportant role that problem structure plays in the overall performance of the\nsystem. In this paper, we focus on these structural elements (which we now call\n\"semantic structure\") and show how explicit consideration of their properties\nreduces what previously were seen as difficult evidential reasoning problems to\nmore tractable questions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:09 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2747","submitter":"Michael P. Wellman","authors":"Michael P. Wellman, David Heckerman","title":"The Role of Calculi in Uncertain Inference Systems","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-321-331","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Much of the controversy about methods for automated decision making has\nfocused on specific calculi for combining beliefs or propagating uncertainty.\nWe broaden the debate by (1) exploring the constellation of secondary tasks\nsurrounding any primary decision problem, and (2) identifying knowledge\nengineering concerns that present additional representational tradeoffs. We\nargue on pragmatic grounds that the attempt to support all of these tasks\nwithin a single calculus is misguided. In the process, we note several\nuncertain reasoning objectives that conflict with the Bayesian ideal of\ncomplete specification of probabilities and utilities. In response, we advocate\ntreating the uncertainty calculus as an object language for reasoning\nmechanisms that support the secondary tasks. Arguments against Bayesian\ndecision theory are weakened when the calculus is relegated to this role.\nArchitectures for uncertainty handling that take statements in the calculus as\nobjects to be reasoned about offer the prospect of retaining normative status\nwith respect to decision making while supporting the other tasks in uncertain\nreasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:15 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2748","submitter":"Ben P. Wise","authors":"Ben P. Wise, Bruce M. Perrin, David S. Vaughan, Robert M. Yadrick","title":"The Role of Tuning Uncertain Inference Systems","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-332-339","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study examined the effects of \"tuning\" the parameters of the incremental\nfunction of MYCIN, the independent function of PROSPECTOR, a probability model\nthat assumes independence, and a simple additive linear equation. me parameters\nof each of these models were optimized to provide solutions which most nearly\napproximated those from a full probability model for a large set of simple\nnetworks. Surprisingly, MYCIN, PROSPECTOR, and the linear equation performed\nequivalently; the independence model was clearly more accurate on the networks\nstudied.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:20 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2749","submitter":"Minchuan Zhang","authors":"Minchuan Zhang, Su-shing Chen","title":"Evidential Reasoning in Image Understanding","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-340-346","categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we present some results of evidential reasoning in\nunderstanding multispectral images of remote sensing systems. The\nDempster-Shafer approach of combination of evidences is pursued to yield\ncontextual classification results, which are compared with previous results of\nthe Bayesian context free classification, contextual classifications of dynamic\nprogramming and stochastic relaxation approaches.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:25 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2750","submitter":"Lashon B. Booker","authors":"Lashon B. Booker, Naveen Hota, Gavin Hemphill","title":"Implementing a Bayesian Scheme for Revising Belief Commitments","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-348-354","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Our previous work on classifying complex ship images [1,2] has evolved into\nan effort to develop software tools for building and solving generic\nclassification problems. Managing the uncertainty associated with feature data\nand other evidence is an important issue in this endeavor. Bayesian techniques\nfor managing uncertainty [7,12,13] have proven to be useful for managing\nseveral of the belief maintenance requirements of classification problem\nsolving. One such requirement is the need to give qualitative explanations of\nwhat is believed. Pearl [11] addresses this need by computing what he calls a\nbelief commitment-the most probable instantiation of all hypothesis variables\ngiven the evidence available. Before belief commitments can be computed, the\nstraightforward implementation of Pearl's procedure involves finding an\nanalytical solution to some often difficult optimization problems. We describe\nan efficient implementation of this procedure using tensor products that solves\nthese problems enumeratively and avoids the need for case by case analysis. The\nprocedure is thereby made more practical to use in the general case.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:30 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2751","submitter":"John S. Breese","authors":"John S. Breese, Edison Tse","title":"Integrating Logical and Probabilistic Reasoning for Decision Making","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-355-362","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe a representation and a set of inference methods that combine\nlogic programming techniques with probabilistic network representations for\nuncertainty (influence diagrams). The techniques emphasize the dynamic\nconstruction and solution of probabilistic and decision-theoretic models for\ncomplex and uncertain domains. Given a query, a logical proof is produced if\npossible; if not, an influence diagram based on the query and the knowledge of\nthe decision domain is produced and subsequently solved. A uniform declarative,\nfirst-order, knowledge representation is combined with a set of integrated\ninference procedures for logical, probabilistic, and decision-theoretic\nreasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:35 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2752","submitter":"Stephen Chiu","authors":"Stephen Chiu, Masaki Togai","title":"Compiling Fuzzy Logic Control Rules to Hardware Implementations","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-363-371","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A major aspect of human reasoning involves the use of approximations.\nParticularly in situations where the decision-making process is under stringent\ntime constraints, decisions are based largely on approximate, qualitative\nassessments of the situations. Our work is concerned with the application of\napproximate reasoning to real-time control. Because of the stringent processing\nspeed requirements in such applications, hardware implementations of fuzzy\nlogic inferencing are being pursued. We describe a programming environment for\ntranslating fuzzy control rules into hardware realizations. Two methods of\nhardware realizations are possible. The First is based on a special purpose\nchip for fuzzy inferencing. The second is based on a simple memory chip. The\nability to directly translate a set of decision rules into hardware\nimplementations is expected to make fuzzy control an increasingly practical\napproach to the control of complex systems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:40 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2753","submitter":"Paul Cohen","authors":"Paul Cohen","title":"Steps Towards Programs that Manage Uncertainty","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-372-379","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Reasoning under uncertainty in Al hats come to mean assessing the credibility\nof hypotheses inferred from evidence. But techniques for assessing credibility\ndo not tell a problem solver what to do when it is uncertain. This is the focus\nof our current research. We have developed a medical expert system called MUM,\nfor Managing Uncertainty in Medicine, that plans diagnostic sequences of\nquestions, tests, and treatments. This paper describes the kinds of problems\nthat MUM was designed to solve and gives a brief description of its\narchitecture. More recently, we have built an empty version of MUM called MU,\nand used it to reimplement MUM and a small diagnostic system for plant\npathology. The latter part of the paper describes the features of MU that make\nit appropriate for building expert systems that manage uncertainty.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:44 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2754","submitter":"Gregory F. Cooper","authors":"Gregory F. Cooper","title":"An Algorithm for Computing Probabilistic Propositions","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-380-385","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A method for computing probabilistic propositions is presented. It assumes\nthe availability of a single external routine for computing the probability of\none instantiated variable, given a conjunction of other instantiated variables.\nIn particular, the method allows belief network algorithms to calculate general\nprobabilistic propositions over nodes in the network. Although in the worst\ncase the time complexity of the method is exponential in the size of a query,\nit is polynomial in the size of a number of common types of queries.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:49 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2755","submitter":"Bruce D'Ambrosio","authors":"Bruce D'Ambrosio","title":"Combining Symbolic and Numeric Approaches to Uncertainty Management","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-386-393","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A complete approach to reasoning under uncertainty requires support for\nincremental and interactive formulation and revision of, as well as reasoning\nwith, models of the problem domain capable of representing our uncertainty. We\npresent a hybrid reasoning scheme which combines symbolic and numeric methods\nfor uncertainty management to provide efficient and effective support for each\nof these tasks. The hybrid is based on symbolic techniques adapted from\nAssumption-based Truth Maintenance systems (ATMS), combined with numeric\nmethods adapted from the Dempster/Shafer theory of evidence, as extended in\nBaldwin's Support Logic Programming system. The hybridization is achieved by\nviewing an ATMS as a symbolic algebra system for uncertainty calculations. This\ntechnique has several major advantages over conventional methods for performing\ninference with numeric certainty estimates in addition to the ability to\ndynamically determine hypothesis spaces, including improved management of\ndependent and partially independent evidence, faster run-time evaluation of\npropositional certainties, the ability to query the certainty value of a\nproposition from multiple perspectives, and the ability to incrementally extend\nor revise domain models.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:54 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2756","submitter":"Christopher Elsaesser","authors":"Christopher Elsaesser","title":"Explanation of Probabilistic Inference for Decision Support Systems","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-394-403","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An automated explanation facility for Bayesian conditioning aimed at\nimproving user acceptance of probability-based decision support systems has\nbeen developed. The domain-independent facility is based on an information\nprocessing perspective on reasoning about conditional evidence that accounts\nboth for biased and normative inferences. Experimental results indicate that\nthe facility is both acceptable to naive users and effective in improving\nunderstanding.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:49:58 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2757","submitter":"Greg Hager","authors":"Greg Hager, Max Mintz","title":"Estimation Procedures for Robust Sensor Control","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-404-411","categories":"cs.SY cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many robotic sensor estimation problems can characterized in terms of\nnonlinear measurement systems. These systems are contaminated with noise and\nmay be underdetermined from a single observation. In order to get reliable\nestimation results, the system must choose views which result in an\noverdetermined system. This is the sensor control problem. Accurate and\nreliable sensor control requires an estimation procedure which yields both\nestimates and measures of its own performance. In the case of nonlinear\nmeasurement systems, computationally simple closed-form estimation solutions\nmay not exist. However, approximation techniques provide viable alternatives.\nIn this paper, we evaluate three estimation techniques: the extended Kalman\nfilter, a discrete Bayes approximation, and an iterative Bayes approximation.\nWe present mathematical results and simulation statistics illustrating\noperating conditions where the extended Kalman filter is inappropriate for\nsensor control, and discuss issues in the use of the discrete Bayes\napproximation.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:50:04 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2758","submitter":"Ross D. Shachter","authors":"Ross D. Shachter, Leonard Bertrand","title":"Efficient Inference on Generalized Fault Diagrams","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-413-420","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The generalized fault diagram, a data structure for failure analysis based on\nthe influence diagram, is defined. Unlike the fault tree, this structure allows\nfor dependence among the basic events and replicated logical elements. A\nheuristic procedure is developed for efficient processing of these structures.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:50:09 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.2759","submitter":"Eric J. Horvitz","authors":"Eric J. Horvitz","title":"Reasoning About Beliefs and Actions Under Computational Resource\n  Constraints","comments":"Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)","journal-ref":null,"doi":null,"report-no":"UAI-P-1987-PG-429-447","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Although many investigators affirm a desire to build reasoning systems that\nbehave consistently with the axiomatic basis defined by probability theory and\nutility theory, limited resources for engineering and computation can make a\ncomplete normative analysis impossible. We attempt to move discussion beyond\nthe debate over the scope of problems that can be handled effectively to cases\nwhere it is clear that there are insufficient computational resources to\nperform an analysis deemed as complete. Under these conditions, we stress the\nimportance of considering the expected costs and benefits of applying\nalternative approximation procedures and heuristics for computation and\nknowledge acquisition. We discuss how knowledge about the structure of user\nutility can be used to control value tradeoffs for tailoring inference to\nalternative contexts. We address the notion of real-time rationality, focusing\non the application of knowledge about the expected timewise-refinement\nabilities of reasoning strategies to balance the benefits of additional\ncomputation with the costs of acting with a partial result. We discuss the\nbenefits of applying decision theory to control the solution of difficult\nproblems given limitations and uncertainty in reasoning resources.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:50:20 GMT"}],"update_date":"2013-04-11"}
{"id":"1304.3075","submitter":"Shoshana Abel","authors":"Shoshana Abel","title":"Application of Evidential Reasoning to Helicopter Flight Path Control","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-1-6","categories":"cs.AI cs.RO cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a methodology for research and development of the\ninferencing and knowledge representation aspects of an Expert System approach\nfor performing reasoning under uncertainty in support of a real time vehicle\nguidance and navigation system. Such a system could be of major benefit for\nnon-terrain following low altitude flight systems operating in foreign hostile\nenvironments such as might be experienced by NOE helicopter or similar mission\ncraft. An innovative extension of the evidential reasoning methodology, termed\nthe Sum-and-Lattice-Points Method, has been developed. The research and\ndevelopment effort presented in this paper consists of a formal mathematical\ndevelopment of the Sum-and-Lattice-Points Method, its formulation and\nrepresentation in a parallel environment, prototype software development of the\nmethod within an expert system, and initial testing of the system within the\nconfines of the vehicle guidance system.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:00 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3076","submitter":"Stephen W. Barth","authors":"Stephen W. Barth, Steven W. Norton","title":"Knowledge Engineering Within A Generalized Bayesian Framework","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-7-16","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  During the ongoing debate over the representation of uncertainty in\nArtificial Intelligence, Cheeseman, Lemmer, Pearl, and others have argued that\nprobability theory, and in particular the Bayesian theory, should be used as\nthe basis for the inference mechanisms of Expert Systems dealing with\nuncertainty. In order to pursue the issue in a practical setting, sophisticated\ntools for knowledge engineering are needed that allow flexible and\nunderstandable interaction with the underlying knowledge representation\nschemes. This paper describes a Generalized Bayesian framework for building\nexpert systems which function in uncertain domains, using algorithms proposed\nby Lemmer. It is neither rule-based nor frame-based, and requires a new system\nof knowledge engineering tools. The framework we describe provides a\nknowledge-based system architecture with an inference engine, explanation\ncapability, and a unique aid for building consistent knowledge bases.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:06 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3077","submitter":"Moshe Ben-Bassat","authors":"Moshe Ben-Bassat","title":"Taxonomy, Structure, and Implementation of Evidential Reasoning","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-17-28","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The fundamental elements of evidential reasoning problems are described,\nfollowed by a discussion of the structure of various types of problems.\nBayesian inference networks and state space formalism are used as the tool for\nproblem representation.\n  A human-oriented decision making cycle for solving evidential reasoning\nproblems is described and illustrated for a military situation assessment\nproblem. The implementation of this cycle may serve as the basis for an expert\nsystem shell for evidential reasoning; i.e. a situation assessment processor.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:12 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3078","submitter":"Lashon B. Booker","authors":"Lashon B. Booker, Naveen Hota","title":"Probabilistic Reasoning About Ship Images","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-29-36","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One of the most important aspects of current expert systems technology is the\nability to make causal inferences about the impact of new evidence. When the\ndomain knowledge and problem knowledge are uncertain and incomplete Bayesian\nreasoning has proven to be an effective way of forming such inferences [3,4,8].\nWhile several reasoning schemes have been developed based on Bayes Rule, there\nhas been very little work examining the comparative effectiveness of these\nschemes in a real application. This paper describes a knowledge based system\nfor ship classification [1], originally developed using the PROSPECTOR updating\nmethod [2], that has been reimplemented to use the inference procedure\ndeveloped by Pearl and Kim [4,5]. We discuss our reasons for making this\nchange, the implementation of the new inference engine, and the comparative\nperformance of the two versions of the system.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:17 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3079","submitter":"Kaihu Chen","authors":"Kaihu Chen","title":"Towards The Inductive Acquisition of Temporal Knowledge","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-37-42","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The ability to predict the future in a given domain can be acquired by\ndiscovering empirically from experience certain temporal patterns that tend to\nrepeat unerringly. Previous works in time series analysis allow one to make\nquantitative predictions on the likely values of certain linear variables.\nSince certain types of knowledge are better expressed in symbolic forms, making\nqualitative predictions based on symbolic representations require a different\napproach. A domain independent methodology called TIM (Time based Inductive\nMachine) for discovering potentially uncertain temporal patterns from real time\nobservations using the technique of inductive inference is described here.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:22 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3080","submitter":"Su-shing Chen","authors":"Su-shing Chen","title":"Some Extensions of Probabilistic Logic","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-43-48","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In [12], Nilsson proposed the probabilistic logic in which the truth values\nof logical propositions are probability values between 0 and 1. It is\napplicable to any logical system for which the consistency of a finite set of\npropositions can be established. The probabilistic inference scheme reduces to\nthe ordinary logical inference when the probabilities of all propositions are\neither 0 or 1. This logic has the same limitations of other probabilistic\nreasoning systems of the Bayesian approach. For common sense reasoning,\nconsistency is not a very natural assumption. We have some well known examples:\n{Dick is a Quaker, Quakers are pacifists, Republicans are not pacifists, Dick\nis a Republican}and {Tweety is a bird, birds can fly, Tweety is a penguin}. In\nthis paper, we shall propose some extensions of the probabilistic logic. In the\nsecond section, we shall consider the space of all interpretations, consistent\nor not. In terms of frames of discernment, the basic probability assignment\n(bpa) and belief function can be defined. Dempster's combination rule is\napplicable. This extension of probabilistic logic is called the evidential\nlogic in [ 1]. For each proposition s, its belief function is represented by an\ninterval [Spt(s), Pls(s)]. When all such intervals collapse to single points,\nthe evidential logic reduces to probabilistic logic (in the generalized version\nof not necessarily consistent interpretations). Certainly, we get Nilsson's\nprobabilistic logic by further restricting to consistent interpretations. In\nthe third section, we shall give a probabilistic interpretation of\nprobabilistic logic in terms of multi-dimensional random variables. This\ninterpretation brings the probabilistic logic into the framework of probability\ntheory. Let us consider a finite set S = {sl, s2, ..., Sn) of logical\npropositions. Each proposition may have true or false values; and may be\nconsidered as a random variable. We have a probability distribution for each\nproposition. The e-dimensional random variable (sl,..., Sn) may take values in\nthe space of all interpretations of 2n binary vectors. We may compute absolute\n(marginal), conditional and joint probability distributions. It turns out that\nthe permissible probabilistic interpretation vector of Nilsson [12] consists of\nthe joint probabilities of S. Inconsistent interpretations will not appear, by\nsetting their joint probabilities to be zeros. By summing appropriate joint\nprobabilities, we get probabilities of individual propositions or subsets of\npropositions. Since the Bayes formula and other techniques are valid for\ne-dimensional random variables, the probabilistic logic is actually very close\nto the Bayesian inference schemes. In the last section, we shall consider a\nrelaxation scheme for probabilistic logic. In this system, not only new\nevidences will update the belief measures of a collection of propositions, but\nalso constraint satisfaction among these propositions in the relational network\nwill revise these measures. This mechanism is similar to human reasoning which\nis an evaluative process converging to the most satisfactory result. The main\nidea arises from the consistent labeling problem in computer vision. This\nmethod is originally applied to scene analysis of line drawings. Later, it is\napplied to matching, constraint satisfaction and multi sensor fusion by several\nauthors [8], [16] (and see references cited there). Recently, this method is\nused in knowledge aggregation by Landy and Hummel [9].\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:27 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3081","submitter":"Ping-Chung Chi","authors":"Ping-Chung Chi, Dana Nau","title":"Predicting The Performance of Minimax and Product in Game-Tree","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-49-56","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The discovery that the minimax decision rule performs poorly in some games\nhas sparked interest in possible alternatives to minimax. Until recently, the\nonly games in which minimax was known to perform poorly were games which were\nmainly of theoretical interest. However, this paper reports results showing\npoor performance of minimax in a more common game called kalah. For the kalah\ngames tested, a non-minimax decision rule called the product rule performs\nsignificantly better than minimax.\n  This paper also discusses a possible way to predict whether or not minimax\nwill perform well in a game when compared to product. A parameter called the\nrate of heuristic flaw (rhf) has been found to correlate positively with the.\nperformance of product against minimax. Both analytical and experimental\nresults are given that appear to support the predictive power of rhf.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:32 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3082","submitter":"A. Julian Craddock","authors":"A. Julian Craddock, Roger A. Browse","title":"Reasoning With Uncertain Knowledge","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-57-62","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A model of knowledge representation is described in which propositional facts\nand the relationships among them can be supported by other facts. The set of\nknowledge which can be supported is called the set of cognitive units, each\nhaving associated descriptions of their explicit and implicit support\nstructures, summarizing belief and reliability of belief. This summary is\nprecise enough to be useful in a computational model while remaining\ndescriptive of the underlying symbolic support structure. When a fact supports\nanother supportive relationship between facts we call this meta-support. This\nfacilitates reasoning about both the propositional knowledge. and the support\nstructures underlying it.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:38 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3083","submitter":"Norman C. Dalkey","authors":"Norman C. Dalkey","title":"Models vs. Inductive Inference for Dealing With Probabilistic Knowledge","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-63-70","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Two different approaches to dealing with probabilistic knowledge are examined\n-models and inductive inference. Examples of the first are: influence diagrams\n[1], Bayesian networks [2], log-linear models [3, 4]. Examples of the second\nare: games-against nature [5, 6] varieties of maximum-entropy methods [7, 8,\n9], and the author's min-score induction [10]. In the modeling approach, the\nbasic issue is manageability, with respect to data elicitation and computation.\nThus, it is assumed that the pertinent set of users in some sense knows the\nrelevant probabilities, and the problem is to format that knowledge in a way\nthat is convenient to input and store and that allows computation of the\nanswers to current questions in an expeditious fashion. The basic issue for the\ninductive approach appears at first sight to be very different. In this\napproach it is presumed that the relevant probabilities are only partially\nknown, and the problem is to extend that incomplete information in a reasonable\nway to answer current questions. Clearly, this approach requires that some form\nof induction be invoked. Of course, manageability is an important additional\nconcern. Despite their seeming differences, the two approaches have a fair\namount in common, especially with respect to the structural framework they\nemploy. Roughly speaking, this framework involves identifying clusters of\nvariables which strongly interact, establishing marginal probability\ndistributions on the clusters, and extending the subdistributions to a more\ncomplete distribution, usually via a product formalism. The product extension\nis justified on the modeling approach in terms of assumed conditional\nindependence; in the inductive approach the product form arises from an\ninductive rule.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:44 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3084","submitter":"Brian Falkenhainer","authors":"Brian Falkenhainer","title":"Towards a General-Purpose Belief Maintenance System","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-71-76","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There currently exists a gap between the theories proposed by the probability\nand uncertainty and the needs of Artificial Intelligence research. These\ntheories primarily address the needs of expert systems, using knowledge\nstructures which must be pre-compiled and remain static in structure during\nruntime. Many Al systems require the ability to dynamically add and remove\nparts of the current knowledge structure (e.g., in order to examine what the\nworld would be like for different causal theories). This requires more\nflexibility than existing uncertainty systems display. In addition, many Al\nresearchers are only interested in using \"probabilities\" as a means of\nobtaining an ordering, rather than attempting to derive an accurate\nprobabilistic account of a situation. This indicates the need for systems which\nstress ease of use and don't require extensive probability information when one\ncannot (or doesn't wish to) provide such information. This paper attempts to\nhelp reconcile the gap between approaches to uncertainty and the needs of many\nAI systems by examining the control issues which arise, independent of a\nparticular uncertainty calculus. when one tries to satisfy these needs. Truth\nMaintenance Systems have been used extensively in problem solving tasks to help\norganize a set of facts and detect inconsistencies in the believed state of the\nworld. These systems maintain a set of true/false propositions and their\nassociated dependencies. However, situations often arise in which we are unsure\nof certain facts or in which the conclusions we can draw from available\ninformation are somewhat uncertain. The non-monotonic TMS 12] was an attempt at\nreasoning when all the facts are not known, but it fails to take into account\ndegrees of belief and how available evidence can combine to strengthen a\nparticular belief. This paper addresses the problem of probabilistic reasoning\nas it applies to Truth Maintenance Systems. It describes a belief Maintenance\nSystem that manages a current set of beliefs in much the same way that a TMS\nmanages a set of true/false propositions. If the system knows that belief in\nfact is dependent in some way upon belief in fact2, then it automatically\nmodifies its belief in facts when new information causes a change in belief of\nfact2. It models the behavior of a TMS, replacing its 3-valued logic (true,\nfalse, unknown) with an infinite valued logic, in such a way as to reduce to a\nstandard TMS if all statements are given in absolute true/false terms. Belief\nMaintenance Systems can, therefore, be thought of as a generalization of Truth\nMaintenance Systems, whose possible reasoning tasks are a superset of those for\na TMS.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:49 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3085","submitter":"B. R. Fox","authors":"B. R. Fox, Karl G. Kempf","title":"Planning, Scheduling, and Uncertainty in the Sequence of Future Events","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-77-84","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Scheduling in the factory setting is compounded by computational complexity\nand temporal uncertainty. Together, these two factors guarantee that the\nprocess of constructing an optimal schedule will be costly and the chances of\nexecuting that schedule will be slight. Temporal uncertainty in the task\nexecution time can be offset by several methods: eliminate uncertainty by\ncareful engineering, restore certainty whenever it is lost, reduce the\nuncertainty by using more accurate sensors, and quantify and circumscribe the\nremaining uncertainty. Unfortunately, these methods focus exclusively on the\nsources of uncertainty and fail to apply knowledge of the tasks which are to be\nscheduled. A complete solution must adapt the schedule of activities to be\nperformed according to the evolving state of the production world. The example\nof vision-directed assembly is presented to illustrate that the principle of\nleast commitment, in the creation of a plan, in the representation of a\nschedule, and in the execution of a schedule, enables a robot to operate\nintelligently and efficiently, even in the presence of considerable uncertainty\nin the sequence of future events.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:51:55 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3086","submitter":"Pascal Fua","authors":"Pascal Fua","title":"Deriving And Combining Continuous Possibility Functions in the Framework\n  of Evidential Reasoning","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-85-90","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To develop an approach to utilizing continuous statistical information within\nthe Dempster- Shafer framework, we combine methods proposed by Strat and by\nShafero We first derive continuous possibility and mass functions from\nprobability-density functions. Then we propose a rule for combining such\nevidence that is simpler and more efficiently computed than Dempster's rule. We\ndiscuss the relationship between Dempster's rule and our proposed rule for\ncombining evidence over continuous frames.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:00 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3087","submitter":"Benjamin N. Grosof","authors":"Benjamin N. Grosof","title":"Non-Monotonicity in Probabilistic Reasoning","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-91-98","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We start by defining an approach to non-monotonic probabilistic reasoning in\nterms of non-monotonic categorical (true-false) reasoning. We identify a type\nof non-monotonic probabilistic reasoning, akin to default inheritance, that is\ncommonly found in practice, especially in \"evidential\" and \"Bayesian\"\nreasoning. We formulate this in terms of the Maximization of Conditional\nIndependence (MCI), and identify a variety of applications for this sort of\ndefault. We propose a formalization using Pointwise Circumscription. We compare\nMCI to Maximum Entropy, another kind of non-monotonic principle, and conclude\nby raising a number of open questions\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:05 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3088","submitter":"Greg Hager","authors":"Greg Hager, Hugh F. Durrant-Whyte","title":"Information and Multi-Sensor Coordination","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-99-108","categories":"cs.SY cs.AI cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The control and integration of distributed, multi-sensor perceptual systems\nis a complex and challenging problem. The observations or opinions of different\nsensors are often disparate incomparable and are usually only partial views.\nSensor information is inherently uncertain and in addition the individual\nsensors may themselves be in error with respect to the system as a whole. The\nsuccessful operation of a multi-sensor system must account for this uncertainty\nand provide for the aggregation of disparate information in an intelligent and\nrobust manner. We consider the sensors of a multi-sensor system to be members\nor agents of a team, able to offer opinions and bargain in group decisions. We\nwill analyze the coordination and control of this structure using a theory of\nteam decision-making. We present some new analytic results on multi-sensor\naggregation and detail a simulation which we use to investigate our ideas. This\nsimulation provides a basis for the analysis of complex agent structures\ncooperating in the presence of uncertainty. The results of this study are\ndiscussed with reference to multi-sensor robot systems, distributed Al and\ndecision making under uncertainty.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:12 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3089","submitter":"Shohara L. Hardt","authors":"Shohara L. Hardt","title":"Flexible Interpretations: A Computational Model for Dynamic Uncertainty\n  Assessment","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-109-114","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The investigations reported in this paper center on the process of dynamic\nuncertainty assessment during interpretation tasks in real domain. In\nparticular, we are interested here in the nature of the control structure of\ncomputer programs that can support multiple interpretation and smooth\ntransitions between them, in real time. Each step of the processing involves\nthe interpretation of one input item and the appropriate re-establishment of\nthe system's confidence of the correctness of its interpretation(s).\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:17 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3090","submitter":"David Heckerman","authors":"David Heckerman, Eric J. Horvitz","title":"The Myth of Modularity in Rule-Based Systems","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-115-122","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we examine the concept of modularity, an often cited advantage\nof the ruled-based representation methodology. We argue that the notion of\nmodularity consists of two distinct concepts which we call syntactic modularity\nand semantic modularity. We argue that when reasoning under certainty, it is\nreasonable to regard the rule-based approach as both syntactically and\nsemantically modular. However, we argue that in the case of plausible\nreasoning, rules are syntactically modular but are rarely semantically modular.\nTo illustrate this point, we examine a particular approach for managing\nuncertainty in rule-based systems called the MYCIN certainty factor model. We\nformally define the concept of semantic modularity with respect to the\ncertainty factor model and discuss logical consequences of the definition. We\nshow that the assumption of semantic modularity imposes strong restrictions on\nrules in a knowledge base. We argue that such restrictions are rarely valid in\npractical applications. Finally, we suggest how the concept of semantic\nmodularity can be relaxed in a manner that makes it appropriate for plausible\nreasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:23 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3091","submitter":"David Heckerman","authors":"David Heckerman","title":"An Axiomatic Framework for Belief Updates","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-123-128","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the 1940's, a physicist named Cox provided the first formal justification\nfor the axioms of probability based on the subjective or Bayesian\ninterpretation. He showed that if a measure of belief satisfies several\nfundamental properties, then the measure must be some monotonic transformation\nof a probability. In this paper, measures of change in belief or belief updates\nare examined. In the spirit of Cox, properties for a measure of change in\nbelief are enumerated. It is shown that if a measure satisfies these\nproperties, it must satisfy other restrictive conditions. For example, it is\nshown that belief updates in a probabilistic context must be equal to some\nmonotonic transformation of a likelihood ratio. It is hoped that this formal\nexplication of the belief update paradigm will facilitate critical discussion\nand useful extensions of the approach.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:28 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3092","submitter":"Steven J. Henkind","authors":"Steven J. Henkind","title":"Imprecise Meanings as a Cause of Uncertainty in Medical Knowledge-Based\n  Systems","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-129-134","categories":"cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There has been a considerable amount of work on uncertainty in\nknowledge-based systems. This work has generally been concerned with\nuncertainty arising from the strength of inferences and the weight of evidence.\nIn this paper we discuss another type of uncertainty: that which is due to\nimprecision in the underlying primitives used to represent the knowledge of the\nsystem. In particular, a given word may denote many similar but not identical\nentities. Such words are said to be lexically imprecise. Lexical imprecision\nhas caused widespread problems in many areas. Unless this phenomenon is\nrecognized and appropriately handled, it can degrade the performance of\nknowledge-based systems. In particular, it can lead to difficulties with the\nuser interface, and with the inferencing processes of these systems. Some\ntechniques are suggested for coping with this phenomenon.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:35 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3093","submitter":"Robert Hummel","authors":"Robert Hummel, Michael Landy","title":"Evidence as Opinions of Experts","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-135-144","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe a viewpoint on the Dempster/Shafer 'Theory of Evidence', and\nprovide an interpretation which regards the combination formulas as statistics\nof the opinions of \"experts\". This is done by introducing spaces with binary\noperations that are simpler to interpret or simpler to implement than the\nstandard combination formula, and showing that these spaces can be mapped\nhomomorphically onto the Dempster/Shafer theory of evidence space. The experts\nin the space of \"opinions of experts\" combine information in a Bayesian\nfashion. We present alternative spaces for the combination of evidence\nsuggested by this viewpoint.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:40 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3094","submitter":"Charles I. Kalme","authors":"Charles I. Kalme","title":"Decision Under Uncertainty in Diagnosis","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-145-150","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper describes the incorporation of uncertainty in diagnostic reasoning\nbased on the set covering model of Reggia et. al. extended to what in the\nArtificial Intelligence dichotomy between deep and compiled (shallow, surface)\nknowledge based diagnosis may be viewed as the generic form at the compiled end\nof the spectrum. A major undercurrent in this is advocating the need for a\nstrong underlying model and an integrated set of support tools for carrying\nsuch a model in order to deal with uncertainty.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:45 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3095","submitter":"Henry E. Kyburg Jr.","authors":"Henry E. Kyburg Jr","title":"Knowledge and Uncertainty","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-151-158","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One purpose -- quite a few thinkers would say the main purpose -- of seeking\nknowledge about the world is to enhance our ability to make good decisions. An\nitem of knowledge that can make no conceivable difference with regard to\nanything we might do would strike many as frivolous. Whether or not we want to\nbe philosophical pragmatists in this strong sense with regard to everything we\nmight want to enquire about, it seems a perfectly appropriate attitude to adopt\ntoward artificial knowledge systems. If is granted that we are ultimately\nconcerned with decisions, then some constraints are imposed on our measures of\nuncertainty at the level of decision making. If our measure of uncertainty is\nreal-valued, then it isn't hard to show that it must satisfy the classical\nprobability axioms. For example, if an act has a real-valued utility U(E) if\nthe event E obtains, and the same real-valued utility if the denial of E\nobtains, so that U(E) = U(-E), then the expected utility of that act must be\nU(E), and that must be the same as the uncertainty-weighted average of the\nreturns of the act, p-U(E) + q-U('E), where p and q represent the uncertainty\nof E and-E respectively. But then we must have p + q = 1.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:50 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3096","submitter":"Kathryn Blackmond Laskey","authors":"Kathryn Blackmond Laskey, Marvin S. Cohen","title":"An Application of Non-Monotonic Probabilistic Reasoning to Air Force\n  Threat Correlation","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-159-166","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current approaches to expert systems' reasoning under uncertainty fail to\ncapture the iterative revision process characteristic of intelligent human\nreasoning. This paper reports on a system, called the Non-monotonic\nProbabilist, or NMP (Cohen, et al., 1985). When its inferences result in\nsubstantial conflict, NMP examines and revises the assumptions underlying the\ninferences until conflict is reduced to acceptable levels. NMP has been\nimplemented in a demonstration computer-based system, described below, which\nsupports threat correlation and in-flight route replanning by Air Force pilots.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:52:56 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3097","submitter":"Tod S. Levitt","authors":"Tod S. Levitt","title":"Bayesian Inference for Radar Imagery Based Surveillance","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-167-174","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We are interested in creating an automated or semi-automated system with the\ncapability of taking a set of radar imagery, collection parameters and a priori\nmap and other tactical data, and producing likely interpretations of the\npossible military situations given the available evidence. This paper is\nconcerned with the problem of the interpretation and computation of certainty\nor belief in the conclusions reached by such a system.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:02 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3098","submitter":"Ze-Nian Li","authors":"Ze-Nian Li, Leonard Uhr","title":"Evidential Reasoning in Parallel Hierarchical Vision Programs","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-175-182","categories":"cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents an efficient adaptation and application of the\nDempster-Shafer theory of evidence, one that can be used effectively in a\nmassively parallel hierarchical system for visual pattern perception. It\ndescribes the techniques used, and shows in an extended example how they serve\nto improve the system's performance as it applies a multiple-level set of\nprocesses.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:08 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3099","submitter":"Ronald P. Loui","authors":"Ronald P. Loui","title":"Computing Reference Classes","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-183-188","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For any system with limited statistical knowledge, the combination of\nevidence and the interpretation of sampling information require the\ndetermination of the right reference class (or of an adequate one). The present\nnote (1) discusses the use of reference classes in evidential reasoning, and\n(2) discusses implementations of Kyburg's rules for reference classes. This\npaper contributes the first frank discussion of how much of Kyburg's system is\nneeded to be powerful, how much can be computed effectively, and how much is\nphilosophical fat.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:13 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3100","submitter":"Uttam Mukhopadhyay","authors":"Uttam Mukhopadhyay","title":"An Uncertainty Management Calculus for Ordering Searches in Distributed\n  Dynamic Databases","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-189-192","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  MINDS is a distributed system of cooperating query engines that customize,\ndocument retrieval for each user in a dynamic environment. It improves its\nperformance and adapts to changing patterns of document distribution by\nobserving system-user interactions and modifying the appropriate certainty\nfactors, which act as search control parameters. It argued here that the\nuncertainty management calculus must account for temporal precedence,\nreliability of evidence, degree of support for a proposition, and saturation\neffects. The calculus presented here possesses these features. Some results\nobtained with this scheme are discussed.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:17 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3101","submitter":"Steven W. Norton","authors":"Steven W. Norton","title":"An Explanation Mechanism for Bayesian Inferencing Systems","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-193-200","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Explanation facilities are a particularly important feature of expert system\nframeworks. It is an area in which traditional rule-based expert system\nframeworks have had mixed results. While explanations about control are well\nhandled, facilities are needed for generating better explanations concerning\nknowledge base content. This paper approaches the explanation problem by\nexamining the effect an event has on a variable of interest within a symmetric\nBayesian inferencing system. We argue that any effect measure operating in this\ncontext must satisfy certain properties. Such a measure is proposed. It forms\nthe basis for an explanation facility which allows the user of the Generalized\nBayesian Inferencing System to question the meaning of the knowledge base. That\nfacility is described in detail.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:23 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3102","submitter":"Judea Pearl","authors":"Judea Pearl","title":"Distributed Revision of Belief Commitment in Multi-Hypothesis\n  Interpretations","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-201-210","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper extends the applications of belief-networks to include the\nrevision of belief commitments, i.e., the categorical acceptance of a subset of\nhypotheses which, together, constitute the most satisfactory explanation of the\nevidence at hand. A coherent model of non-monotonic reasoning is established\nand distributed algorithms for belief revision are presented. We show that, in\nsingly connected networks, the most satisfactory explanation can be found in\nlinear time by a message-passing algorithm similar to the one used in belief\nupdating. In multiply-connected networks, the problem may be exponentially hard\nbut, if the network is sparse, topological considerations can be used to render\nthe interpretation task tractable. In general, finding the most probable\ncombination of hypotheses is no more complex than computing the degree of\nbelief for any individual hypothesis. Applications to medical diagnosis are\nillustrated.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:29 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3103","submitter":"Igor Roizer","authors":"Igor Roizer, Judea Pearl","title":"Learning Link-Probabilities in Causal Trees","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-211-214","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A learning algorithm is presented which given the structure of a causal tree,\nwill estimate its link probabilities by sequential measurements on the leaves\nonly. Internal nodes of the tree represent conceptual (hidden) variables\ninaccessible to observation. The method described is incremental, local,\nefficient, and remains robust to measurement imprecisions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:34 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3104","submitter":"Enrique H. Ruspini","authors":"Enrique H. Ruspini","title":"Approximate Deduction in Single Evidential Bodies","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-215-222","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Results on approximate deduction in the context of the calculus of evidence\nof Dempster-Shafer and the theory of interval probabilities are reported.\nApproximate conditional knowledge about the truth of conditional propositions\nwas assumed available and expressed as sets of possible values (actually\nnumeric intervals) of conditional probabilities. Under different\ninterpretations of this conditional knowledge, several formulas were produced\nto integrate unconditioned estimates (assumed given as sets of possible values\nof unconditioned probabilities) with conditional estimates. These formulas are\ndiscussed together with the computational characteristics of the methods\nderived from them. Of particular importance is one such evidence integration\nformulation, produced under a belief oriented interpretation, which\nincorporates both modus ponens and modus tollens inferential mechanisms, allows\nintegration of conditioned and unconditioned knowledge without resorting to\niterative or sequential approximations, and produces elementary mass\ndistributions as outputs using similar distributions as inputs.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:39 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3105","submitter":"Shimon Schocken","authors":"Shimon Schocken","title":"The Rational and Computational Scope of Probabilistic Rule-Based Expert\n  Systems","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-223-228","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Belief updating schemes in artificial intelligence may be viewed as three\ndimensional languages, consisting of a syntax (e.g. probabilities or certainty\nfactors), a calculus (e.g. Bayesian or CF combination rules), and a semantics\n(i.e. cognitive interpretations of competing formalisms). This paper studies\nthe rational scope of those languages on the syntax and calculus grounds. In\nparticular, the paper presents an endomorphism theorem which highlights the\nlimitations imposed by the conditional independence assumptions implicit in the\nCF calculus. Implications of the theorem to the relationship between the CF and\nthe Bayesian languages and the Dempster-Shafer theory of evidence are\npresented. The paper concludes with a discussion of some implications on\nrule-based knowledge engineering in uncertain domains.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:46 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3106","submitter":"Stanley M. Schwartz","authors":"Stanley M. Schwartz, Jonathan Baron, John R. Clarke","title":"A Causal Bayesian Model for the Diagnosis of Appendicitis","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-229-236","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The causal Bayesian approach is based on the assumption that effects (e.g.,\nsymptoms) that are not conditionally independent with respect to some causal\nagent (e.g., a disease) are conditionally independent with respect to some\nintermediate state caused by the agent, (e.g., a pathological condition). This\npaper describes the development of a causal Bayesian model for the diagnosis of\nappendicitis. The paper begins with a description of the standard Bayesian\napproach to reasoning about uncertainty and the major critiques it faces. The\npaper then lays the theoretical groundwork for the causal extension of the\nBayesian approach, and details specific improvements we have developed. The\npaper then goes on to describe our knowledge engineering and implementation and\nthe results of a test of the system. The paper concludes with a discussion of\nhow the causal Bayesian approach deals with the criticisms of the standard\nBayesian model and why it is superior to alternative approaches to reasoning\nabout uncertainty popular in the Al community.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:52 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3107","submitter":"Ross D. Shachter","authors":"Ross D. Shachter, David Heckerman","title":"A Backwards View for Assessment","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-237-242","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Much artificial intelligence research focuses on the problem of deducing the\nvalidity of unobservable propositions or hypotheses from observable evidence.!\nMany of the knowledge representation techniques designed for this problem\nencode the relationship between evidence and hypothesis in a directed manner.\nMoreover, the direction in which evidence is stored is typically from evidence\nto hypothesis.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:53:57 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3108","submitter":"Ross D. Shachter","authors":"Ross D. Shachter","title":"DAVID: Influence Diagram Processing System for the Macintosh","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-243-248","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Influence diagrams are a directed graph representation for uncertainties as\nprobabilities. The graph distinguishes between those variables which are under\nthe control of a decision maker (decisions, shown as rectangles) and those\nwhich are not (chances, shown as ovals), as well as explicitly denoting a goal\nfor solution (value, shown as a rounded rectangle.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:03 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3109","submitter":"Prakash P. Shenoy","authors":"Prakash P. Shenoy, Glenn Shafer, Khaled Mellouli","title":"Propagation of Belief Functions: A Distributed Approach","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-249-260","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we describe a scheme for propagating belief functions in\ncertain kinds of trees using only local computations. This scheme generalizes\nthe computational scheme proposed by Shafer and Logan1 for diagnostic trees of\nthe type studied by Gordon and Shortliffe, and the slightly more general scheme\ngiven by Shafer for hierarchical evidence. It also generalizes the scheme\nproposed by Pearl for Bayesian causal trees (see Shenoy and Shafer). Pearl's\ncausal trees and Gordon and Shortliffe's diagnostic trees are both ways of\nbreaking the evidence that bears on a large problem down into smaller items of\nevidence that bear on smaller parts of the problem so that these smaller\nproblems can be dealt with one at a time. This localization of effort is often\nessential in order to make the process of probability judgment feasible, both\nfor the person who is making probability judgments and for the machine that is\ncombining them. The basic structure for our scheme is a type of tree that\ngeneralizes both Pearl's and Gordon and Shortliffe's trees. Trees of this\ngeneral type permit localized computation in Pearl's sense. They are based on\nqualitative judgments of conditional independence. We believe that the scheme\nwe describe here will prove useful in expert systems. It is now clear that the\nsuccessful propagation of probabilities or certainty factors in expert systems\nrequires much more structure than can be provided in a pure production-system\nframework. Bayesian schemes, on the other hand, often make unrealistic demands\nfor structure. The propagation of belief functions in trees and more general\nnetworks stands on a middle ground where some sensible and useful things can be\ndone. We would like to emphasize that the basic idea of local computation for\npropagating probabilities is due to Judea Pearl. It is a very innovative idea;\nwe do not believe that it can be found in the Bayesian literature prior to\nPearl's work. We see our contribution as extending the usefulness of Pearl's\nidea by generalizing it from Bayesian probabilities to belief functions. In the\nnext section, we give a brief introduction to belief functions. The notions of\nqualitative independence for partitions and a qualitative Markov tree are\nintroduced in Section III. Finally, in Section IV, we describe a scheme for\npropagating belief functions in qualitative Markov trees.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:09 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3110","submitter":"David Sher","authors":"David Sher","title":"Appropriate and Inappropriate Estimation Techniques","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-261-266","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mode {also called MAP} estimation, mean estimation and median estimation are\nexamined here to determine when they can be safely used to derive {posterior)\ncost minimizing estimates. (These are all Bayes procedures, using the mode.\nmean. or median of the posterior distribution). It is found that modal\nestimation only returns cost minimizing estimates when the cost function is\n0-t. If the cost function is a function of distance then mean estimation only\nreturns cost minimizing estimates when the cost function is squared distance\nfrom the true value and median estimation only returns cost minimizing\nestimates when the cost function ts the distance from the true value. Results\nare presented on the goodness or modal estimation with non 0-t cost functions\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:15 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3111","submitter":"Randall Smith","authors":"Randall Smith, Matthew Self, Peter Cheeseman","title":"Estimating Uncertain Spatial Relationships in Robotics","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-267-288","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we describe a representation for spatial information, called\nthe stochastic map, and associated procedures for building it, reading\ninformation from it, and revising it incrementally as new information is\nobtained. The map contains the estimates of relationships among objects in the\nmap, and their uncertainties, given all the available information. The\nprocedures provide a general solution to the problem of estimating uncertain\nrelative spatial relationships. The estimates are probabilistic in nature, an\nadvance over the previous, very conservative, worst-case approaches to the\nproblem. Finally, the procedures are developed in the context of\nstate-estimation and filtering theory, which provides a solid basis for\nnumerous extensions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:21 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3112","submitter":"Masaki Togai","authors":"Masaki Togai, Hiroyuki Watanabe","title":"A VLSI Design and Implementation for a Real-Time Approximate Reasoning","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-289-296","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The role of inferencing with uncertainty is becoming more important in\nrule-based expert systems (ES), since knowledge given by a human expert is\noften uncertain or imprecise. We have succeeded in designing a VLSI chip which\ncan perform an entire inference process based on fuzzy logic. The design of the\nVLSI fuzzy inference engine emphasizes simplicity, extensibility, and\nefficiency (operational speed and layout area). It is fabricated in 2.5 um CMOS\ntechnology. The inference engine consists of three major components; a rule set\nmemory, an inference processor, and a controller. In this implementation, a\nrule set memory is realized by a read only memory (ROM). The controller\nconsists of two counters. In the inference processor, one data path is laid out\nfor each rule. The number of the inference rule can be increased adding more\ndata paths to the inference processor. All rules are executed in parallel, but\neach rule is processed serially. The logical structure of fuzzy inference\nproposed in the current paper maps nicely onto the VLSI structure. A two-phase\nnonoverlapping clocking scheme is used. Timing tests indicate that the\ninference engine can operate at approximately 20.8 MHz. This translates to an\nexecution speed of approximately 80,000 Fuzzy Logical Inferences Per Second\n(FLIPS), and indicates that the inference engine is suitable for a demanding\nreal-time application. The potential applications include decision-making in\nthe area of command and control for intelligent robot systems, process control,\nmissile and aircraft guidance, and other high performance machines.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:27 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3113","submitter":"Richard M. Tong","authors":"Richard M. Tong, Lee A. Appelbaum, D. G. Shapiro","title":"A General Purpose Inference Engine for Evidential Reasoning Research","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-297-302","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The purpose of this paper is to report on the most recent developments in our\nongoing investigation of the representation and manipulation of uncertainty in\nautomated reasoning systems. In our earlier studies (Tong and Shapiro, 1985) we\ndescribed a series of experiments with RUBRIC (Tong et al., 1985), a system for\nfull-text document retrieval, that generated some interesting insights into the\neffects of choosing among a class of scalar valued uncertainty calculi. [n\norder to extend these results we have begun a new series of experiments with a\nlarger class of representations and calculi, and to help perform these\nexperiments we have developed a general purpose inference engine.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:33 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3114","submitter":"Silvio Ursic","authors":"Silvio Ursic","title":"Generalizing Fuzzy Logic Probabilistic Inferences","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-303-310","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Linear representations for a subclass of boolean symmetric functions selected\nby a parity condition are shown to constitute a generalization of the linear\nconstraints on probabilities introduced by Boole. These linear constraints are\nnecessary to compute probabilities of events with relations between the.\narbitrarily specified with propositional calculus boolean formulas.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:38 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3115","submitter":"Michael P. Wellman","authors":"Michael P. Wellman","title":"Qualitative Probabilistic Networks for Planning Under Uncertainty","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-311-318","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bayesian networks provide a probabilistic semantics for qualitative\nassertions about likelihood. A qualitative reasoner based on an algebra over\nthese assertions can derive further conclusions about the influence of actions.\nWhile the conclusions are much weaker than those computed from complete\nprobability distributions, they are still valuable for suggesting potential\nactions, eliminating obviously inferior plans, identifying important tradeoffs,\nand explaining probabilistic models.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:44 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3116","submitter":"Ben P. Wise","authors":"Ben P. Wise","title":"Experimentally Comparing Uncertain Inference Systems to Probability","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-319-332","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper examines the biases and performance of several uncertain inference\nsystems: Mycin, a variant of Mycin. and a simplified version of probability\nusing conditional independence assumptions. We present axiomatic arguments for\nusing Minimum Cross Entropy inference as the best way to do uncertain\ninference. For Mycin and its variant we found special situations where its\nperformance was very good, but also situations where performance was worse than\nrandom guessing, or where data was interpreted as having the opposite of its\ntrue import We have found that all three of these systems usually gave accurate\nresults, and that the conditional independence assumptions gave the most robust\nresults. We illustrate how the Importance of biases may be quantitatively\nassessed and ranked. Considerations of robustness might be a critical factor is\nselecting UlS's for a given application.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:50 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3117","submitter":"Robert M. Yadrick","authors":"Robert M. Yadrick, Bruce M. Perrin, David S. Vaughan, Peter D. Holden,\n  Karl G. Kempf","title":"Evaluation of Uncertain Inference Models I: PROSPECTOR","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-333-338","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper examines the accuracy of the PROSPECTOR model for uncertain\nreasoning. PROSPECTOR's solutions for a large number of computer-generated\ninference networks were compared to those obtained from probability theory and\nminimum cross-entropy calculations. PROSPECTOR's answers were generally\naccurate for a restricted subset of problems that are consistent with its\nassumptions. However, even within this subset, we identified conditions under\nwhich PROSPECTOR's performance deteriorates.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:54:56 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3118","submitter":"Ronald R. Yager","authors":"Ronald R. Yager","title":"On Implementing Usual Values","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-339-346","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In many cases commonsense knowledge consists of knowledge of what is usual.\nIn this paper we develop a system for reasoning with usual information. This\nsystem is based upon the fact that these pieces of commonsense information\ninvolve both a probabilistic aspect and a granular aspect. We implement this\nsystem with the aid of possibility-probability granules.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:55:01 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3119","submitter":"Lotfi Zadeh","authors":"Lotfi Zadeh, Anca Ralescu","title":"On the Combinality of Evidence in the Dempster-Shafer Theory","comments":"Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)","journal-ref":null,"doi":null,"report-no":"UAI-P-1986-PG-347-349","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the current versions of the Dempster-Shafer theory, the only essential\nrestriction on the validity of the rule of combination is that the sources of\nevidence must be statistically independent. Under this assumption, it is\npermissible to apply the Dempster-Shafer rule to two or mere distinct\nprobability distributions.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:55:05 GMT"}],"update_date":"2013-04-12"}
{"id":"1304.3418","submitter":"Benjamin N. Grosof","authors":"Benjamin N. Grosof","title":"An Inequality Paradigm for Probabilistic Knowledge","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-1-8","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose an inequality paradigm for probabilistic reasoning based on a\nlogic of upper and lower bounds on conditional probabilities. We investigate a\nfamily of probabilistic logics, generalizing the work of Nilsson [14]. We\ndevelop a variety of logical notions for probabilistic reasoning, including\nsoundness, completeness justification; and convergence: reduction of a theory\nto a simpler logical class. We argue that a bound view is especially useful for\ndescribing the semantics of probabilistic knowledge representation and for\ndescribing intermediate states of probabilistic inference and updating. We show\nthat the Dempster-Shafer theory of evidence is formally identical to a special\ncase of our generalized probabilistic logic. Our paradigm thus incorporates\nboth Bayesian \"rule-based\" approaches and avowedly non-Bayesian \"evidential\"\napproaches such as MYCIN and DempsterShafer. We suggest how to integrate the\ntwo \"schools\", and explore some possibilities for novel synthesis of a variety\nof ideas in probabilistic reasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:55:33 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3419","submitter":"David Heckerman","authors":"David Heckerman","title":"Probabilistic Interpretations for MYCIN's Certainty Factors","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-9-20","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper examines the quantities used by MYCIN to reason with uncertainty,\ncalled certainty factors. It is shown that the original definition of certainty\nfactors is inconsistent with the functions used in MYCIN to combine the\nquantities. This inconsistency is used to argue for a redefinition of certainty\nfactors in terms of the intuitively appealing desiderata associated with the\ncombining functions. It is shown that this redefinition accommodates an\nunlimited number of probabilistic interpretations. These interpretations are\nshown to be monotonic transformations of the likelihood ratio p(EIH)/p(El H).\nThe construction of these interpretations provides insight into the assumptions\nimplicit in the certainty factor model. In particular, it is shown that if\nuncertainty is to be propagated through an inference network in accordance with\nthe desiderata, evidence must be conditionally independent given the hypothesis\nand its negation and the inference network must have a tree structure. It is\nemphasized that assumptions implicit in the model are rarely true in practical\napplications. Methods for relaxing the assumptions are suggested.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:55:40 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3420","submitter":"Daniel Hunter","authors":"Daniel Hunter","title":"Uncertain Reasoning Using Maximum Entropy Inference","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-21-27","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The use of maximum entropy inference in reasoning with uncertain information\nis commonly justified by an information-theoretic argument. This paper\ndiscusses a possible objection to this information-theoretic justification and\nshows how it can be met. I then compare maximum entropy inference with certain\nother currently popular methods for uncertain reasoning. In making such a\ncomparison, one must distinguish between static and dynamic theories of degrees\nof belief: a static theory concerns the consistency conditions for degrees of\nbelief at a given time; whereas a dynamic theory concerns how one's degrees of\nbelief should change in the light of new information. It is argued that maximum\nentropy is a dynamic theory and that a complete theory of uncertain reasoning\ncan be gotten by combining maximum entropy inference with probability theory,\nwhich is a static theory. This total theory, I argue, is much better grounded\nthan are other theories of uncertain reasoning.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:55:46 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3421","submitter":"Rodney W. Johnson","authors":"Rodney W. Johnson","title":"Independence and Bayesian Updating Methods","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-28-30","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Duda, Hart, and Nilsson have set forth a method for rule-based inference\nsystems to use in updating the probabilities of hypotheses on the basis of\nmultiple items of new evidence. Pednault, Zucker, and Muresan claimed to give\nconditions under which independence assumptions made by Duda et al. preclude\nupdating-that is, prevent the evidence from altering the probabilities of the\nhypotheses. Glymour refutes Pednault et al.'s claim with a counterexample of a\nrather special form (one item of evidence is incompatible with all but one of\nthe hypotheses); he raises, but leaves open, the question whether their result\nwould be true with an added assumption to rule out such special cases. We show\nthat their result does not hold even with the added assumption, but that it can\nnevertheless be largely salvaged. Namely, under the conditions assumed by\nPednault et al., at most one of the items of evidence can alter the probability\nof any given hypothesis; thus, although updating is possible, multiple updating\nfor any of the hypotheses is precluded.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:55:51 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3422","submitter":"Judea Pearl","authors":"Judea Pearl","title":"A Constraint Propagation Approach to Probabilistic Reasoning","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-31-42","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The paper demonstrates that strict adherence to probability theory does not\npreclude the use of concurrent, self-activated constraint-propagation\nmechanisms for managing uncertainty. Maintaining local records of\nsources-of-belief allows both predictive and diagnostic inferences to be\nactivated simultaneously and propagate harmoniously towards a stable\nequilibrium.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:55:56 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3423","submitter":"John E. Shore","authors":"John E. Shore","title":"Relative Entropy, Probabilistic Inference and AI","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-43-47","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Various properties of relative entropy have led to its widespread use in\ninformation theory. These properties suggest that relative entropy has a role\nto play in systems that attempt to perform inference in terms of probability\ndistributions. In this paper, I will review some basic properties of relative\nentropy as well as its role in probabilistic inference. I will also mention\nbriefly a few existing and potential applications of relative entropy to\nso-called artificial intelligence (AI).\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:01 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3424","submitter":"Ray Solomonoff","authors":"Ray Solomonoff","title":"Foundations of Probability Theory for AI - The Application of\n  Algorithmic Probability to Problems in Artificial Intelligence","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-48-56","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper covers two topics: first an introduction to Algorithmic Complexity\nTheory: how it defines probability, some of its characteristic properties and\npast successful applications. Second, we apply it to problems in A.I. - where\nit promises to give near optimum search procedures for two very broad classes\nof problems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:07 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3425","submitter":"Piero P. Bonissone","authors":"Piero P. Bonissone, Keith S. Decker","title":"Selecting Uncertainty Calculi and Granularity: An Experiment in\n  Trading-Off Precision and Complexity","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-57-66","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The management of uncertainty in expert systems has usually been left to ad\nhoc representations and rules of combinations lacking either a sound theory or\nclear semantics. The objective of this paper is to establish a theoretical\nbasis for defining the syntax and semantics of a small subset of calculi of\nuncertainty operating on a given term set of linguistic statements of\nlikelihood. Each calculus is defined by specifying a negation, a conjunction\nand a disjunction operator. Families of Triangular norms and conorms constitute\nthe most general representations of conjunction and disjunction operators.\nThese families provide us with a formalism for defining an infinite number of\ndifferent calculi of uncertainty. The term set will define the uncertainty\ngranularity, i.e. the finest level of distinction among different\nquantifications of uncertainty. This granularity will limit the ability to\ndifferentiate between two similar operators. Therefore, only a small finite\nsubset of the infinite number of calculi will produce notably different\nresults. This result is illustrated by two experiments where nine and eleven\ndifferent calculi of uncertainty are used with three term sets containing five,\nnine, and thirteen elements, respectively. Finally, the use of context\ndependent rule set is proposed to select the most appropriate calculus for any\ngiven situation. Such a rule set will be relatively small since it must only\ndescribe the selection policies for a small number of calculi (resulting from\nthe analyzed trade-off between complexity and precision).\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:13 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3426","submitter":"Marvin S. Cohen","authors":"Marvin S. Cohen","title":"A Framework for Non-Monotonic Reasoning About Probabilistic Assumptions","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-67-75","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Attempts to replicate probabilistic reasoning in expert systems have\ntypically overlooked a critical ingredient of that process. Probabilistic\nanalysis typically requires extensive judgments regarding interdependencies\namong hypotheses and data, and regarding the appropriateness of various\nalternative models. The application of such models is often an iterative\nprocess, in which the plausibility of the results confirms or disconfirms the\nvalidity of assumptions made in building the model. In current expert systems,\nby contrast, probabilistic information is encapsulated within modular rules\n(involving, for example, \"certainty factors\"), and there is no mechanism for\nreviewing the overall form of the probability argument or the validity of the\njudgments entering into it.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:20 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3427","submitter":"Robert Fung","authors":"Robert Fung, Chee Yee Chong","title":"Metaprobability and Dempster-Shafer in Evidential Reasoning","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-76-83","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Evidential reasoning in expert systems has often used ad-hoc uncertainty\ncalculi. Although it is generally accepted that probability theory provides a\nfirm theoretical foundation, researchers have found some problems with its use\nas a workable uncertainty calculus. Among these problems are representation of\nignorance, consistency of probabilistic judgements, and adjustment of a priori\njudgements with experience. The application of metaprobability theory to\nevidential reasoning is a new approach to solving these problems.\nMetaprobability theory can be viewed as a way to provide soft or hard\nconstraints on beliefs in much the same manner as the Dempster-Shafer theory\nprovides constraints on probability masses on subsets of the state space. Thus,\nwe use the Dempster-Shafer theory, an alternative theory of evidential\nreasoning to illuminate metaprobability theory as a theory of evidential\nreasoning. The goal of this paper is to compare how metaprobability theory and\nDempster-Shafer theory handle the adjustment of beliefs with evidence with\nrespect to a particular thought experiment. Sections 2 and 3 give brief\ndescriptions of the metaprobability and Dempster-Shafer theories.\nMetaprobability theory deals with higher order probabilities applied to\nevidential reasoning. Dempster-Shafer theory is a generalization of probability\ntheory which has evolved from a theory of upper and lower probabilities.\nSection 4 describes a thought experiment and the metaprobability and\nDempsterShafer analysis of the experiment. The thought experiment focuses on\nforming beliefs about a population with 6 types of members {1, 2, 3, 4, 5, 6}.\nA type is uniquely defined by the values of three features: A, B, C. That is,\nif the three features of one member of the population were known then its type\ncould be ascertained. Each of the three features has two possible values, (e.g.\nA can be either \"a0\" or \"al\"). Beliefs are formed from evidence accrued from\ntwo sensors: sensor A, and sensor B. Each sensor senses the corresponding\ndefining feature. Sensor A reports that half of its observations are \"a0\" and\nhalf the observations are 'al'. Sensor B reports that half of its observations\nare ``b0,' and half are \"bl\". Based on these two pieces of evidence, what\nshould be the beliefs on the distribution of types in the population? Note that\nthe third feature is not observed by any sensor.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:26 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3428","submitter":"Matthew L. Ginsberg","authors":"Matthew L. Ginsberg","title":"Implementing Probabilistic Reasoning","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-84-90","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  General problems in analyzing information in a probabilistic database are\nconsidered. The practical difficulties (and occasional advantages) of storing\nuncertain data, of using it conventional forward- or backward-chaining\ninference engines, and of working with a probabilistic version of resolution\nare discussed. The background for this paper is the incorporation of uncertain\nreasoning facilities in MRS, a general-purpose expert system building tool.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:32 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3429","submitter":"Glenn Shafer","authors":"Glenn Shafer","title":"Probability Judgement in Artificial Intelligence","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-91-98","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is concerned with two theories of probability judgment: the\nBayesian theory and the theory of belief functions. It illustrates these\ntheories with some simple examples and discusses some of the issues that arise\nwhen we try to implement them in expert systems. The Bayesian theory is well\nknown; its main ideas go back to the work of Thomas Bayes (1702-1761). The\ntheory of belief functions, often called the Dempster-Shafer theory in the\nartificial intelligence community, is less well known, but it has even older\nantecedents; belief-function arguments appear in the work of George Hooper\n(16401723) and James Bernoulli (1654-1705). For elementary expositions of the\ntheory of belief functions, see Shafer (1976, 1985).\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:37 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3430","submitter":"Ben P. Wise","authors":"Ben P. Wise, Max Henrion","title":"A Framework for Comparing Uncertain Inference Systems to Probability","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-99-108","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Several different uncertain inference systems (UISs) have been developed for\nrepresenting uncertainty in rule-based expert systems. Some of these, such as\nMycin's Certainty Factors, Prospector, and Bayes' Networks were designed as\napproximations to probability, and others, such as Fuzzy Set Theory and\nDempsterShafer Belief Functions were not. How different are these UISs in\npractice, and does it matter which you use? When combining and propagating\nuncertain information, each UIS must, at least by implication, make certain\nassumptions about correlations not explicily specified. The maximum entropy\nprinciple with minimum cross-entropy updating, provides a way of making\nassumptions about the missing specification that minimizes the additional\ninformation assumed, and thus offers a standard against which the other UISs\ncan be compared. We describe a framework for the experimental comparison of the\nperformance of different UISs, and provide some illustrative results.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:43 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3431","submitter":"Norman C. Dalkey","authors":"Norman C. Dalkey","title":"Inductive Inference and the Representation of Uncertainty","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-109-116","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The form and justification of inductive inference rules depend strongly on\nthe representation of uncertainty. This paper examines one generic\nrepresentation, namely, incomplete information. The notion can be formalized by\npresuming that the relevant probabilities in a decision problem are known only\nto the extent that they belong to a class K of probability distributions. The\nconcept is a generalization of a frequent suggestion that uncertainty be\nrepresented by intervals or ranges on probabilities. To make the representation\nuseful for decision making, an inductive rule can be formulated which\ndetermines, in a well-defined manner, a best approximation to the unknown\nprobability, given the set K. In addition, the knowledge set notion entails a\nnatural procedure for updating -- modifying the set K given new evidence.\nSeveral non-intuitive consequences of updating emphasize the differences\nbetween inference with complete and inference with incomplete information.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:49 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3432","submitter":"Stephen Jose Hanson","authors":"Stephen Jose Hanson, Malcolm Bauer","title":"Machine Learning, Clustering, and Polymorphy","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-117-128","categories":"cs.AI cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper describes a machine induction program (WITT) that attempts to\nmodel human categorization. Properties of categories to which human subjects\nare sensitive includes best or prototypical members, relative contrasts between\nputative categories, and polymorphy (neither necessary or sufficient features).\nThis approach represents an alternative to usual Artificial Intelligence\napproaches to generalization and conceptual clustering which tend to focus on\nnecessary and sufficient feature rules, equivalence classes, and simple search\nand match schemes. WITT is shown to be more consistent with human\ncategorization while potentially including results produced by more traditional\nclustering schemes. Applications of this approach in the domains of expert\nsystems and information retrieval are also discussed.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:56:55 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3433","submitter":"Larry Rendell","authors":"Larry Rendell","title":"Induction, of and by Probability","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-129-134","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper examines some methods and ideas underlying the author's successful\nprobabilistic learning systems(PLS), which have proven uniquely effective and\nefficient in generalization learning or induction. While the emerging\nprinciples are generally applicable, this paper illustrates them in heuristic\nsearch, which demands noise management and incremental learning. In our\napproach, both task performance and learning are guided by probability.\nProbabilities are incrementally normalized and revised, and their errors are\nlocated and corrected.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:01 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3434","submitter":"David S. Vaughan","authors":"David S. Vaughan, Bruce M. Perrin, Robert M. Yadrick, Peter D. Holden,\n  Karl G. Kempf","title":"An Odds Ratio Based Inference Engine","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-135-142","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Expert systems applications that involve uncertain inference can be\nrepresented by a multidimensional contingency table. These tables offer a\ngeneral approach to inferring with uncertain evidence, because they can embody\nany form of association between any number of pieces of evidence and\nconclusions. (Simpler models may be required, however, if the number of pieces\nof evidence bearing on a conclusion is large.) This paper presents a method of\nusing these tables to make uncertain inferences without assumptions of\nconditional independence among pieces of evidence or heuristic combining rules.\nAs evidence is accumulated, new joint probabilities are calculated so as to\nmaintain any dependencies among the pieces of evidence that are found in the\ncontingency table. The new conditional probability of the conclusion is then\ncalculated directly from these new joint probabilities and the conditional\nprobabilities in the contingency table.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:05 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3435","submitter":"Moshe Ben-Bassat","authors":"Moshe Ben-Bassat, Oded Maler","title":"A Framework for Control Strategies in Uncertain Inference Networks","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-143-151","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Control Strategies for hierarchical tree-like probabilistic inference\nnetworks are formulated and investigated. Strategies that utilize staged\nlook-ahead and temporary focus on subgoals are formalized and refined using the\nDepth Vector concept that serves as a tool for defining the 'virtual tree'\nregarded by the control strategy. The concept is illustrated by four types of\ncontrol strategies for three-level trees that are characterized according to\ntheir Depth Vector, and according to the way they consider intermediate nodes\nand the role that they let these nodes play. INFERENTI is a computerized\ninference system written in Prolog, which provides tools for exercising a\nvariety of control strategies. The system also provides tools for simulating\ntest data and for comparing the relative average performance under different\nstrategies.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:11 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3436","submitter":"Henry Hamburger","authors":"Henry Hamburger","title":"Combining Uncertain Estimates","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-152-159","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a real expert system, one may have unreliable, unconfident, conflicting\nestimates of the value for a particular parameter. It is important for decision\nmaking that the information present in this aggregate somehow find its way into\nuse. We cast the problem of representing and combining uncertain estimates as\nselection of two kinds of functions, one to determine an estimate, the other\nits uncertainty. The paper includes a long list of properties that such\nfunctions should satisfy, and it presents one method that satisfies them.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:16 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3437","submitter":"John F. Lemmer","authors":"John F. Lemmer","title":"Confidence Factors, Empiricism and the Dempster-Shafer Theory of\n  Evidence","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-160-176","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The issue of confidence factors in Knowledge Based Systems has become\nincreasingly important and Dempster-Shafer (DS) theory has become increasingly\npopular as a basis for these factors. This paper discusses the need for an\nempirical lnterpretatlon of any theory of confidence factors applied to\nKnowledge Based Systems and describes an empirical lnterpretatlon of DS theory\nsuggesting that the theory has been extensively misinterpreted. For the\nessentially syntactic DS theory, a model is developed based on sample spaces,\nthe traditional semantic model of probability theory. This model is used to\nshow that, if belief functions are based on reasonably accurate sampling or\nobservation of a sample space, then the beliefs and upper probabilities as\ncomputed according to DS theory cannot be interpreted as frequency ratios.\nSince many proposed applications of DS theory use belief functions in\nsituations with statistically derived evidence (Wesley [1]) and seem to appeal\nto statistical intuition to provide an lnterpretatlon of the results as has\nGarvey [2], it may be argued that DS theory has often been misapplied.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:24 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3438","submitter":"Alan Bundy","authors":"Alan Bundy","title":"Incidence Calculus: A Mechanism for Probabilistic Reasoning","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-177-184","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mechanisms for the automation of uncertainty are required for expert systems.\nSometimes these mechanisms need to obey the properties of probabilistic\nreasoning. A purely numeric mechanism, like those proposed so far, cannot\nprovide a probabilistic logic with truth functional connectives. We propose an\nalternative mechanism, Incidence Calculus, which is based on a representation\nof uncertainty using sets of points, which might represent situations, models\nor possible worlds. Incidence Calculus does provide a probabilistic logic with\ntruth functional connectives.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:29 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3439","submitter":"Benjamin N. Grosof","authors":"Benjamin N. Grosof","title":"Evidential Confirmation as Transformed Probability","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-185-192","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A considerable body of work in AI has been concerned with aggregating\nmeasures of confirmatory and disconfirmatory evidence for a common set of\npropositions. Claiming classical probability to be inadequate or inappropriate,\nseveral researchers have gone so far as to invent new formalisms and methods.\nWe show how to represent two major such alternative approaches to evidential\nconfirmation not only in terms of transformed (Bayesian) probability, but also\nin terms of each other. This unifies two of the leading approaches to\nconfirmation theory, by showing that a revised MYCIN Certainty Factor method\n[12] is equivalent to a special case of Dempster-Shafer theory. It yields a\nwell-understood axiomatic basis, i.e. conditional independence, to interpret\nprevious work on quantitative confirmation theory. It substantially resolves\nthe \"taxe-them-or-leave-them\" problem of priors: MYCIN had to leave them out,\nwhile PROSPECTOR had to have them in. It recasts some of confirmation theory's\nadvantages in terms of the psychological accessibility of probabilistic\ninformation in different (transformed) formats. Finally, it helps to unify the\nrepresentation of uncertain reasoning (see also [11]).\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:35 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3440","submitter":"Ronald P. Loui","authors":"Ronald P. Loui","title":"Interval-Based Decisions for Reasoning Systems","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-193-200","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This essay looks at decision-making with interval-valued probability\nmeasures. Existing decision methods have either supplemented expected utility\nmethods with additional criteria of optimality, or have attempted to supplement\nthe interval-valued measures. We advocate a new approach, which makes the\nfollowing questions moot: 1. which additional criteria to use, and 2. how wide\nintervals should be. In order to implement the approach, we need more\nepistemological information. Such information can be generated by a rule of\nacceptance with a parameter that allows various attitudes toward error, or can\nsimply be declared. In sketch, the argument is: 1. probability intervals are\nuseful and natural in All. systems; 2. wide intervals avoid error, but are\nuseless in some risk sensitive decision-making; 3. one may obtain narrower\nintervals if one is less cautious; 4. if bodies of knowledge can be ordered by\ntheir caution, one should perform the decision analysis with the acceptable\nbody of knowledge that is the most cautious, of those that are useful. The\nresulting behavior differs from that of a behavioral probabilist (a Bayesian)\nbecause in the proposal, 5. intervals based on successive bodies of knowledge\nare not always nested; 6. if the agent uses a probability for a particular\ndecision, she need not commit to that probability for credence or future\ndecision; and 7. there may be no acceptable body of knowledge that is useful;\nhence, sometimes no decision is mandated.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:41 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3441","submitter":"James E. Corter","authors":"James E. Corter, Mark A. Gluck","title":"Machine Generalization and Human Categorization: An\n  Information-Theoretic View","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-201-207","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In designing an intelligent system that must be able to explain its reasoning\nto a human user, or to provide generalizations that the human user finds\nreasonable, it may be useful to take into consideration psychological data on\nwhat types of concepts and categories people naturally use. The psychological\nliterature on concept learning and categorization provides strong evidence that\ncertain categories are more easily learned, recalled, and recognized than\nothers. We show here how a measure of the informational value of a category\npredicts the results of several important categorization experiments better\nthan standard alternative explanations. This suggests that information-based\napproaches to machine generalization may prove particularly useful and natural\nfor human users of the systems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:47 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3442","submitter":"Samuel Holtzman","authors":"Samuel Holtzman, John S. Breese","title":"Exact Reasoning Under Uncertainty","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-208-216","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper focuses on designing expert systems to support decision making in\ncomplex, uncertain environments. In this context, our research indicates that\nstrictly probabilistic representations, which enable the use of\ndecision-theoretic reasoning, are highly preferable to recently proposed\nalternatives (e.g., fuzzy set theory and Dempster-Shafer theory). Furthermore,\nwe discuss the language of influence diagrams and a corresponding methodology\n-decision analysis -- that allows decision theory to be used effectively and\nefficiently as a decision-making aid. Finally, we use RACHEL, a system that\nhelps infertile couples select medical treatments, to illustrate the\nmethodology of decision analysis as basis for expert decision systems.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:53 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3443","submitter":"Alf C. Zimmer","authors":"Alf C. Zimmer","title":"The Estimation of Subjective Probabilities via Categorical Judgments of\n  Uncertainty","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-217-224","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Theoretically as well as experimentally it is investigated how people\nrepresent their knowledge in order to make decisions or to share their\nknowledge with others. Experiment 1 probes into the ways how people 6ather\ninformation about the frequencies of events and how the requested response\nmode, that is, numerical vs. verbal estimates interferes with this knowledge.\nThe least interference occurs if the subjects are allowed to give verbal\nresponses. From this it is concluded that processing knowledge about\nuncertainty categorically, that is, by means of verbal expressions, imposes\nless mental work load on the decision matter than numerical processing.\nPossibility theory is used as a framework for modeling the individual usage of\nverbal categories for grades of uncertainty. The 'elastic' constraints on the\nverbal expressions for every sing1e subject are determined in Experiment 2 by\nmeans of sequential calibration. In further experiments it is shown that the\nsuperiority of the verbal processing of knowledge about uncertainty guise\ngenerally reduces persistent biases reported in the literature: conservatism\n(Experiment 3) and neg1igence of regression (Experiment 4). The reanalysis of\nHormann's data reveal that in verbal Judgments people exhibit sensitivity for\nbase rates and are not prone to the conjunction fallacy. In a final experiment\n(5) about predictions in a real-life situation it turns out that in a numerical\nforecasting task subjects restricted themselves to those parts of their\nknowledge which are numerical. On the other hand subjects in a verbal\nforecasting task accessed verbally as well as numerically stated knowledge.\nForecasting is structurally related to the estimation of probabilities for rare\nevents insofar as supporting and contradicting arguments have to be evaluated\nand the choice of the final Judgment has to be Justified according to the\nevidence brought forward. In order to assist people in such choice situations a\nformal model for the interactive checking of arguments has been developed. The\nmodel transforms the normal-language quantifiers used in the arguments into\nfuzzy numbers and evaluates the given train of arguments by means of fuzzy\nnumerica1 operations. Ambiguities in the meanings of quantifiers are resolved\ninteractively.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:57:59 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3444","submitter":"Bruce Abramson","authors":"Bruce Abramson","title":"A Cure for Pathological Behavior in Games that Use Minimax","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-225-231","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The traditional approach to choosing moves in game-playing programs is the\nminimax procedure. The general belief underlying its use is that increasing\nsearch depth improves play. Recent research has shown that given certain\nsimplifying assumptions about a game tree's structure, this belief is\nerroneous: searching deeper decreases the probability of making a correct move.\nThis phenomenon is called game tree pathology. Among these simplifying\nassumptions is uniform depth of win/loss (terminal) nodes, a condition which is\nnot true for most real games. Analytic studies in [10] have shown that if every\nnode in a pathological game tree is made terminal with probability exceeding a\ncertain threshold, the resulting tree is nonpathological. This paper considers\na new evaluation function which recognizes increasing densities of forced wins\nat deeper levels in the tree. This property raises two points that strengthen\nthe hypothesis that uniform win depth causes pathology. First, it proves\nmathematically that as search deepens, an evaluation function that does not\nexplicitly check for certain forced win patterns becomes decreasingly likely to\nforce wins. This failing predicts the pathological behavior of the original\nevaluation function. Second, it shows empirically that despite recognizing\nfewer mid-game wins than the theoretically predicted minimum, the new function\nis nonpathological.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:05 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3445","submitter":"Dana Nau","authors":"Dana Nau, Paul Purdom, Chun-Hung Tzeng","title":"An Evaluation of Two Alternatives to Minimax","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-232-236","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the field of Artificial Intelligence, traditional approaches to choosing\nmoves in games involve the we of the minimax algorithm. However, recent\nresearch results indicate that minimizing may not always be the best approach.\nIn this paper we summarize the results of some measurements on several model\ngames with several different evaluation functions. These measurements, which\nare presented in detail in [NPT], show that there are some new algorithms that\ncan make significantly better use of evaluation function values than the\nminimax algorithm does.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:11 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3446","submitter":"Ross D. Shachter","authors":"Ross D. Shachter","title":"Intelligent Probabilistic Inference","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-237-244","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The analysis of practical probabilistic models on the computer demands a\nconvenient representation for the available knowledge and an efficient\nalgorithm to perform inference. An appealing representation is the influence\ndiagram, a network that makes explicit the random variables in a model and\ntheir probabilistic dependencies. Recent advances have developed solution\nprocedures based on the influence diagram. In this paper, we examine the\nfundamental properties that underlie those techniques, and the information\nabout the probabilistic structure that is available in the influence diagram\nrepresentation. The influence diagram is a convenient representation for\ncomputer processing while also being clear and non-mathematical. It displays\nprobabilistic dependence precisely, in a way that is intuitive for decision\nmakers and experts to understand and communicate. As a result, the same\ninfluence diagram can be used to build, assess and analyze a model,\nfacilitating changes in the formulation and feedback from sensitivity analysis.\nThe goal in this paper is to determine arbitrary conditional probability\ndistributions from a given probabilistic model. Given qualitative information\nabout the dependence of the random variables in the model we can, for a\nspecific conditional expression, specify precisely what quantitative\ninformation we need to be able to determine the desired conditional probability\ndistribution. It is also shown how we can find that probability distribution by\nperforming operations locally, that is, over subspaces of the joint\ndistribution. In this way, we can exploit the conditional independence present\nin the model to avoid having to construct or manipulate the full joint\ndistribution. These results are extended to include maximal processing when the\ninformation available is incomplete, and optimal decision making in an\nuncertain environment. Influence diagrams as a computer-aided modeling tool\nwere developed by Miller, Merkofer, and Howard [5] and extended by Howard and\nMatheson [2]. Good descriptions of how to use them in modeling are in Owen [7]\nand Howard and Matheson [2]. The notion of solving a decision problem through\ninfluence diagrams was examined by Olmsted [6] and such an algorithm was\ndeveloped by Shachter [8]. The latter paper also shows how influence diagrams\ncan be used to perform a variety of sensitivity analyses. This paper extends\nthose results by developing a theory of the properties of the diagram that are\nused by the algorithm, and the information needed to solve arbitrary\nprobability inference problems. Section 2 develops the notation and the\nframework for the paper and the relationship between influence diagrams and\njoint probability distributions. The general probabilistic inference problem is\nposed in Section 3. In Section 4 the transformations on the diagram are\ndeveloped and then put together into a solution procedure in Section 5. In\nSection 6, this procedure is used to calculate the information requirement to\nsolve an inference problem and the maximal processing that can be performed\nwith incomplete information. Section 7 contains a summary of results.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:16 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3447","submitter":"David Sher","authors":"David Sher","title":"Developing and Analyzing Boundary Detection Operators Using\n  Probabilistic Models","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-245-252","categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Most feature detectors such as edge detectors or circle finders are\nstatistical, in the sense that they decide at each point in an image about the\npresence of a feature, this paper describes the use of Bayesian feature\ndetectors.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:23 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3448","submitter":"John Fox","authors":"John Fox","title":"Strong & Weak Methods: A Logical View of Uncertainty","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-253-257","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The last few years has seen a growing debate about techniques for managing\nuncertainty in AI systems. Unfortunately this debate has been cast as a rivalry\nbetween AI methods and classical probability based ones. Three arguments for\nextending the probability framework of uncertainty are presented, none of which\nimply a challenge to classical methods. These are (1) explicit representation\nof several types of uncertainty, specifically possibility and plausibility, as\nwell as probability, (2) the use of weak methods for uncertainty management in\nproblems which are poorly defined, and (3) symbolic representation of different\nuncertainty calculi and methods for choosing between them.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:28 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3449","submitter":"Lester Ingber","authors":"Lester Ingber","title":"Statistical Mechanics Algorithm for Response to Targets (SMART)","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-258-264","categories":"cs.CE cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is proposed to apply modern methods of nonlinear nonequilibrium\nstatistical mechanics to develop software algorithms that will optimally\nrespond to targets within short response times with minimal computer resources.\nThis Statistical Mechanics Algorithm for Response to Targets (SMART) can be\ndeveloped with a view towards its future implementation into a hardwired\nStatistical Algorithm Multiprocessor (SAM) to enhance the efficiency and speed\nof response to targets (SMART_SAM).\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:34 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3450","submitter":"Tod S. Levitt","authors":"Tod S. Levitt","title":"Probabilistic Conflict Resolution in Hierarchical Hypothesis Spaces","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-265-272","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Artificial intelligence applications such as industrial robotics, military\nsurveillance, and hazardous environment clean-up, require situation\nunderstanding based on partial, uncertain, and ambiguous or erroneous evidence.\nIt is necessary to evaluate the relative likelihood of multiple possible\nhypotheses of the (current) situation faced by the decision making program.\nOften, the evidence and hypotheses are hierarchical in nature. In image\nunderstanding tasks, for example, evidence begins with raw imagery, from which\nambiguous features are extracted which have multiple possible aggregations\nproviding evidential support for the presence of multiple hypothesis of objects\nand terrain, which in turn aggregate in multiple ways to provide partial\nevidence for different interpretations of the ambient scene. Information fusion\nfor military situation understanding has a similar evidence/hypothesis\nhierarchy from multiple sensor through message level interpretations, and also\nprovides evidence at multiple levels of the doctrinal hierarchy of military\nforces.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:40 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.3451","submitter":"Gerald Shao-Hung Liu","authors":"Gerald Shao-Hung Liu","title":"Knowledge Structures and Evidential Reasoning in Decision Analysis","comments":"Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)","journal-ref":null,"doi":null,"report-no":"UAI-P-1985-PG-273-282","categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The roles played by decision factors in making complex subject are decisions\nare characterized by how these factors affect the overall decision. Evidence\nthat partially matches a factor is evaluated, and then effective computational\nrules are applied to these roles to form an appropriate aggregation of the\nevidence. The use of this technique supports the expression of deeper levels of\ncausality, and may also preserve the cognitive structure of the decision maker\nbetter than the usual weighting methods, certainty-factor or other\nprobabilistic models can.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 19:58:46 GMT"}],"update_date":"2013-04-15"}
{"id":"1304.7217","submitter":"Oleg Kupervasser","authors":"Oleg Kupervasser, Alexander Rubinstein","title":"Correction of inertial navigation system's errors by the help of\n  video-based navigator based on Digital Terrarium Map","comments":"32 pages, 18 figures, Positioning Vol.4 No.1, February 2013. arXiv\n  admin note: substantial text overlap with arXiv:1107.0399, arXiv:1107.1470,\n  arXiv:1106.6341","journal-ref":null,"doi":"10.4236/pos.2013.41010","report-no":null,"categories":"cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper deals with the error analysis of a novel navigation algorithm that\nuses as input the sequence of images acquired from a moving camera and a\nDigital Terrain (or Elevation) Map (DTM/DEM). More specifically, it has been\nshown that the optical flow derived from two consecutive camera frames can be\nused in combination with a DTM to estimate the position, orientation and\nego-motion parameters of the moving camera. As opposed to previous works, the\nproposed approach does not require an intermediate explicit reconstruction of\nthe 3D world. In the present work the sensitivity of the algorithm outlined\nabove is studied. The main sources for errors are identified to be the\noptical-flow evaluation and computation, the quality of the information about\nthe terrain, the structure of the observed terrain and the trajectory of the\ncamera. By assuming appropriate characterization of these error sources, a\nclosed form expression for the uncertainty of the pose and motion of the camera\nis first developed and then the influence of these factors is confirmed using\nextensive numerical simulations. The main conclusion of this paper is to\nestablish that the proposed navigation algorithm generates accurate estimates\nfor reasonable scenarios and error sources, and thus can be effectively used as\npart of a navigation system of autonomous vehicles.\n","versions":[{"version":"v1","created":"Wed, 27 Mar 2013 20:46:49 GMT"}],"update_date":"2013-04-29"}
{"id":"1304.7244","submitter":"Henning Schnoor","authors":"Rudolf Berghammer and Henning Schnoor","title":"Relation-algebraic and Tool-supported Control of Condorcet Voting","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a relation-algebraic model of Condorcet voting and, based on it,\nrelation-algebraic solutions of the constructive control problem via the\nremoval of voters.\n  We consider two winning conditions, viz. to be a Condorcet winner and to be\nin the (Gilles resp. upward) uncovered set. For the first condition the control\nproblem is known to be NP-hard; for the second condition the NP-hardness of the\ncontrol problem is shown in the paper. All relation-algebraic specifications we\nwill develop in the paper immediately can be translated into the programming\nlanguage of the BDD-based computer system RelView. Our approach is very\nflexible and especially appropriate for prototyping and experimentation, and as\nsuch very instructive for educational purposes. It can easily be applied to\nother voting rules and control problems.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 11:17:46 GMT"}],"update_date":"2013-04-29"}
{"id":"1304.8001","submitter":"LiGang Hou","authors":"L. G. Hou and J. L. Han","title":"The spiral structure of our Milky Way","comments":"To appear in IAUS 292, \"Molecular Gas, Dust, and Star Formation in\n  Galaxies\", 1 page, 1 figure","journal-ref":null,"doi":"10.1017/S1743921313000665","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The spiral structure of our Milky Way has not yet been well outlined. HII\nregions, giant molecular clouds (GMCs) and 6.7-GHz methanol masers are primary\ntracers for spiral arms. We collect and update the database of these tracers\nwhich has been used in Hou, Han & Shi (2009) for mapping the spiral structure.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 02:06:01 GMT"}],"update_date":"2013-05-01"}
{"id":"1305.6505","submitter":"Germano D'Abramo","authors":"Germano D'Abramo","title":"The Demon in a vacuum tube","comments":"16 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:1101.5056","journal-ref":"Entropy 2013; 15(5):1916-1928","doi":"10.3390/e15051916","report-no":null,"categories":"physics.class-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the present paper, several issues concerning the second law of\nthermodynamics, Maxwell's demon and Landauer's principle are dealt with. I\nargue that if the demon and the system on which it operates without dissipation\nof external energy are made of atoms and molecules (gas, liquid or solid) in\nthermal equilibrium (whose behaviour is described by a canonical distribution),\nthen the unavoidable reason why the demon cannot successfully operate resides\nin the ubiquity of thermal fluctuations and friction. Landauer's principle\nappears to be unnecessary. I also suggest that if the behaviour of the demon\nand the system on which it acts is not always describable by a canonical\ndistribution, as would happen for instance with the ballistic motion of\nelectrons at early stages of thermionic emission, then a successful working\ndemon cannot be ruled out a priori. A critical review of two recent experiments\non thermionic emission Maxwell's demons is also given.\n","versions":[{"version":"v1","created":"Thu, 28 Mar 2013 09:41:28 GMT"},{"version":"v2","created":"Mon, 3 Jun 2013 14:11:17 GMT"}],"update_date":"2013-06-04"}
